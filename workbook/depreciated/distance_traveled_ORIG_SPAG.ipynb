{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Notebook - DEPRECIATED - CODE IS SPAGHETTI\n",
    "## Refactored - impoved book in workbook folder (as of 10-2-24)\n",
    "### Calculate the distance each team will need to travel over the course of the season\n",
    "\n",
    "#### Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy\n",
    "from geopy.distance import geodesic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paths to source data\n",
    "\n",
    "# schedule_path = os.path.join('..', 'data', 'schedule', '2024_current.csv')\n",
    "schedule_path = os.path.join('..', 'data', 'schedule', 'CHN_Schedule_First Pass_v1.csv')\n",
    "schedule_data = pd.read_csv(schedule_path)\n",
    "raw_schedule_df = schedule_data.copy()\n",
    "\n",
    "# ARENA INFO FILE\n",
    "arena_path = os.path.join('..', 'data', 'arena_school_info.csv')\n",
    "arena_data = pd.read_csv(arena_path)\n",
    "arena_info_df = arena_data.copy()\n",
    "\n",
    "# NEUTRAL SITE ARENA INFORMATION FILE\n",
    "neutral_path = os.path.join('..', 'data', 'neutral_arenas_2024.csv')\n",
    "neutral_arenas_df = pd.read_csv(neutral_path)\n",
    "\n",
    "# Display data\n",
    "# schedule_data.head()\n",
    "# schedule_data.tail()\n",
    "# arena_data.head()\n",
    "# neutral_arenas_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW ATTEMPT WITH PAIRED DOWN LOGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbanc\\AppData\\Local\\Temp\\ipykernel_20260\\3456361135.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_schedule_filtered['Is_Neutral_Game'] = raw_schedule_filtered.apply(is_neutral_game, axis=1, flags=neutral_flags)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>N_trips</th>\n",
       "      <th>N_total_distance</th>\n",
       "      <th>N_AVG</th>\n",
       "      <th>N_longest</th>\n",
       "      <th>N_shortest</th>\n",
       "      <th>non_con_trips</th>\n",
       "      <th>non_con_total_distance</th>\n",
       "      <th>non_con_AVG</th>\n",
       "      <th>non_con_longest</th>\n",
       "      <th>non_con_shortest</th>\n",
       "      <th>con_trips</th>\n",
       "      <th>con_total_distance</th>\n",
       "      <th>con_AVG</th>\n",
       "      <th>con_longest</th>\n",
       "      <th>con_shortest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>1.0</td>\n",
       "      <td>600.521127</td>\n",
       "      <td>600.521127</td>\n",
       "      <td>600.521127</td>\n",
       "      <td>600.521127</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3542.001054</td>\n",
       "      <td>1180.667018</td>\n",
       "      <td>1764.998085</td>\n",
       "      <td>12.004884</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18965.356972</td>\n",
       "      <td>1580.446414</td>\n",
       "      <td>1771.362615</td>\n",
       "      <td>1316.604241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2721.985269</td>\n",
       "      <td>2721.985269</td>\n",
       "      <td>2721.985269</td>\n",
       "      <td>2721.985269</td>\n",
       "      <td>23.0</td>\n",
       "      <td>57082.542783</td>\n",
       "      <td>2481.849686</td>\n",
       "      <td>3275.395086</td>\n",
       "      <td>260.422806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska Anchorage</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>53129.593788</td>\n",
       "      <td>2656.479689</td>\n",
       "      <td>3401.368614</td>\n",
       "      <td>260.422806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Intl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1611.208703</td>\n",
       "      <td>268.534784</td>\n",
       "      <td>565.237531</td>\n",
       "      <td>51.976219</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2582.489109</td>\n",
       "      <td>198.653008</td>\n",
       "      <td>410.160970</td>\n",
       "      <td>39.218970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arizona State</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.751265</td>\n",
       "      <td>1.751265</td>\n",
       "      <td>1.751265</td>\n",
       "      <td>1.751265</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8786.443755</td>\n",
       "      <td>1464.407292</td>\n",
       "      <td>2271.357695</td>\n",
       "      <td>548.654698</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10198.994030</td>\n",
       "      <td>849.916169</td>\n",
       "      <td>1563.331540</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Team  N_trips  N_total_distance        N_AVG    N_longest  \\\n",
       "0         Air Force      1.0        600.521127   600.521127   600.521127   \n",
       "1            Alaska      1.0       2721.985269  2721.985269  2721.985269   \n",
       "2  Alaska Anchorage      0.0          0.000000     0.000000     0.000000   \n",
       "3     American Intl      0.0          0.000000     0.000000     0.000000   \n",
       "4     Arizona State      1.0          1.751265     1.751265     1.751265   \n",
       "\n",
       "    N_shortest  non_con_trips  non_con_total_distance  non_con_AVG  \\\n",
       "0   600.521127            3.0             3542.001054  1180.667018   \n",
       "1  2721.985269           23.0            57082.542783  2481.849686   \n",
       "2     0.000000           20.0            53129.593788  2656.479689   \n",
       "3     0.000000            6.0             1611.208703   268.534784   \n",
       "4     1.751265            6.0             8786.443755  1464.407292   \n",
       "\n",
       "   non_con_longest  non_con_shortest  con_trips  con_total_distance  \\\n",
       "0      1764.998085         12.004884       12.0        18965.356972   \n",
       "1      3275.395086        260.422806        0.0            0.000000   \n",
       "2      3401.368614        260.422806        0.0            0.000000   \n",
       "3       565.237531         51.976219       13.0         2582.489109   \n",
       "4      2271.357695        548.654698       12.0        10198.994030   \n",
       "\n",
       "       con_AVG  con_longest  con_shortest  \n",
       "0  1580.446414  1771.362615   1316.604241  \n",
       "1     0.000000     0.000000      0.000000  \n",
       "2     0.000000     0.000000      0.000000  \n",
       "3   198.653008   410.160970     39.218970  \n",
       "4   849.916169  1563.331540      0.000000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete refactored code block with corrections\n",
    "## Ensure the Data column in the schedule data is in datetime format\n",
    "raw_schedule_df['Date'] = pd.to_datetime(raw_schedule_df['Date'])\n",
    "\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# ## Remove ' from all Team columns\n",
    "raw_schedule_df['Home_Team'] = raw_schedule_df['Home_Team'].str.replace(\"'\", \"\")\n",
    "raw_schedule_df['Away_Team'] = raw_schedule_df['Away_Team'].str.replace(\"'\", \"\")\n",
    "\n",
    "# Helper function to calculate distance between two sets of coordinates\n",
    "def calculate_distance(coord1, coord2):\n",
    "    if pd.notna(coord1[0]) and pd.notna(coord2[0]):\n",
    "        return geodesic(coord1, coord2).miles\n",
    "    return 0\n",
    "\n",
    "# Step 1: Filter out exhibition games, games with \"TBA\", and games with \"/\" in team names\n",
    "raw_schedule_filtered = raw_schedule_df[\n",
    "    (raw_schedule_df['Conference'] != 'Exhibition') &\n",
    "    (~raw_schedule_df['Away_Team'].str.contains('TBA')) &\n",
    "    (~raw_schedule_df['Home_Team'].str.contains('TBA')) &\n",
    "    (~raw_schedule_df['Away_Team'].str.contains('/')) &\n",
    "    (~raw_schedule_df['Home_Team'].str.contains('/'))\n",
    "]\n",
    "\n",
    "# Step 2: Flag neutral site games using the 'Flag' column from the neutral arenas table\n",
    "def is_neutral_game(row, flags):\n",
    "    # Check for flags in both Conference and Game_Notes columns\n",
    "    conference_match = any(flag in str(row['Conference']) for flag in flags)\n",
    "    notes_match = any(flag in str(row['Game_Notes']) for flag in flags)\n",
    "    return conference_match or notes_match\n",
    "\n",
    "neutral_flags = neutral_arenas_df['Flag'].tolist()\n",
    "raw_schedule_filtered['Is_Neutral_Game'] = raw_schedule_filtered.apply(is_neutral_game, axis=1, flags=neutral_flags)\n",
    "\n",
    "# Step 3: Merge arena coordinates for home and away teams\n",
    "# Merge home team coordinates\n",
    "schedule_with_coords = raw_schedule_filtered.merge(arena_info_df[['Team', 'Latitude', 'Longitude']], \n",
    "                                                   left_on='Home_Team', right_on='Team', how='left')\n",
    "schedule_with_coords = schedule_with_coords.rename(columns={'Latitude': 'Home_Lat', 'Longitude': 'Home_Lon'})\n",
    "\n",
    "# Merge away team coordinates\n",
    "schedule_with_coords = schedule_with_coords.merge(arena_info_df[['Team', 'Latitude', 'Longitude']], \n",
    "                                                  left_on='Away_Team', right_on='Team', how='left')\n",
    "schedule_with_coords = schedule_with_coords.rename(columns={'Latitude': 'Away_Lat', 'Longitude': 'Away_Lon'})\n",
    "\n",
    "# Step 4: Categorize games into on-campus conference, on-campus non-conference, and neutral site\n",
    "def categorize_game(row):\n",
    "    if row['Is_Neutral_Game']:\n",
    "        return 'Neutral'\n",
    "    elif row['Conference'] == 'Non-Conference':\n",
    "        return 'On-Campus Non-Conference'\n",
    "    else:\n",
    "        return 'On-Campus Conference'\n",
    "\n",
    "schedule_with_coords['Game_Type'] = schedule_with_coords.apply(categorize_game, axis=1)\n",
    "\n",
    "# Step 5: Calculate the distance for all games\n",
    "schedule_with_coords['Distance'] = schedule_with_coords.apply(\n",
    "    lambda row: calculate_distance((row['Away_Lat'], row['Away_Lon']), (row['Home_Lat'], row['Home_Lon'])), axis=1)\n",
    "\n",
    "# Adjust the neutral site distance calculation using the neutral arena coordinates for both teams\n",
    "def calculate_neutral_distance(row, neutral_df):\n",
    "    if row['Is_Neutral_Game']:\n",
    "        # Find the neutral site coordinates from the neutral arenas table\n",
    "        neutral_site = neutral_df[neutral_df['Flag'].apply(lambda x: x in str(row['Conference']) or x in str(row['Game_Notes']))]\n",
    "        \n",
    "        if not neutral_site.empty:\n",
    "            neutral_lat = neutral_site.iloc[0]['latitude']\n",
    "            neutral_lon = neutral_site.iloc[0]['longitude']\n",
    "            # Calculate distance from away team to neutral site\n",
    "            away_to_neutral = calculate_distance((row['Away_Lat'], row['Away_Lon']), (neutral_lat, neutral_lon))\n",
    "            # Calculate distance from home team to neutral site\n",
    "            home_to_neutral = calculate_distance((row['Home_Lat'], row['Home_Lon']), (neutral_lat, neutral_lon))\n",
    "            # Return both distances separately to track for both teams\n",
    "            return away_to_neutral, home_to_neutral\n",
    "    # Non-neutral games: apply the same distance for both teams (travel for the away team)\n",
    "    return row['Distance'], row['Distance']\n",
    "\n",
    "# Apply the new logic for neutral site games using the correct neutral coordinates\n",
    "schedule_with_coords[['Away_Distance', 'Home_Distance']] = schedule_with_coords.apply(calculate_neutral_distance, axis=1, result_type='expand', neutral_df=neutral_arenas_df)\n",
    "\n",
    "# Convert 'Date' column to datetime format for easier manipulation\n",
    "schedule_with_coords['Date'] = pd.to_datetime(schedule_with_coords['Date'])\n",
    "\n",
    "\n",
    "# # Rework the Travel Flag logic to account for consecutive games at the same venue and not count them as travel\n",
    "# schedule_with_coords['Travel_Flag'] = 1\n",
    "\n",
    "# # Sort the data by 'Away_Team', 'Home_Team', and 'Date' to ensure games are grouped correctly\n",
    "# schedule_with_coords = schedule_with_coords.sort_values(by=['Away_Team', 'Home_Team', 'Date'])\n",
    "\n",
    "\n",
    "\n",
    "## Step 6: Calculate the travel flag for each game\n",
    "# Reset the travel flag\n",
    "schedule_with_coords['Travel_Flag'] = 1\n",
    "\n",
    "# Sort the data by 'Away_Team', 'Home_Team', and 'Date' to ensure games are grouped correctly\n",
    "schedule_with_coords = schedule_with_coords.sort_values(by=['Away_Team', 'Home_Team', 'Date'])\n",
    "\n",
    "# Group by 'Away_Team' and 'Home_Team', then iterate through each group to set the travel flag\n",
    "for (away_team, home_team), group in schedule_with_coords.groupby(['Away_Team', 'Home_Team']):\n",
    "    group = group.sort_values(by='Date')  # Sort by date within each group\n",
    "    \n",
    "    # Iterate through the group to check for consecutive games\n",
    "    for i in range(1, len(group)):\n",
    "        current_game = group.iloc[i]\n",
    "        previous_game = group.iloc[i - 1]\n",
    "        \n",
    "        # Check if the games are within (plus or minus) 3 days at the same venue\n",
    "        if (current_game['Date'] - previous_game['Date']).days <= 3 and current_game['Distance'] == 0:\n",
    "            # Set the travel flag to 0 for the current game\n",
    "            schedule_with_coords.loc[current_game.name, 'Travel_Flag'] = 0\n",
    "        \n",
    "\n",
    "# # Only consider rows where Travel_Flag is 1 for calculating total travel distance\n",
    "schedule_with_coords['Adjusted_Away_Distance'] = schedule_with_coords['Away_Distance'] * schedule_with_coords['Travel_Flag']\n",
    "schedule_with_coords['Adjusted_Home_Distance'] = schedule_with_coords['Home_Distance'] * schedule_with_coords['Travel_Flag']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 8: Group by team and game type for both away and home travel distances\n",
    "away_team_travel_stats = schedule_with_coords.groupby(['Away_Team', 'Game_Type']).agg(\n",
    "    total_trips=('Game_ID', 'count'),\n",
    "    total_distance=('Adjusted_Away_Distance', 'sum'),\n",
    "    average_distance=('Adjusted_Away_Distance', 'mean'),\n",
    "    longest_trip=('Adjusted_Away_Distance', 'max'),\n",
    "    shortest_trip=('Adjusted_Away_Distance', 'min')\n",
    ").reset_index()\n",
    "\n",
    "# Home teams need separate stats for neutral games\n",
    "home_team_travel_stats = schedule_with_coords[schedule_with_coords['Is_Neutral_Game']].groupby(['Home_Team', 'Game_Type']).agg(\n",
    "    total_trips=('Game_ID', 'count'),\n",
    "    total_distance=('Adjusted_Home_Distance', 'sum'),\n",
    "    average_distance=('Adjusted_Home_Distance', 'mean'),\n",
    "    longest_trip=('Adjusted_Home_Distance', 'max'),\n",
    "    shortest_trip=('Adjusted_Home_Distance', 'min')\n",
    ").reset_index()\n",
    "\n",
    "# Step 9: Combine both the away and home team travel stats into a unified DataFrame\n",
    "travel_stats_combined = pd.concat([away_team_travel_stats.rename(columns={'Away_Team': 'Team'}),\n",
    "                                   home_team_travel_stats.rename(columns={'Home_Team': 'Team'})], axis=0)\n",
    "\n",
    "# Step 10: Aggregate the final travel stats for each team\n",
    "team_travel_stats_final = travel_stats_combined.groupby(['Team', 'Game_Type']).agg(\n",
    "    total_trips=('total_trips', 'sum'),\n",
    "    total_distance=('total_distance', 'sum'),\n",
    "    average_distance=('average_distance', 'mean'),\n",
    "    longest_trip=('longest_trip', 'max'),\n",
    "    shortest_trip=('shortest_trip', 'min')\n",
    ").reset_index()\n",
    "\n",
    "# Step 11: Pivot the final travel stats to match the required format\n",
    "team_travel_summary_final = team_travel_stats_final.pivot_table(\n",
    "    index='Team',\n",
    "    columns='Game_Type',\n",
    "    values=['total_trips', 'total_distance', 'average_distance', 'longest_trip', 'shortest_trip'],\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Step 12: Flatten the columns for readability\n",
    "team_travel_summary_final.columns = ['_'.join(col).strip() for col in team_travel_summary_final.columns]\n",
    "\n",
    "# Step 13: Rename and reorder columns to the desired format\n",
    "team_travel_summary_reset = team_travel_summary_final.reset_index()\n",
    "\n",
    "new_column_names_final = {\n",
    "    'total_trips_Neutral': 'N_trips',\n",
    "    'total_distance_Neutral': 'N_total_distance',\n",
    "    'average_distance_Neutral': 'N_AVG',\n",
    "    'longest_trip_Neutral': 'N_longest',\n",
    "    'shortest_trip_Neutral': 'N_shortest',\n",
    "    'total_trips_On-Campus Non-Conference': 'non_con_trips',\n",
    "    'total_distance_On-Campus Non-Conference': 'non_con_total_distance',\n",
    "    'average_distance_On-Campus Non-Conference': 'non_con_AVG',\n",
    "    'longest_trip_On-Campus Non-Conference': 'non_con_longest',\n",
    "    'shortest_trip_On-Campus Non-Conference': 'non_con_shortest',\n",
    "    'total_trips_On-Campus Conference': 'con_trips',\n",
    "    'total_distance_On-Campus Conference': 'con_total_distance',\n",
    "    'average_distance_On-Campus Conference': 'con_AVG',\n",
    "    'longest_trip_On-Campus Conference': 'con_longest',\n",
    "    'shortest_trip_On-Campus Conference': 'con_shortest'\n",
    "}\n",
    "\n",
    "team_travel_summary_reset.rename(columns=new_column_names_final, inplace=True)\n",
    "\n",
    "\n",
    "new_column_names_final = {\n",
    "    'total_trips_Neutral': 'N_trips',\n",
    "    'total_distance_Neutral': 'N_total_distance',\n",
    "    'average_distance_Neutral': 'N_AVG',\n",
    "    'longest_trip_Neutral': 'N_longest',\n",
    "    'shortest_trip_Neutral': 'N_shortest',\n",
    "    'total_trips_On-Campus Non-Conference': 'non_con_trips',\n",
    "    'total_distance_On-Campus Non-Conference': 'non_con_total_distance',\n",
    "    'average_distance_On-Campus Non-Conference': 'non_con_AVG',\n",
    "    'longest_trip_On-Campus Non-Conference': 'non_con_longest',\n",
    "    'shortest_trip_On-Campus Non-Conference': 'non_con_shortest',\n",
    "    'total_trips_On-Campus Conference': 'con_trips',\n",
    "    'total_distance_On-Campus Conference': 'con_total_distance',\n",
    "    'average_distance_On-Campus Conference': 'con_AVG',\n",
    "    'longest_trip_On-Campus Conference': 'con_longest',\n",
    "    'shortest_trip_On-Campus Conference': 'con_shortest'\n",
    "}\n",
    "\n",
    "team_travel_summary_reset.rename(columns=new_column_names_final, inplace=True)\n",
    "\n",
    "# Final columns order\n",
    "columns_order_final = [\n",
    "    'Team', 'N_trips', 'N_total_distance', 'N_AVG', 'N_longest', 'N_shortest',\n",
    "    'non_con_trips', 'non_con_total_distance', 'non_con_AVG', 'non_con_longest', 'non_con_shortest',\n",
    "    'con_trips', 'con_total_distance', 'con_AVG', 'con_longest', 'con_shortest'\n",
    "]\n",
    "\n",
    "team_travel_summary_final_display = team_travel_summary_reset[columns_order_final]\n",
    "\n",
    "# Display the final table\n",
    "\n",
    "\n",
    "team_travel_summary_final_display.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>N_trips</th>\n",
       "      <th>N_total_distance</th>\n",
       "      <th>N_AVG</th>\n",
       "      <th>N_longest</th>\n",
       "      <th>N_shortest</th>\n",
       "      <th>non_con_trips</th>\n",
       "      <th>non_con_total_distance</th>\n",
       "      <th>non_con_AVG</th>\n",
       "      <th>non_con_longest</th>\n",
       "      <th>non_con_shortest</th>\n",
       "      <th>con_trips</th>\n",
       "      <th>con_total_distance</th>\n",
       "      <th>con_AVG</th>\n",
       "      <th>con_longest</th>\n",
       "      <th>con_shortest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>2.0</td>\n",
       "      <td>237.861534</td>\n",
       "      <td>118.930767</td>\n",
       "      <td>202.363751</td>\n",
       "      <td>35.497783</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4681.364810</td>\n",
       "      <td>936.272962</td>\n",
       "      <td>1646.638250</td>\n",
       "      <td>95.807984</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2939.925058</td>\n",
       "      <td>244.993755</td>\n",
       "      <td>510.848289</td>\n",
       "      <td>49.682849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Michigan State</td>\n",
       "      <td>3.0</td>\n",
       "      <td>310.955628</td>\n",
       "      <td>103.651876</td>\n",
       "      <td>170.821767</td>\n",
       "      <td>62.204115</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1092.667842</td>\n",
       "      <td>273.166961</td>\n",
       "      <td>286.541055</td>\n",
       "      <td>259.792866</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2845.336209</td>\n",
       "      <td>258.666928</td>\n",
       "      <td>463.104574</td>\n",
       "      <td>49.682849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Michigan Tech</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2035.046257</td>\n",
       "      <td>1017.523128</td>\n",
       "      <td>1715.855635</td>\n",
       "      <td>319.190621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3822.215818</td>\n",
       "      <td>273.015416</td>\n",
       "      <td>469.624467</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Northern Michigan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>262.673453</td>\n",
       "      <td>262.673453</td>\n",
       "      <td>262.673453</td>\n",
       "      <td>262.673453</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2127.680969</td>\n",
       "      <td>709.226990</td>\n",
       "      <td>1030.803345</td>\n",
       "      <td>66.074279</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4111.358643</td>\n",
       "      <td>293.668475</td>\n",
       "      <td>502.372833</td>\n",
       "      <td>66.074279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Western Michigan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.901420</td>\n",
       "      <td>46.901420</td>\n",
       "      <td>46.901420</td>\n",
       "      <td>46.901420</td>\n",
       "      <td>3.0</td>\n",
       "      <td>931.591936</td>\n",
       "      <td>310.530645</td>\n",
       "      <td>738.973955</td>\n",
       "      <td>95.807984</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8913.161448</td>\n",
       "      <td>742.763454</td>\n",
       "      <td>1553.692919</td>\n",
       "      <td>196.194384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Team  N_trips  N_total_distance        N_AVG    N_longest  \\\n",
       "34           Michigan      2.0        237.861534   118.930767   202.363751   \n",
       "35     Michigan State      3.0        310.955628   103.651876   170.821767   \n",
       "36      Michigan Tech      2.0       2035.046257  1017.523128  1715.855635   \n",
       "44  Northern Michigan      1.0        262.673453   262.673453   262.673453   \n",
       "65   Western Michigan      1.0         46.901420    46.901420    46.901420   \n",
       "\n",
       "    N_shortest  non_con_trips  non_con_total_distance  non_con_AVG  \\\n",
       "34   35.497783            5.0             4681.364810   936.272962   \n",
       "35   62.204115            4.0             1092.667842   273.166961   \n",
       "36  319.190621            0.0                0.000000     0.000000   \n",
       "44  262.673453            3.0             2127.680969   709.226990   \n",
       "65   46.901420            3.0              931.591936   310.530645   \n",
       "\n",
       "    non_con_longest  non_con_shortest  con_trips  con_total_distance  \\\n",
       "34      1646.638250         95.807984       12.0         2939.925058   \n",
       "35       286.541055        259.792866       11.0         2845.336209   \n",
       "36         0.000000          0.000000       14.0         3822.215818   \n",
       "44      1030.803345         66.074279       14.0         4111.358643   \n",
       "65       738.973955         95.807984       12.0         8913.161448   \n",
       "\n",
       "       con_AVG  con_longest  con_shortest  \n",
       "34  244.993755   510.848289     49.682849  \n",
       "35  258.666928   463.104574     49.682849  \n",
       "36  273.015416   469.624467      0.000000  \n",
       "44  293.668475   502.372833     66.074279  \n",
       "65  742.763454  1553.692919    196.194384  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show only Michginan teams to quality check\n",
    "team_travel_summary_final_display[team_travel_summary_final_display['Team'].str.contains('Michigan')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OUTPUT TO CSV\n",
    "temp_path = os.path.join('..', 'TEMP', 'team_travel_summary_final_v1.01.csv')\n",
    "team_travel_summary_final_display.to_csv(temp_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLDER CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbanc\\AppData\\Local\\Temp\\ipykernel_20260\\1617166954.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_schedule_filtered['Is_Neutral_Game'] = raw_schedule_filtered.apply(is_neutral_game, axis=1, flags=neutral_flags)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Distance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Distance'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistance\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistance\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Non-neutral games, the same distance applies for both (travel for the away team)\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Apply the new logic for neutral site games\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m schedule_with_coords[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAway_Distance\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHome_Distance\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mschedule_with_coords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_neutral_distance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexpand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Reset the travel flag\u001b[39;00m\n\u001b[0;32m     74\u001b[0m schedule_with_coords[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTravel_Flag\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[50], line 68\u001b[0m, in \u001b[0;36mcalculate_neutral_distance\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m away_to_neutral, home_to_neutral\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDistance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistance\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Distance'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# ## Remove ' from all Team columns\n",
    "raw_schedule_df['Home_Team'] = raw_schedule_df['Home_Team'].str.replace(\"'\", \"\")\n",
    "raw_schedule_df['Away_Team'] = raw_schedule_df['Away_Team'].str.replace(\"'\", \"\")\n",
    "\n",
    "\n",
    "# Helper function to calculate distance between two sets of coordinates\n",
    "def calculate_distance(coord1, coord2):\n",
    "    if pd.notna(coord1[0]) and pd.notna(coord2[0]):\n",
    "        return geodesic(coord1, coord2).miles\n",
    "    return 0\n",
    "\n",
    "# Step 1: Filter out exhibition games, games with \"TBA\", and games with \"/\" in team names\n",
    "raw_schedule_filtered = raw_schedule_df[\n",
    "    (raw_schedule_df['Conference'] != 'Exhibition') &\n",
    "    (~raw_schedule_df['Away_Team'].str.contains('TBA')) &\n",
    "    (~raw_schedule_df['Home_Team'].str.contains('TBA')) &\n",
    "    (~raw_schedule_df['Away_Team'].str.contains('/')) &\n",
    "    (~raw_schedule_df['Home_Team'].str.contains('/'))\n",
    "]\n",
    "\n",
    "# Step 2: Flag neutral site games using the 'Flag' column from the neutral arenas table\n",
    "def is_neutral_game(row, flags):\n",
    "    # Check for flags in both Conference and Game_Notes columns\n",
    "    conference_match = any(flag in str(row['Conference']) for flag in flags)\n",
    "    notes_match = any(flag in str(row['Game_Notes']) for flag in flags)\n",
    "    return conference_match or notes_match\n",
    "\n",
    "neutral_flags = neutral_arenas_df['Flag'].tolist()\n",
    "raw_schedule_filtered['Is_Neutral_Game'] = raw_schedule_filtered.apply(is_neutral_game, axis=1, flags=neutral_flags)\n",
    "\n",
    "# Step 3: Merge arena coordinates for home and away teams\n",
    "# Merge home team coordinates\n",
    "schedule_with_coords = raw_schedule_filtered.merge(arena_info_df[['Team', 'Latitude', 'Longitude']], \n",
    "                                                   left_on='Home_Team', right_on='Team', how='left')\n",
    "schedule_with_coords = schedule_with_coords.rename(columns={'Latitude': 'Home_Lat', 'Longitude': 'Home_Lon'})\n",
    "\n",
    "# Merge away team coordinates\n",
    "schedule_with_coords = schedule_with_coords.merge(arena_info_df[['Team', 'Latitude', 'Longitude']], \n",
    "                                                  left_on='Away_Team', right_on='Team', how='left')\n",
    "schedule_with_coords = schedule_with_coords.rename(columns={'Latitude': 'Away_Lat', 'Longitude': 'Away_Lon'})\n",
    "\n",
    "# Step 4: Categorize games into on-campus conference, on-campus non-conference, and neutral site\n",
    "def categorize_game(row):\n",
    "    if row['Is_Neutral_Game']:\n",
    "        return 'Neutral'\n",
    "    elif row['Conference'] == 'Non-Conference':\n",
    "        return 'On-Campus Non-Conference'\n",
    "    else:\n",
    "        return 'On-Campus Conference'\n",
    "\n",
    "schedule_with_coords['Game_Type'] = schedule_with_coords.apply(categorize_game, axis=1)\n",
    "\n",
    "# Adjust the neutral site distance calculation to record distances for both teams separately\n",
    "\n",
    "def calculate_neutral_distance(row):\n",
    "    if row['Is_Neutral_Game']:\n",
    "        # Calculate distance from away team to neutral site (assuming the home location in the row represents the neutral site)\n",
    "        away_to_neutral = calculate_distance((row['Away_Lat'], row['Away_Lon']), (row['Home_Lat'], row['Home_Lon']))\n",
    "        \n",
    "        # Calculate distance from home team to neutral site (assuming the home location in the row represents the neutral site)\n",
    "        home_to_neutral = calculate_distance((row['Home_Lat'], row['Home_Lon']), (row['Away_Lat'], row['Away_Lon']))\n",
    "        \n",
    "        # Return both distances separately to track for both teams\n",
    "        return away_to_neutral, home_to_neutral\n",
    "    else:\n",
    "        return row['Distance'], row['Distance']  # Non-neutral games, the same distance applies for both (travel for the away team)\n",
    "\n",
    "# Apply the new logic for neutral site games\n",
    "schedule_with_coords[['Away_Distance', 'Home_Distance']] = schedule_with_coords.apply(calculate_neutral_distance, axis=1, result_type='expand')\n",
    "\n",
    "# Reset the travel flag\n",
    "schedule_with_coords['Travel_Flag'] = 1\n",
    "\n",
    "# Only consider trips where the Travel_Flag is set to 1 for calculating travel stats\n",
    "schedule_with_coords['Adjusted_Away_Distance'] = schedule_with_coords['Away_Distance'] * schedule_with_coords['Travel_Flag']\n",
    "schedule_with_coords['Adjusted_Home_Distance'] = schedule_with_coords['Home_Distance'] * schedule_with_coords['Travel_Flag']\n",
    "\n",
    "# Group by team and game type for both away and home travel distances\n",
    "away_team_travel_stats = schedule_with_coords.groupby(['Away_Team', 'Game_Type']).agg(\n",
    "    total_trips=('Game_ID', 'count'),\n",
    "    total_distance=('Adjusted_Away_Distance', 'sum'),\n",
    "    average_distance=('Adjusted_Away_Distance', 'mean'),\n",
    "    longest_trip=('Adjusted_Away_Distance', 'max'),\n",
    "    shortest_trip=('Adjusted_Away_Distance', 'min')\n",
    ").reset_index()\n",
    "\n",
    "# Home teams need separate stats for neutral games\n",
    "home_team_travel_stats = schedule_with_coords[schedule_with_coords['Is_Neutral_Game']].groupby(['Home_Team', 'Game_Type']).agg(\n",
    "    total_trips=('Game_ID', 'count'),\n",
    "    total_distance=('Adjusted_Home_Distance', 'sum'),\n",
    "    average_distance=('Adjusted_Home_Distance', 'mean'),\n",
    "    longest_trip=('Adjusted_Home_Distance', 'max'),\n",
    "    shortest_trip=('Adjusted_Home_Distance', 'min')\n",
    ").reset_index()\n",
    "\n",
    "# Combine both the away and home team travel stats into a unified DataFrame\n",
    "travel_stats_combined = pd.concat([away_team_travel_stats.rename(columns={'Away_Team': 'Team'}),\n",
    "                                   home_team_travel_stats.rename(columns={'Home_Team': 'Team'})], axis=0)\n",
    "\n",
    "# Aggregate the final travel stats for each team\n",
    "team_travel_stats_final = travel_stats_combined.groupby(['Team', 'Game_Type']).agg(\n",
    "    total_trips=('total_trips', 'sum'),\n",
    "    total_distance=('total_distance', 'sum'),\n",
    "    average_distance=('average_distance', 'mean'),\n",
    "    longest_trip=('longest_trip', 'max'),\n",
    "    shortest_trip=('shortest_trip', 'min')\n",
    ").reset_index()\n",
    "\n",
    "# Pivot the final travel stats to match the required format\n",
    "team_travel_summary_final = team_travel_stats_final.pivot_table(\n",
    "    index='Team',\n",
    "    columns='Game_Type',\n",
    "    values=['total_trips', 'total_distance', 'average_distance', 'longest_trip', 'shortest_trip'],\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Flatten the columns for readability\n",
    "team_travel_summary_final.columns = ['_'.join(col).strip() for col in team_travel_summary_final.columns]\n",
    "\n",
    "# Rename and reorder columns to the desired format\n",
    "team_travel_summary_reset = team_travel_summary_final.reset_index()\n",
    "\n",
    "new_column_names_final = {\n",
    "    'total_trips_Neutral': 'N_trips',\n",
    "    'total_distance_Neutral': 'N_total_distance',\n",
    "    'average_distance_Neutral': 'N_AVG',\n",
    "    'longest_trip_Neutral': 'N_longest',\n",
    "    'shortest_trip_Neutral': 'N_shortest',\n",
    "    'total_trips_On-Campus Non-Conference': 'non_con_trips',\n",
    "    'total_distance_On-Campus Non-Conference': 'non_con_total_distance',\n",
    "    'average_distance_On-Campus Non-Conference': 'non_con_AVG',\n",
    "    'longest_trip_On-Campus Non-Conference': 'non_con_longest',\n",
    "    'shortest_trip_On-Campus Non-Conference': 'non_con_shortest',\n",
    "    'total_trips_On-Campus Conference': 'con_trips',\n",
    "    'total_distance_On-Campus Conference': 'con_total_distance',\n",
    "    'average_distance_On-Campus Conference': 'con_AVG',\n",
    "    'longest_trip_On-Campus Conference': 'con_longest',\n",
    "    'shortest_trip_On-Campus Conference': 'con_shortest'\n",
    "}\n",
    "\n",
    "team_travel_summary_reset.rename(columns=new_column_names_final, inplace=True)\n",
    "\n",
    "# Final columns order\n",
    "columns_order_final = [\n",
    "    'Team', 'N_trips', 'N_total_distance', 'N_AVG', 'N_longest', 'N_shortest',\n",
    "    'non_con_trips', 'non_con_total_distance', 'non_con_AVG', 'non_con_longest', 'non_con_shortest',\n",
    "    'con_trips', 'con_total_distance', 'con_AVG', 'con_longest', 'con_shortest'\n",
    "]\n",
    "\n",
    "team_travel_summary_final_display = team_travel_summary_reset[columns_order_final]\n",
    "\n",
    "# Display the final table\n",
    "\n",
    "\n",
    "team_travel_summary_final_display.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Remove ' from all Team columns\n",
    "# raw_schedule_df['Home_Team'] = raw_schedule_df['Home_Team'].str.replace(\"'\", \"\")\n",
    "# raw_schedule_df['Away_Team'] = raw_schedule_df['Away_Team'].str.replace(\"'\", \"\")\n",
    "\n",
    "\n",
    "# # Step 1: Filter out exhibition games\n",
    "# raw_schedule_filtered = raw_schedule_df[raw_schedule_df['Conference'] != 'Exhibition']\n",
    "\n",
    "# # Step 2: Flag neutral site games based on the 'Flag' from the neutral arenas table\n",
    "# def is_neutral_game(row, flags):\n",
    "#     conference_match = any(flag in str(row['Conference']) for flag in flags)\n",
    "#     notes_match = any(flag in str(row['Game_Notes']) for flag in flags)\n",
    "#     return conference_match or notes_match\n",
    "\n",
    "# # Extract the list of flags from the neutral arenas table\n",
    "# neutral_flags = neutral_arenas_df['Flag'].tolist()\n",
    "\n",
    "# # Apply the neutral site game flagging logic\n",
    "# raw_schedule_filtered['Is_Neutral_Game'] = raw_schedule_filtered.apply(is_neutral_game, axis=1, flags=neutral_flags)\n",
    "\n",
    "# # Step 3: Merge coordinates for home and away teams based on the arena info\n",
    "# # First, merge the home team coordinates\n",
    "# schedule_with_coords = raw_schedule_filtered.merge(arena_info_df[['Team', 'Latitude', 'Longitude']], \n",
    "#                                                    left_on='Home_Team', right_on='Team', how='left')\n",
    "# schedule_with_coords = schedule_with_coords.rename(columns={'Latitude': 'Home_Lat', 'Longitude': 'Home_Lon'})\n",
    "\n",
    "# # Then, merge the away team coordinates\n",
    "# schedule_with_coords = schedule_with_coords.merge(arena_info_df[['Team', 'Latitude', 'Longitude']], \n",
    "#                                                   left_on='Away_Team', right_on='Team', how='left')\n",
    "# schedule_with_coords = schedule_with_coords.rename(columns={'Latitude': 'Away_Lat', 'Longitude': 'Away_Lon'})\n",
    "\n",
    "# # Step 4: Categorize games into three categories: on-campus conference, on-campus non-conference, and neutral site\n",
    "# def categorize_game(row):\n",
    "#     if row['Is_Neutral_Game']:\n",
    "#         return 'Neutral'\n",
    "#     elif row['Conference'] == 'Non-Conference':\n",
    "#         return 'On-Campus Non-Conference'\n",
    "#     else:\n",
    "#         return 'On-Campus Conference'\n",
    "\n",
    "# schedule_with_coords['Game_Type'] = schedule_with_coords.apply(categorize_game, axis=1)\n",
    "\n",
    "# # View the updated table with neutral game flagging and game categorization\n",
    "# schedule_with_coords[['Date', 'Away_Team', 'Home_Team', 'Is_Neutral_Game', 'Game_Type']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from geopy.distance import geodesic\n",
    "\n",
    "# # Helper function to calculate distance between two sets of coordinates\n",
    "# def calculate_distance(coord1, coord2):\n",
    "#     if pd.notna(coord1[0]) and pd.notna(coord2[0]):  # Ensure coordinates are valid\n",
    "#         return geodesic(coord1, coord2).miles\n",
    "#     return 0\n",
    "\n",
    "# # Step 5: Calculate distance for each game\n",
    "# schedule_with_coords['Distance'] = schedule_with_coords.apply(\n",
    "#     lambda row: calculate_distance((row['Away_Lat'], row['Away_Lon']), (row['Home_Lat'], row['Home_Lon'])), axis=1)\n",
    "\n",
    "# # Step 6: Group by team and game type to calculate total trips, total distance, average distance, longest trip, shortest trip\n",
    "# team_travel_stats = schedule_with_coords.groupby(['Away_Team', 'Game_Type']).agg(\n",
    "#     total_trips=('Game_ID', 'count'),\n",
    "#     total_distance=('Distance', 'sum'),\n",
    "#     average_distance=('Distance', 'mean'),\n",
    "#     longest_trip=('Distance', 'max'),\n",
    "#     shortest_trip=('Distance', 'min')\n",
    "# ).reset_index()\n",
    "\n",
    "# # Pivot the table to show the results for each game type\n",
    "# team_travel_summary = team_travel_stats.pivot_table(\n",
    "#     index='Away_Team', \n",
    "#     columns='Game_Type', \n",
    "#     values=['total_trips', 'total_distance', 'average_distance', 'longest_trip', 'shortest_trip'], \n",
    "#     fill_value=0\n",
    "# )\n",
    "\n",
    "# # Flatten the multi-index columns for readability\n",
    "# team_travel_summary.columns = ['_'.join(col).strip() for col in team_travel_summary.columns]\n",
    "\n",
    "# # team_travel_summary.head(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert 'Date' column to datetime format for easier manipulation\n",
    "schedule_with_coords['Date'] = pd.to_datetime(schedule_with_coords['Date'])\n",
    "\n",
    "# Step 2: Initialize the Travel_Flag for every game as 1 (indicating travel)\n",
    "schedule_with_coords['Travel_Flag'] = 1\n",
    "\n",
    "# Step 3: Sort by 'Away_Team', 'Home_Team', and 'Date' to group correctly\n",
    "schedule_with_coords = schedule_with_coords.sort_values(by=['Away_Team', 'Home_Team', 'Date'])\n",
    "\n",
    "# Step 4: Group by 'Away_Team' and 'Home_Team', and identify multiple-game series\n",
    "for (away_team, home_team), group in schedule_with_coords.groupby(['Away_Team', 'Home_Team']):\n",
    "    group = group.sort_values(by='Date')  # Sort by date within each group\n",
    "    \n",
    "    # Iterate through the group to check for consecutive games within 3 days\n",
    "    for i in range(1, len(group)):\n",
    "        current_game = group.iloc[i]\n",
    "        previous_game = group.iloc[i - 1]\n",
    "        \n",
    "        # If games are within 3 days, set the travel flag of the current game to 0 (no new trip)\n",
    "        if (current_game['Date'] - previous_game['Date']).days <= 3:\n",
    "            schedule_with_coords.loc[current_game.name, 'Travel_Flag'] = 0\n",
    "\n",
    "# Step 5: Calculate adjusted travel distance, considering only trips with Travel_Flag set to 1\n",
    "schedule_with_coords['Adjusted_Travel_Distance'] = schedule_with_coords['Distance'] * schedule_with_coords['Travel_Flag']\n",
    "\n",
    "# Step 6: Remove games with '/' in the team names (as per original notebook logic)\n",
    "schedule_with_coords = schedule_with_coords[~schedule_with_coords['Home_Team'].str.contains('/')]\n",
    "schedule_with_coords = schedule_with_coords[~schedule_with_coords['Away_Team'].str.contains('/')]\n",
    "\n",
    "# Step 7: Handle neutral site games by calculating distance for both home and away teams\n",
    "def calculate_neutral_distance(row):\n",
    "    if row['Is_Neutral_Game']:\n",
    "        # Calculate distance from both home and away team to the neutral site\n",
    "        away_to_neutral = calculate_distance((row['Away_Lat'], row['Away_Lon']), (row['Home_Lat'], row['Home_Lon']))\n",
    "        home_to_neutral = calculate_distance((row['Home_Lat'], row['Home_Lon']), (row['Away_Lat'], row['Away_Lon']))\n",
    "        return away_to_neutral + home_to_neutral  # Sum of both distances\n",
    "    return row['Distance']  # Use original distance if not a neutral site game\n",
    "\n",
    "schedule_with_coords['Adjusted_Travel_Distance'] = schedule_with_coords.apply(calculate_neutral_distance, axis=1)\n",
    "\n",
    "# Step 8: Group by team and game type, considering only games with Travel_Flag set to 1\n",
    "team_travel_stats_updated = schedule_with_coords[schedule_with_coords['Travel_Flag'] == 1].groupby(['Away_Team', 'Game_Type']).agg(\n",
    "    total_trips=('Game_ID', 'count'),\n",
    "    total_distance=('Adjusted_Travel_Distance', 'sum'),\n",
    "    average_distance=('Adjusted_Travel_Distance', 'mean'),\n",
    "    longest_trip=('Adjusted_Travel_Distance', 'max'),\n",
    "    shortest_trip=('Adjusted_Travel_Distance', 'min')\n",
    ").reset_index()\n",
    "\n",
    "# Step 9: Pivot the table to show the results for each game type\n",
    "team_travel_summary_updated = team_travel_stats_updated.pivot_table(\n",
    "    index='Away_Team', \n",
    "    columns='Game_Type', \n",
    "    values=['total_trips', 'total_distance', 'average_distance', 'longest_trip', 'shortest_trip'], \n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Flatten the multi-index columns for readability\n",
    "team_travel_summary_updated.columns = ['_'.join(col).strip() for col in team_travel_summary_updated.columns]\n",
    "\n",
    "# Rename and rearrange columns as requested\n",
    "team_travel_summary_reset_updated = team_travel_summary_updated.reset_index()\n",
    "\n",
    "new_column_names_updated = {\n",
    "    'total_trips_Neutral': 'N_trips',\n",
    "    'total_distance_Neutral': 'N_total_distance',\n",
    "    'average_distance_Neutral': 'N_AVG',\n",
    "    'longest_trip_Neutral': 'N_longest',\n",
    "    'shortest_trip_Neutral': 'N_shortest',\n",
    "    'total_trips_On-Campus Non-Conference': 'non_con_trips',\n",
    "    'total_distance_On-Campus Non-Conference': 'non_con_total_distance',\n",
    "    'average_distance_On-Campus Non-Conference': 'non_con_AVG',\n",
    "    'longest_trip_On-Campus Non-Conference': 'non_con_longest',\n",
    "    'shortest_trip_On-Campus Non-Conference': 'non_con_shortest',\n",
    "    'total_trips_On-Campus Conference': 'con_trips',\n",
    "    'total_distance_On-Campus Conference': 'con_total_distance',\n",
    "    'average_distance_On-Campus Conference': 'con_AVG',\n",
    "    'longest_trip_On-Campus Conference': 'con_longest',\n",
    "    'shortest_trip_On-Campus Conference': 'con_shortest'\n",
    "}\n",
    "\n",
    "team_travel_summary_reset_updated.rename(columns=new_column_names_updated, inplace=True)\n",
    "\n",
    "columns_order_updated = [\n",
    "    'Away_Team', 'N_trips', 'N_total_distance', 'N_AVG', 'N_longest', 'N_shortest',\n",
    "    'non_con_trips', 'non_con_total_distance', 'non_con_AVG', 'non_con_longest', 'non_con_shortest',\n",
    "    'con_trips', 'con_total_distance', 'con_AVG', 'con_longest', 'con_shortest'\n",
    "]\n",
    "\n",
    "team_travel_summary_final_updated = team_travel_summary_reset_updated[columns_order_updated]\n",
    "\n",
    "# Display the final updated table\n",
    "\n",
    "\n",
    "team_travel_summary_final_updated.tail(45)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's rename and rearrange the columns to match the desired output format\n",
    "# team_travel_summary_reset = team_travel_summary.reset_index()\n",
    "\n",
    "# # New column names for better readability\n",
    "# new_column_names = {\n",
    "#     'total_trips_Neutral': 'N_trips',\n",
    "#     'total_distance_Neutral': 'N_total_distance',\n",
    "#     'average_distance_Neutral': 'N_AVG',\n",
    "#     'longest_trip_Neutral': 'N_longest',\n",
    "#     'shortest_trip_Neutral': 'N_shortest',\n",
    "#     'total_trips_On-Campus Non-Conference': 'non_con_trips',\n",
    "#     'total_distance_On-Campus Non-Conference': 'non_con_total_distance',\n",
    "#     'average_distance_On-Campus Non-Conference': 'non_con_AVG',\n",
    "#     'longest_trip_On-Campus Non-Conference': 'non_con_longest',\n",
    "#     'shortest_trip_On-Campus Non-Conference': 'non_con_shortest',\n",
    "#     'total_trips_On-Campus Conference': 'con_trips',\n",
    "#     'total_distance_On-Campus Conference': 'con_total_distance',\n",
    "#     'average_distance_On-Campus Conference': 'con_AVG',\n",
    "#     'longest_trip_On-Campus Conference': 'con_longest',\n",
    "#     'shortest_trip_On-Campus Conference': 'con_shortest'\n",
    "# }\n",
    "\n",
    "# # Renaming the columns\n",
    "# team_travel_summary_reset.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "# # Rearranging columns\n",
    "# columns_order = [\n",
    "#     'Away_Team', 'N_trips', 'N_total_distance', 'N_AVG', 'N_longest', 'N_shortest',\n",
    "#     'non_con_trips', 'non_con_total_distance', 'non_con_AVG', 'non_con_longest', 'non_con_shortest',\n",
    "#     'con_trips', 'con_total_distance', 'con_AVG', 'con_longest', 'con_shortest'\n",
    "# ]\n",
    "\n",
    "# team_travel_summary_final = team_travel_summary_reset[columns_order]\n",
    "\n",
    "# # Display the final table\n",
    "# # tools.display_dataframe_to_user(name=\"Team Travel Summary (Renamed and Rearranged)\", dataframe=team_travel_summary_final)\n",
    "\n",
    "# team_travel_summary_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORIGINAL CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HOTFIX\n",
    "### remove ' from Team names\n",
    "schedule_data['Home_Team'] = schedule_data['Home_Team'].str.replace(\"'\", \"\")\n",
    "schedule_data['Away_Team'] = schedule_data['Away_Team'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop Exhibition Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop Exhibition games from schedule\n",
    "# If 'Exhibition' in Conference column, drop row\n",
    "\n",
    "# Print Schedule length\n",
    "print(f\"Schedule length before dropping Exhibition games: {len(schedule_data)}\")\n",
    "\n",
    "# Drop rows with 'Exhibition' in Conference column\n",
    "schedule_data = schedule_data[schedule_data['Conference'] != 'Exhibition']\n",
    "\n",
    "# Print Schedule length\n",
    "print(f\"Schedule length after dropping Exhibition games: {len(schedule_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Account for neutral site games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows in the schedule table that involve neutral site games\n",
    "# by checking if the 'Conference' or 'Game_Notes' contains a match with the 'Flag' in the neutral arenas table.\n",
    "\n",
    "# Helper function to find if any flag appears in the Conference or Game_Notes columns\n",
    "def is_neutral_game(row, flags):\n",
    "    # Check for flags in both Conference and Game_Notes, ensuring correct handling of NaN\n",
    "    conference_match = any(flag in str(row['Conference']) for flag in flags)\n",
    "    notes_match = any(flag in str(row['Game_Notes']) for flag in flags)\n",
    "    return conference_match or notes_match\n",
    "\n",
    "# Extract the list of flags from the neutral arenas table (assuming already loaded neutral_arenas_df)\n",
    "neutral_flags = neutral_arenas_df['Flag'].tolist()\n",
    "\n",
    "# Apply the function to the schedule data to identify neutral site games\n",
    "schedule_data['Is_Neutral_Game'] = schedule_data.apply(is_neutral_game, axis=1, flags=neutral_flags)\n",
    "\n",
    "# Filter the schedule for neutral site games\n",
    "neutral_site_games = schedule_data[schedule_data['Is_Neutral_Game']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the distance to neutral site locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "### refactor the code to include the distance between the two teams\n",
    "\n",
    "\n",
    "# Helper function to calculate the distance between two points (lat, lon)\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    if pd.notnull(lat1) and pd.notnull(lon1) and pd.notnull(lat2) and pd.notnull(lon2):\n",
    "        return geodesic((lat1, lon1), (lat2, lon2)).miles\n",
    "    else:\n",
    "        return None  # Return None if any coordinates are missing\n",
    "\n",
    "# Function to merge team location data and neutral arenas\n",
    "def merge_team_and_arena_data(schedule_df, team_df, arena_df):\n",
    "    # Merge team locations (away and home teams)\n",
    "    schedule_df = schedule_df.merge(\n",
    "        team_df[['Team', 'Latitude', 'Longitude']], \n",
    "        left_on='Away_Team', right_on='Team', how='left', suffixes=('', '_away')\n",
    "    )\n",
    "    schedule_df = schedule_df.merge(\n",
    "        team_df[['Team', 'Latitude', 'Longitude']], \n",
    "        left_on='Home_Team', right_on='Team', how='left', suffixes=('', '_home')\n",
    "    )\n",
    "\n",
    "    # Merge on 'Conference' column first\n",
    "    schedule_df = schedule_df.merge(\n",
    "        arena_df[['Flag', 'latitude', 'longitude']], \n",
    "        left_on='Conference', right_on='Flag', how='left'\n",
    "    )\n",
    "\n",
    "    # Handle rows where the Conference merge did not work by checking 'Game_Notes'\n",
    "    missing_coords_df = schedule_df[schedule_df['latitude'].isnull()].copy()\n",
    "\n",
    "    def match_flag_in_game_notes(row, arena_df):\n",
    "        for _, flag_row in arena_df.iterrows():\n",
    "            if flag_row['Flag'] in str(row['Game_Notes']):\n",
    "                return flag_row['latitude'], flag_row['longitude']\n",
    "        return None, None\n",
    "\n",
    "    # Apply partial matching function for missing coordinates\n",
    "    missing_coords_df[['latitude', 'longitude']] = missing_coords_df.apply(\n",
    "        lambda row: match_flag_in_game_notes(row, arena_df), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "\n",
    "    # Fill missing latitude/longitude\n",
    "    schedule_df.loc[schedule_df['latitude'].isnull(), ['latitude', 'longitude']] = missing_coords_df[['latitude', 'longitude']]\n",
    "\n",
    "    return schedule_df\n",
    "\n",
    "# Output results\n",
    "# output_path = '../TEMP/neutral_site_games_distances_TEST2.csv'\n",
    "# neutral_site_games.to_csv(output_path, index=False)\n",
    "\n",
    "## PRINT DF INFOR BEFORE THE CLEANING\n",
    "# print(neutral_site_games.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CLEANING BASED ON LOOK AT OUTPUT FROM CELL ABOVE\n",
    "\n",
    "\n",
    "# Remove Rows that have TBD or a / in one of the team columns\n",
    "neutral_site_games = neutral_site_games[~neutral_site_games['Home_Team'].str.contains('/')]\n",
    "neutral_site_games = neutral_site_games[~neutral_site_games['Away_Team'].str.contains('/')]\n",
    "neutral_site_games = neutral_site_games[~neutral_site_games['Home_Team'].str.contains('TBD')]\n",
    "neutral_site_games = neutral_site_games[~neutral_site_games['Away_Team'].str.contains('TBD')]\n",
    "\n",
    "# Print DF INFO AFTER CLEANING\n",
    "# print(neutral_site_games.info())\n",
    "\n",
    "# OUTPUT CSV FOR CHECKING INTO TEMP FOLDER\n",
    "# output_path = '../TEMP/neutral_site_games.csv'\n",
    "# neutral_site_games.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neutral_site_games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New Approach - create a new table and structure for the neutral site games - add them to the agg count at the end\n",
    "\n",
    "## Assign a location to each game - based on the FLag column from neutral_arenas_df\n",
    "\n",
    "# Drop the columns that are not needed\n",
    "neutral_site_games = neutral_site_games.drop(columns=['Away_Team_Link', 'Away_Score', 'Home_Team_Link', 'Home_Score', 'OT', 'Box_Link', 'Metrics_Link'])\n",
    "\n",
    "# Reinex the DF\n",
    "neutral_site_games.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# If Game_Notes is NaN fill with Conference\n",
    "neutral_site_games['Game_Notes'] = neutral_site_games['Game_Notes'].fillna(neutral_site_games['Conference'])\n",
    "\n",
    "# Assign a location to each game\n",
    "# Look for Game_Notes that contain the Flag from neutral_arenas_df\n",
    "# If there is a match, assign the location to the game\n",
    "\n",
    "# Helper function to assign latitude and longitude to each game\n",
    "def assign_location(row, arena_df):\n",
    "    for _, flag_row in arena_df.iterrows():\n",
    "        if flag_row['Flag'] in str(row['Game_Notes']):\n",
    "            return flag_row['latitude'], flag_row['longitude']\n",
    "    return None, None\n",
    "\n",
    "# Extract the list of flags from the neutral arenas table (assuming already loaded neutral_arenas_df)\n",
    "neutral_flags = neutral_arenas_df['Flag'].tolist()\n",
    "\n",
    "# Apply the function to the schedule data to identify neutral site games\n",
    "neutral_site_games[['latitude', 'longitude']] = neutral_site_games.apply(assign_location, axis=1, arena_df=neutral_arenas_df, result_type=\"expand\")\n",
    "\n",
    "# If Gama_Notes is empty or an empty string, fill with Conference value\n",
    "# neutral_site_games['Game_Notes'] = neutral_site_games['Game_Notes'].replace('', neutral_site_games['Conference']) # NOT WORKING AT ALL - THROWING ERROR\n",
    "# neutral_site_games['Game_Notes'] = neutral_site_games['Game_Notes'].fillna(neutral_site_games['Conference']) # Not working must be empty string not NaN\n",
    "\n",
    "\n",
    "# neutral_site_games.head()\n",
    "# neutral_site_games.tail()\n",
    "# neutral_site_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the distance between the two teams for each game\n",
    "\n",
    "# Helper function to calculate the distance between two points (lat, lon)\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    if pd.notnull(lat1) and pd.notnull(lon1) and pd.notnull(lat2) and pd.notnull(lon2):\n",
    "        return geodesic((lat1, lon1), (lat2, lon2)).miles\n",
    "    else:\n",
    "        return None  # Return None if any coordinates are missing\n",
    "\n",
    "# Function to calculate distances to neutral site\n",
    "def calculate_team_distances(schedule_df):\n",
    "    schedule_df['Away_Distance'] = schedule_df.apply(\n",
    "        lambda row: calculate_distance(row['Latitude'], row['Longitude'], row['latitude'], row['longitude']), axis=1\n",
    "    )\n",
    "    schedule_df['Home_Distance'] = schedule_df.apply(\n",
    "        lambda row: calculate_distance(row['Latitude_home'], row['Longitude_home'], row['latitude'], row['longitude']), axis=1\n",
    "    )\n",
    "\n",
    "    return schedule_df\n",
    "\n",
    "# Refactor into steps\n",
    "neutral_site_games = merge_team_and_arena_data(schedule_data, arena_data, neutral_arenas_df)\n",
    "neutral_site_games = calculate_team_distances(neutral_site_games)\n",
    "\n",
    "# Filter out rows with missing distances\n",
    "neutral_site_games = neutral_site_games.dropna(subset=['Away_Distance', 'Home_Distance'])\n",
    "\n",
    "\n",
    "# Output results\n",
    "# output_path = '../TEMP/neutral_site_games_distances_TESTv3.csv'\n",
    "# neutral_site_games.to_csv(output_path, index=False)\n",
    "\n",
    "# neutral_site_games.head()\n",
    "# neutral_site_games.tail()\n",
    "# neutral_site_games.info()\n",
    "# Show Michigan Tech games\n",
    "neutral_site_games[neutral_site_games['Away_Team'] == 'Michigan Tech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DESIRED OUTPUT\n",
    "# Date, Game_ID, Conference, Game_Notes, Team, Distance for each team in each game\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "neutral_site_games_agg = pd.DataFrame(columns=['Date', 'Game_ID', 'Game_Notes', 'Team', 'N_Distance'])\n",
    "\n",
    "# Iterate through the neutral_site_games DataFrame and add the data to the new DataFrame\n",
    "rows = []  # Use a list to accumulate rows for better performance\n",
    "for index, row in neutral_site_games.iterrows():\n",
    "    # Add the Away Team data\n",
    "    rows.append({\n",
    "        'Date': row['Date'],\n",
    "        'Game_ID': row['Game_ID'],\n",
    "        'Game_Notes': row['Game_Notes'],\n",
    "        'Team': row['Away_Team'],\n",
    "        'N_Distance': row['Away_Distance']\n",
    "    })\n",
    "    \n",
    "    # Add the Home Team data\n",
    "    rows.append({\n",
    "        'Date': row['Date'],\n",
    "        'Game_ID': row['Game_ID'],\n",
    "        'Game_Notes': row['Game_Notes'],\n",
    "        'Team': row['Home_Team'],\n",
    "        'N_Distance': row['Home_Distance']\n",
    "    })\n",
    "\n",
    "# Convert the list of rows into a DataFrame and concatenate\n",
    "neutral_site_games_agg_1 = pd.concat([neutral_site_games_agg, pd.DataFrame(rows)], ignore_index=True)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "## Team, Nuetral Site Games, Longest Nueteral Site Game, Shortest Neutral Site Game, Total Distance, Average Neutral Site Game Distance\n",
    "neutral_site_games_agg_1 = neutral_site_games_agg_1.groupby('Team').agg(\n",
    "    N_Games=('Game_ID', 'nunique'),\n",
    "    Longest_N_Game=('N_Distance', 'max'),\n",
    "    Shortest_N_Game=('N_Distance', 'min'),\n",
    "    Total_N_Distance=('N_Distance', 'sum'),\n",
    "    Average_N_Distance=('N_Distance', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "# Output results\n",
    "output_path = '../TEMP/neutral_site_games_agg.csv'\n",
    "neutral_site_games_agg_1.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the first and last few rows of the DataFrame\n",
    "# neutral_site_games_agg_1.head(23)\n",
    "neutral_site_games_agg_1.tail()\n",
    "# Show Michigan Tech\n",
    "neutral_site_games_agg_1[neutral_site_games_agg_1['Team'] == 'Michigan Tech']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NON NEUTRAL GAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the schedule data with the arena data to include home and away team locations\n",
    "\n",
    "# First, ensure team names match between datasets\n",
    "# We will merge on the 'Team' column in the arena data and 'Home_Team'/'Away_Team' in the schedule data\n",
    "merged_data = schedule_data.merge(arena_data[['Team', 'Latitude', 'Longitude']], left_on='Home_Team', right_on='Team', how='left')\n",
    "merged_data = merged_data.rename(columns={'Latitude': 'Home_Latitude', 'Longitude': 'Home_Longitude'})\n",
    "\n",
    "# Merge again for the away teams\n",
    "merged_data = merged_data.merge(arena_data[['Team', 'Latitude', 'Longitude']], left_on='Away_Team', right_on='Team', how='left')\n",
    "merged_data = merged_data.rename(columns={'Latitude': 'Away_Latitude', 'Longitude': 'Away_Longitude'})\n",
    "\n",
    "# Drop the unnecessary 'Team' columns from the merged data\n",
    "merged_data = merged_data.drop(columns=['Team_x', 'Team_y'])\n",
    "\n",
    "# Display the first few rows of the merged data to verify the result\n",
    "# merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the distance between each school\n",
    "- Using Haversine equation to calculate the straight line distance between two sets of lat/lon coodinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VERSION 2 USING GEOPY\n",
    "# Function to calculate distance with NaN check\n",
    "def calculate_distance(row):\n",
    "    # Check for NaN values in lat/long coordinates\n",
    "    if (np.isnan(row['Home_Latitude']) or np.isnan(row['Home_Longitude']) or\n",
    "        np.isnan(row['Away_Latitude']) or np.isnan(row['Away_Longitude'])):\n",
    "        return np.nan  # Return NaN if any of the coordinates are missing\n",
    "    else:\n",
    "        # Calculate the distance if all coordinates are present\n",
    "        return geodesic((row['Home_Latitude'], row['Home_Longitude']), \n",
    "                        (row['Away_Latitude'], row['Away_Longitude'])).miles\n",
    "\n",
    "# Apply the function to calculate the distance between the home and away arenas\n",
    "merged_data['Distance_Miles'] = merged_data.apply(calculate_distance, axis=1)\n",
    "\n",
    "# Display the updated data with the calculated distance\n",
    "# merged_data[['Conference', 'Home_Team', 'Away_Team', 'Distance_Miles']].head()\n",
    "## Display all columns of the merged data\n",
    "# merged_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out results to avoid double counting games on weekend series\n",
    "\n",
    "- Travel_Flag to account for consecutive games played at the same venue within a 3-day span. If a team plays multiple games at the same venue within this period, travel is only counted for the first game.\n",
    "\n",
    "- The Adjusted_Travel_Distance column reflects the distance a team will travel for each game, considering the consecutive game rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VERSION 2\n",
    "# Update logic to handle non-consecutive rows by grouping first\n",
    "\n",
    "# Convert 'Date' column to datetime format for easier manipulation\n",
    "merged_data['Date'] = pd.to_datetime(merged_data['Date'])\n",
    "\n",
    "# Reset the travel flag\n",
    "merged_data['Travel_Flag'] = 1\n",
    "\n",
    "# Sort the data by 'Away_Team', 'Home_Team', and 'Date' to ensure games are grouped correctly\n",
    "merged_data = merged_data.sort_values(by=['Away_Team', 'Home_Team', 'Date'])\n",
    "\n",
    "# Group by 'Away_Team' and 'Home_Team', then iterate through each group to set the travel flag\n",
    "for (away_team, home_team), group in merged_data.groupby(['Away_Team', 'Home_Team']):\n",
    "    group = group.sort_values(by='Date')  # Sort by date within each group\n",
    "    \n",
    "    # Iterate through the group to check for consecutive games\n",
    "    for i in range(1, len(group)):\n",
    "        current_game = group.iloc[i]\n",
    "        previous_game = group.iloc[i - 1]\n",
    "        \n",
    "        # Check if the games are within 3 days\n",
    "        if (current_game['Date'] - previous_game['Date']).days <= 3:\n",
    "            # Set the travel flag to 0 for the current game\n",
    "            merged_data.loc[current_game.name, 'Travel_Flag'] = 0\n",
    "\n",
    "# Only consider rows where travel flag is 1 for calculating total travel distance\n",
    "merged_data['Adjusted_Travel_Distance'] = merged_data['Distance_Miles'] * merged_data['Travel_Flag']\n",
    "\n",
    "# Remove any row where there is a / in either the Home_Team or Away_Team\n",
    "merged_data = merged_data[~merged_data['Home_Team'].str.contains('/')]\n",
    "merged_data = merged_data[~merged_data['Away_Team'].str.contains('/')]\n",
    "\n",
    "# Display the updated data with the travel flag and adjusted distance\n",
    "merged_data[['Away_Team', 'Home_Team', 'Date', 'Distance_Miles', 'Travel_Flag', 'Adjusted_Travel_Distance']].head()\n",
    "\n",
    "# OUTPUT TABLE TO TEMP FILE FOR TESTING\n",
    "output_path = os.path.join('..', 'TEMP', 'schedule_w_distance.csv')\n",
    "merged_data.to_csv(output_path, index=False)\n",
    "\n",
    "schedule_w_distance = merged_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Total Travel Distance for Each Team For Conference and Non Conference Games\n",
    "## Calculate and store the Trip Count and the Average trip distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data.head(15)\\\n",
    "# neutral_site_games.info()\n",
    "# neutral_site_games.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Desired Output\n",
    "\n",
    "## Team, Non-Conference_GP, Non-Conference_Miles, Non-Conference_AVG, \n",
    "## Conference_GP, Conference_Miles, Conference_AVG\n",
    "\n",
    "# Only consider rows where travel flag is 1 for calculating total travel distance\n",
    "merged_data['Adjusted_Travel_Distance'] = merged_data['Distance_Miles'] * merged_data['Travel_Flag']\n",
    "\n",
    "# Filter Nuetral Site games out of the data because those distatnces are already calculated and will be merged back later\n",
    "# If Game_ID appears in neutral_site_games, drop the row from merged_data\n",
    "merged_data = merged_data[~merged_data['Game_ID'].isin(neutral_site_games['Game_ID'])]\n",
    "\n",
    "\n",
    "# Group Non-Conference and Conference games separately\n",
    "non_conference_data = merged_data[merged_data['Conference'] == 'Non-Conference']\n",
    "conference_data = merged_data[merged_data['Conference'] != 'Non-Conference']\n",
    "\n",
    "\n",
    "\n",
    "# Calculate total distance and number of games for each team in Non-Conference and Conference games\n",
    "non_conference_agg = non_conference_data.groupby('Away_Team').agg(\n",
    "    Non_Conference_GP=('Travel_Flag', 'sum'),\n",
    "    Non_Conference_Miles=('Adjusted_Travel_Distance', 'sum'),\n",
    "    Longest_NC_Game=('Adjusted_Travel_Distance', 'max'),\n",
    "    Shortest_NC_Game=('Adjusted_Travel_Distance', lambda x: x[x > 0].min()) ## Find the Shortest Non 0 trip\n",
    "    \n",
    ").reset_index()\n",
    "\n",
    "conference_agg = conference_data.groupby('Away_Team').agg(\n",
    "    Conference_GP=('Travel_Flag', 'sum'),\n",
    "    Conference_Miles=('Adjusted_Travel_Distance', 'sum'),\n",
    "    Longest_Conf_Game=('Adjusted_Travel_Distance', 'max'),\n",
    "    \n",
    "    Shortest_Conf_Game=('Adjusted_Travel_Distance', lambda x: x[x > 0].min())\n",
    ").reset_index()\n",
    "\n",
    "# Calculate average distance per game for Non-Conference and Conference games\n",
    "non_conference_agg['Non_Conference_AVG'] = non_conference_agg['Non_Conference_Miles'] / non_conference_agg['Non_Conference_GP']\n",
    "conference_agg['Conference_AVG'] = conference_agg['Conference_Miles'] / conference_agg['Conference_GP']\n",
    "\n",
    "### Merge the two tables to get the final output\n",
    "merged_agg = non_conference_agg.merge(conference_agg, on='Away_Team', how='outer')\n",
    "\n",
    "# Rename Away_Team to Team\n",
    "merged_agg = merged_agg.rename(columns={'Away_Team': 'Team'})\n",
    "\n",
    "\n",
    "# non_conference_agg.head(10) # Display the aggregated data for Non-Conference games\n",
    "conference_agg.head(10) # Display the aggregated data for Conference games\n",
    "merged_agg.head(10) # Display the merged aggregated data\n",
    "\n",
    "## Examine Michigan State's Conference data\n",
    "# Rearanging with travel flag up front\n",
    "# conference_data = conference_data[['Away_Team', 'Home_Team', 'Date', 'Distance_Miles', 'Travel_Flag', 'Adjusted_Travel_Distance']]\n",
    "# conference_data[conference_data['Away_Team'] == 'Michigan State']\n",
    "\n",
    "non_conference_data.head()\n",
    "\n",
    "# Find Michigan Tech in the nuetral site aggragated data\n",
    "neutral_site_games_agg_1[neutral_site_games_agg_1['Team'] == 'Michigan Tech']\n",
    "# Find Michigan Tech in nueutral site games\n",
    "neutral_site_games[neutral_site_games['Away_Team'] == 'Michigan Tech']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge the neutral site game table with the merged_agg table\n",
    "\n",
    "# Merge the two tables to get the final output\n",
    "final_agg = merged_agg.merge(neutral_site_games_agg_1, on='Team', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_site_games_agg_1\n",
    "final_agg\n",
    "\n",
    "# Output results for manual verification\n",
    "output_path = '../TEMP/final_agg_v3.csv'\n",
    "final_agg.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge Nuetral Site Calculations with the rest of the data\n",
    "\n",
    "# Merge the neutral site games data with the rest of the schedule data\n",
    "merged_agg = merged_agg.merge(neutral_site_games_agg_1, left_on='Away_Team', right_on='Team', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## OLD CODE\n",
    "###### DOES NOT DIFFERENTIATE BETWEEN CONFERENCE AND NON-CONFERENCE GAMES\n",
    "# # Only consider rows where travel flag is 1 for calculating total travel distance\n",
    "# merged_data['Adjusted_Travel_Distance'] = merged_data['Distance_Miles'] * merged_data['Travel_Flag']\n",
    "\n",
    "# # Calculate the total travel distance per team\n",
    "# team_travel_distances = merged_data.groupby('Away_Team')['Adjusted_Travel_Distance'].sum().reset_index()\n",
    "# team_travel_distances.columns = ['Team', 'Total_Travel_Distance']\n",
    "\n",
    "# # Step 4: Adding Trip Count and Average Trip Distance\n",
    "\n",
    "# # Calculate the number of trips for each team\n",
    "# trip_count = merged_data[merged_data['Travel_Flag'] == 1].groupby('Away_Team').size().reset_index(name='Trip_Count')\n",
    "\n",
    "# # Merge trip count with travel distances\n",
    "# team_travel_data = pd.merge(team_travel_distances, trip_count, left_on='Team', right_on='Away_Team', how='left').drop(columns='Away_Team')\n",
    "\n",
    "# # Calculate average trip distance\n",
    "# team_travel_data['Average_Trip_Distance'] = team_travel_data['Total_Travel_Distance'] / team_travel_data['Trip_Count']\n",
    "\n",
    "# # Display the top 5 teams with the highest average trip distance\n",
    "# team_travel_data = team_travel_data.sort_values(by='Average_Trip_Distance', ascending=False)\n",
    "# team_travel_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find The Closest Other Team to Each team and Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "import pandas as pd\n",
    "\n",
    "# Helper function to calculate the distance between two points (lat, lon)\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    if pd.notnull(lat1) and pd.notnull(lon1) and pd.notnull(lat2) and pd.notnull(lon2):\n",
    "        return geodesic((lat1, lon1), (lat2, lon2)).miles\n",
    "    else:\n",
    "        return None  # Return None if any coordinates are missing\n",
    "\n",
    "# Function to find the closest team to a specific team in the arena data\n",
    "def find_closest_team(current_team_row, team_data):\n",
    "    # Initialize variables to store the closest team and distance\n",
    "    closest_team = None\n",
    "    closest_distance = np.inf\n",
    "    \n",
    "    # Iterate over each row in the team data\n",
    "    for _, row in team_data.iterrows():\n",
    "        # Calculate the distance between the current team and the other team\n",
    "        distance = calculate_distance(current_team_row['Latitude'], current_team_row['Longitude'], row['Latitude'], row['Longitude'])\n",
    "        \n",
    "        # Update the closest team if the distance is smaller\n",
    "        if distance is not None and distance < closest_distance:\n",
    "            closest_team = row['Team']\n",
    "            closest_distance = distance\n",
    "    \n",
    "    return closest_team, closest_distance\n",
    "\n",
    "# Find the closest team to each team in the arena data\n",
    "closest_teams = []\n",
    "closest_distances = []\n",
    "\n",
    "# Iterate over each row in the arena data to find the closest team\n",
    "for _, row in arena_data.iterrows():\n",
    "    # Exclude the current team from the comparison\n",
    "    other_teams = arena_data[arena_data['Team'] != row['Team']]\n",
    "    closest_team, closest_distance = find_closest_team(row, other_teams)\n",
    "    \n",
    "    closest_teams.append(closest_team)\n",
    "    closest_distances.append(closest_distance)\n",
    "\n",
    "# Add the closest team and distance to the arena data\n",
    "arena_data['Closest_Team'] = closest_teams\n",
    "arena_data['Closest_Distance'] = closest_distances\n",
    "\n",
    "# Merge the closest team data with the team travel data\n",
    "team_travel_data = team_travel_data.merge(arena_data[['Team', 'Closest_Team', 'Closest_Distance']], on='Team', how='left')\n",
    "\n",
    "# Sort by closest distance to another team\n",
    "team_travel_data = team_travel_data.sort_values(by='Closest_Distance')\n",
    "\n",
    "# Display the top 5 teams with the highest average trip distance and closest team information\n",
    "# team_travel_data.tail(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add The neutral site data to the aggrigated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REFACTOR\n",
    "\n",
    "# Group by team to calculate total neutral site distances and count neutral site games\n",
    "\n",
    "neutral_site_games_agg = neutral_site_games_agg_1.groupby('Team').agg({'N_Distance': 'sum', 'Game_ID': 'nunique'}).reset_index()\n",
    "neutral_site_games_agg.rename(columns={'Game_ID': 'Neutral_Site_Trips'}, inplace=True)\n",
    "\n",
    "# Merge the neutral site data (distances and game counts) with the team travel data\n",
    "team_travel_data_refactored = pd.merge(team_travel_data, neutral_site_games_agg, on='Team', how='left')\n",
    "\n",
    "# Fill missing values for teams without neutral site games\n",
    "team_travel_data_refactored['N_Distance'] = team_travel_data_refactored['N_Distance'].fillna(0)\n",
    "team_travel_data_refactored['Neutral_Site_Trips'] = team_travel_data_refactored['Neutral_Site_Trips'].fillna(0)\n",
    "\n",
    "# Calculate regular trip stats (excluding neutral site games)\n",
    "team_travel_data_refactored['Reg_Distance'] = team_travel_data_refactored['Total_Travel_Distance']\n",
    "team_travel_data_refactored['Reg_Trips'] = team_travel_data_refactored['Trip_Count']\n",
    "team_travel_data_refactored['Reg_AVG'] = team_travel_data_refactored['Reg_Distance'] / team_travel_data_refactored['Reg_Trips']\n",
    "\n",
    "# Calculate total distance and average with neutral site trips included\n",
    "team_travel_data_refactored['Total_Distance'] = team_travel_data_refactored['Reg_Distance'] + team_travel_data_refactored['N_Distance']\n",
    "team_travel_data_refactored['N_AVG'] = team_travel_data_refactored['N_Distance'] / team_travel_data_refactored['Neutral_Site_Trips']\n",
    "team_travel_data_refactored['Overall_AVG'] = team_travel_data_refactored['Total_Distance'] / (team_travel_data_refactored['Reg_Trips'] + team_travel_data_refactored['Neutral_Site_Trips'])\n",
    "\n",
    "# Select and reorder the columns\n",
    "team_travel_data_refactored = team_travel_data_refactored[[\n",
    "    'Team', \n",
    "    'Reg_Distance', \n",
    "    'Reg_Trips', \n",
    "    'Reg_AVG', \n",
    "    'N_Distance', \n",
    "    'Neutral_Site_Trips', \n",
    "    'N_AVG', \n",
    "    'Total_Distance', \n",
    "    'Overall_AVG'\n",
    "]]\n",
    "\n",
    "# Add the Closest Team and CTeam_Distance columns back at the end of the table\n",
    "team_travel_data_refactored = pd.merge(team_travel_data_refactored, \n",
    "                                       team_travel_data[['Team', 'Closest_Team', 'Closest_Distance']], \n",
    "                                       on='Team', how='left')\n",
    "\n",
    "# Reorder the columns to place Closest Team and CTeam_Distance at the end\n",
    "team_travel_data_refactored = team_travel_data_refactored[[\n",
    "    'Team', \n",
    "    'Reg_Distance', \n",
    "    'Reg_Trips', \n",
    "    'Reg_AVG', \n",
    "    'N_Distance', \n",
    "    'Neutral_Site_Trips', \n",
    "    'N_AVG', \n",
    "    'Total_Distance', \n",
    "    'Overall_AVG', \n",
    "    'Closest_Team', \n",
    "    'Closest_Distance'\n",
    "]]\n",
    "\n",
    "# Drop rows with 0 regular travel distance\n",
    "team_travel_data = team_travel_data_refactored[team_travel_data_refactored['Reg_Distance'] != 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find How many times each team plays their closest rival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename Schedule dataframe\n",
    "\n",
    "df_schedule = schedule_data.copy()\n",
    "\n",
    "# Remove Exhibition games from schedule\n",
    "df_schedule = df_schedule[df_schedule['Conference'] != 'Exhibition']\n",
    "\n",
    "\n",
    "# Match the teams in the schedule with their closest team from the travel distance data\n",
    "# Extract the teams from the schedule and cross-check against the closest team\n",
    "\n",
    "# Merging schedule data with closest team info for both home and away teams\n",
    "df_schedule_merged = schedule_data.merge(\n",
    "    team_travel_data[['Team', 'Closest_Team']],\n",
    "    left_on='Home_Team',\n",
    "    right_on='Team',\n",
    "    how='left',\n",
    "    suffixes=('', '_Closest_Home')\n",
    ")\n",
    "\n",
    "df_schedule_merged.rename(columns={'Closest_Team': 'Closest_Team_Home'}, inplace=True)\n",
    "\n",
    "df_schedule_merged = df_schedule_merged.merge(\n",
    "    team_travel_data[['Team', 'Closest_Team']],\n",
    "    left_on='Away_Team',\n",
    "    right_on='Team',\n",
    "    how='left',\n",
    "    suffixes=('', '_Closest_Away')\n",
    ")\n",
    "\n",
    "df_schedule_merged.rename(columns={'Closest_Team': 'Closest_Team_Away'}, inplace=True)\n",
    "\n",
    "# Now, let's ensure both teams (home and away) are being compared properly\n",
    "df_schedule_merged['Home_vs_Closest'] = df_schedule_merged['Away_Team'] == df_schedule_merged['Closest_Team_Home']\n",
    "df_schedule_merged['Away_vs_Closest'] = df_schedule_merged['Home_Team'] == df_schedule_merged['Closest_Team_Away']\n",
    "\n",
    "# Count how many times each team plays its closest opponent as either home or away\n",
    "df_closest_match_count_home = df_schedule_merged.groupby('Home_Team').agg({\n",
    "    'Home_vs_Closest': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "df_closest_match_count_away = df_schedule_merged.groupby('Away_Team').agg({\n",
    "    'Away_vs_Closest': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Merge both home and away counts to ensure consistency for both teams\n",
    "df_closest_match_total = pd.merge(\n",
    "    df_closest_match_count_home, \n",
    "    df_closest_match_count_away, \n",
    "    left_on='Home_Team', \n",
    "    right_on='Away_Team', \n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Replace missing values with 0 before summing up\n",
    "df_closest_match_total['Home_vs_Closest'].fillna(0, inplace=True)\n",
    "df_closest_match_total['Away_vs_Closest'].fillna(0, inplace=True)\n",
    "\n",
    "# Calculate the total closest matches by summing up both columns\n",
    "df_closest_match_total['Total_Closest_Matches'] = df_closest_match_total['Home_vs_Closest'] + df_closest_match_total['Away_vs_Closest']\n",
    "\n",
    "# Rename columns for clarity and drop unneeded ones\n",
    "df_closest_match_total = df_closest_match_total[['Home_Team', 'Total_Closest_Matches']].rename(columns={'Home_Team': 'Team'})\n",
    "\n",
    "# Merge this back into the travel data\n",
    "team_travel_data_final = team_travel_data.merge(\n",
    "    df_closest_match_total[['Team', 'Total_Closest_Matches']],\n",
    "    on='Team',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values with 0\n",
    "team_travel_data_final['Total_Closest_Matches'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# # Merge the schedule with the closest team data for both home and away teams\n",
    "# df_schedule_merged = df_schedule.merge(team_travel_data[['Team', 'Closest_Team']], \n",
    "#                                        left_on='Home_Team', right_on='Team', how='left')\n",
    "\n",
    "# # Now, let's check how many games each team plays against their closest team (both home and away)\n",
    "# df_schedule_merged['Home_vs_Closest'] = df_schedule_merged['Away_Team'] == df_schedule_merged['Closest_Team']\n",
    "\n",
    "# # Do the same for the away teams\n",
    "# df_schedule_merged = df_schedule_merged.merge(team_travel_data[['Team', 'Closest_Team']], \n",
    "#                                               left_on='Away_Team', right_on='Team', how='left', suffixes=('_home', '_away'))\n",
    "\n",
    "# df_schedule_merged['Away_vs_Closest'] = df_schedule_merged['Home_Team'] == df_schedule_merged['Closest_Team_away']\n",
    "\n",
    "# # Now count how many times each team plays against their closest team, either as home or away\n",
    "# df_closest_match_count = df_schedule_merged.groupby('Team_home').agg({\n",
    "#     'Home_vs_Closest': 'sum',\n",
    "#     'Away_vs_Closest': 'sum'\n",
    "# }).reset_index()\n",
    "\n",
    "# df_closest_match_count['Total_Closest_Matches'] = df_closest_match_count['Home_vs_Closest'] + df_closest_match_count['Away_vs_Closest']\n",
    "\n",
    "# # Merge this back into the original travel data\n",
    "# team_travel_data = team_travel_data.merge(df_closest_match_count[['Team_home', 'Total_Closest_Matches']],\n",
    "#                                           left_on='Team', right_on='Team_home', how='left').drop(columns=['Team_home'])\n",
    "\n",
    "team_travel_data_final.head()\n",
    "\n",
    "## OUTPUT TO TEMP DIRECTORY\n",
    "output_path = os.path.join('..', 'TEMP', 'team_travel_data_test_new_v3.csv')\n",
    "team_travel_data_final.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team_travel_data_expanded_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Each Teams Longest Trip of the Year\n",
    "- and add to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For regular season games, capture Away team, Home team, and distance\n",
    "away_team_info = schedule_w_distance[schedule_w_distance['Travel_Flag'] == 1][['Away_Team', 'Home_Team', 'Distance_Miles']]\n",
    "away_team_info['Game_Type'] = 'Regular'\n",
    "\n",
    "# For neutral site games, capture both teams and distance, along with the Game_Type\n",
    "neutral_team_info = neutral_site_games_agg_1[['Game_ID', 'Team', 'N_Distance']]\n",
    "\n",
    "# Create a dataframe with both Team 1 and Team 2 as opponents for neutral site games\n",
    "neutral_team_info['Opponent'] = neutral_team_info['Game_ID'].str.split('_').str[2]  # Assuming the other team is in the Game_ID\n",
    "\n",
    "# Duplicate rows to handle both teams in neutral site games\n",
    "neutral_team_info_team1 = neutral_team_info[['Game_ID', 'Team', 'Opponent', 'N_Distance']].rename(columns={'N_Distance': 'Distance'})\n",
    "neutral_team_info_team2 = neutral_team_info[['Game_ID', 'Opponent', 'Team', 'N_Distance']].rename(columns={'N_Distance': 'Distance', 'Opponent': 'Team', 'Team': 'Opponent'})\n",
    "\n",
    "# Combine both team datasets for neutral site games\n",
    "neutral_combined = pd.concat([neutral_team_info_team1, neutral_team_info_team2])\n",
    "neutral_combined['Game_Type'] = 'Neutral'\n",
    "\n",
    "# Regular season away games: Home_Team is the opponent\n",
    "away_team_info = away_team_info.rename(columns={'Away_Team': 'Team', 'Home_Team': 'Opponent', 'Distance_Miles': 'Distance'})\n",
    "\n",
    "# Combine both datasets (regular season and neutral site games)\n",
    "combined_info = pd.concat([away_team_info[['Team', 'Opponent', 'Distance', 'Game_Type']], \n",
    "                           neutral_combined[['Team', 'Opponent', 'Distance', 'Game_Type']]])\n",
    "\n",
    "# Clean the combined dataset by dropping rows with missing values in 'Team' or 'Distance'\n",
    "combined_info_cleaned = combined_info.dropna(subset=['Team', 'Distance'])\n",
    "\n",
    "# **Hotfix: Filter out games where the distance is 0**\n",
    "combined_info_cleaned = combined_info_cleaned[combined_info_cleaned['Distance'] > 0]\n",
    "\n",
    "## If Both Team and Opponent match drop the row\n",
    "combined_info_cleaned = combined_info_cleaned[combined_info_cleaned['Team'] != combined_info_cleaned['Opponent']]\n",
    "# Drop any rows with a /\n",
    "combined_info_cleaned = combined_info_cleaned[~combined_info_cleaned['Opponent'].str.contains('/')]\n",
    "combined_info_cleaned = combined_info_cleaned[~combined_info_cleaned['Team'].str.contains('/')]\n",
    "\n",
    "# Now find the longest trip for each team, including the opponent and game type\n",
    "longest_trip_info_cleaned = combined_info_cleaned.loc[combined_info_cleaned.groupby('Team')['Distance'].idxmax()].reset_index(drop=True)\n",
    "\n",
    "# Merge the cleaned longest trip information back into the team_travel_data\n",
    "team_travel_data_expanded_cleaned = pd.merge(team_travel_data_final, longest_trip_info_cleaned, on='Team', how='left')\n",
    "\n",
    "# Drop the duplicate rows that were created\n",
    "team_travel_data_expanded_cleaned = team_travel_data_expanded_cleaned.drop_duplicates(subset=['Team'])\n",
    "# Reindex the DataFrame\n",
    "team_travel_data_expanded_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# team_travel_data_expanded_cleaned.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Distance\n",
    "\n",
    "team_travel_data_expanded_cleaned.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added data clean and transform steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some added transformation steps\n",
    "# Fill Nan Values with 0\n",
    "team_travel_data_expanded_cleaned = team_travel_data_expanded_cleaned.fillna(0)\n",
    "\n",
    "# Set Neutral Site Trips to integer\n",
    "team_travel_data_expanded_cleaned['Neutral_Site_Trips'] = team_travel_data_expanded_cleaned['Neutral_Site_Trips'].astype(int)\n",
    "team_travel_data_expanded_cleaned['Total_Closest_Matches'] = team_travel_data_expanded_cleaned['Total_Closest_Matches'].astype(int)\n",
    "\n",
    "# Round the floats to 2 decimal places\n",
    "team_travel_data_expanded_cleaned = team_travel_data_expanded_cleaned.round({'Reg_Distance': 2, 'Reg_Trips': 2, 'Reg_AVG': 2,\n",
    "                                                                          'N_Distance': 2, 'Neutral_Site_Trips': 2, 'N_AVG': 2,\n",
    "                                                                          'Total_Distance': 2, 'Overall_AVG': 2, 'Closest_Distance': 2,\n",
    "                                                                          'Total_Closest_Matches': 2, 'Distance': 2})\n",
    "\n",
    "## Rename some Columns\n",
    "# Opponent to Longest_Trip_Opponent\n",
    "# Distance_Longest_Trip\n",
    "# Game_Type to Game_Type_Longest_Trip\n",
    "team_travel_data_expanded_cleaned = team_travel_data_expanded_cleaned.rename(columns={'Opponent': 'Longest_Trip_Opponent',\n",
    "                                                                                    'Distance': 'Distance_Longest_Trip',\n",
    "                                                                                    'Game_Type': 'Game_Type_Longest_Trip'})\n",
    "\n",
    "# Display The Resulting DataFrame\n",
    "team_travel_data_expanded_cleaned.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output the Final Table to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEMP FOLDER Output\n",
    "# output_path = os.path.join('..', 'TEMP', 'FINAL_OUT_team_travel_data_v2.csv')\n",
    "# team_travel_data_expanded_cleaned.to_csv(output_path, index=False)\n",
    "# print(f\"Output saved to: {output_path}\")\n",
    "\n",
    "import datetime\n",
    "# create simple string of data (ex. 9/1/2022)\n",
    "date = datetime.datetime.now().strftime(\"%m-%d-%Y\")\n",
    "\n",
    "# print(date)\n",
    "# OUTPUT INTO DATA OUTPUT FOLDER\n",
    "output_path = os.path.join('..', 'data', 'output', f'Team_Travel_Information_v2_{date}.csv')\n",
    "team_travel_data_expanded_cleaned.to_csv(output_path, index=False)\n",
    "print(f\"Output saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING\n",
    "## Check Against Roster File\n",
    "- check number of teams against number that appear in roster\n",
    "- list teams missing form distance table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD ROSTER DATA\n",
    "roster_path = os.path.join('..', 'data', 'roster_2024_current_v3.csv')\n",
    "roster_data = pd.read_csv(roster_path)\n",
    "\n",
    "# Display the data\n",
    "roster_data.head()\n",
    "\n",
    "# get list of unique teams\n",
    "teams_travel = team_travel_data_expanded_cleaned['Team'].unique() # FROM TRAVEL TABLE\n",
    "teams_roster = roster_data['Current Team'].unique() # FROM ROSTER TABLE\n",
    "\n",
    "# Print Report - length of lists and missing teams\n",
    "print(f\"Number of teams in travel data: {len(teams_travel)}\")\n",
    "print(f\"Number of teams in roster data: {len(teams_roster)}\")\n",
    "print('----------------------------------------------------------------\\n')\n",
    "print(\"Teams in travel data but not in roster data:\")\n",
    "print(set(teams_travel) - set(teams_roster))\n",
    "print('----------------------------------------------------------------\\n')\n",
    "print(\"Teams in roster data but not in travel data:\")\n",
    "print(set(teams_roster) - set(teams_travel))\n",
    "\n",
    "\n",
    "\n",
    "missing_teams = set(teams_travel) - set(teams_roster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
