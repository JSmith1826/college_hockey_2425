{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Notebook\n",
    "### Calculate the distance each team will need to travel over the course of the season\n",
    "\n",
    "#### Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy\n",
    "from geopy.distance import geodesic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paths to source data\n",
    "# SCHEDULE FILE\n",
    "schedule_path = os.path.join('..', 'data', 'schedule', '2024_current.csv')\n",
    "schedule_data = pd.read_csv(schedule_path)\n",
    "# ARENA INFO FILE\n",
    "arena_path = os.path.join('..', 'data', 'arena_school_info.csv')\n",
    "arena_data = pd.read_csv(arena_path)\n",
    "\n",
    "# NEUTRAL SITE ARENA INFORMATION FILE\n",
    "neutral_path = os.path.join('..', 'data', 'neutral_arenas_2024.csv')\n",
    "neutral_arenas_df = pd.read_csv(neutral_path)\n",
    "\n",
    "# Display data\n",
    "# schedule_data.head()\n",
    "# schedule_data.tail()\n",
    "# arena_data.head()\n",
    "# neutral_arenas_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Transformation\n",
    "- remove Exhibition games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schedule length before dropping Exhibition games: 1130\n",
      "Schedule length after dropping Exhibition games: 1081\n"
     ]
    }
   ],
   "source": [
    "## Drop Exhibition games from schedule\n",
    "# If 'Exhibition' in Conference column, drop row\n",
    "\n",
    "# Print Schedule length\n",
    "print(f\"Schedule length before dropping Exhibition games: {len(schedule_data)}\")\n",
    "\n",
    "# Drop rows with 'Exhibition' in Conference column\n",
    "schedule_data = schedule_data[schedule_data['Conference'] != 'Exhibition']\n",
    "\n",
    "# Print Schedule length\n",
    "print(f\"Schedule length after dropping Exhibition games: {len(schedule_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Account for neutral site games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows in the schedule table that involve neutral site games\n",
    "# by checking if the 'Conference' or 'Game_Notes' contains a match with the 'Flag' in the neutral arenas table.\n",
    "\n",
    "# Helper function to find if any flag appears in the Conference or Game_Notes columns\n",
    "def is_neutral_game(row, flags):\n",
    "    # Check for flags in both Conference and Game_Notes, ensuring correct handling of NaN\n",
    "    conference_match = any(flag in str(row['Conference']) for flag in flags)\n",
    "    notes_match = any(flag in str(row['Game_Notes']) for flag in flags)\n",
    "    return conference_match or notes_match\n",
    "\n",
    "# Extract the list of flags from the neutral arenas table (assuming already loaded neutral_arenas_df)\n",
    "neutral_flags = neutral_arenas_df['Flag'].tolist()\n",
    "\n",
    "# Apply the function to the schedule data to identify neutral site games\n",
    "schedule_data['Is_Neutral_Game'] = schedule_data.apply(is_neutral_game, axis=1, flags=neutral_flags)\n",
    "\n",
    "# Filter the schedule for neutral site games\n",
    "neutral_site_games = schedule_data[schedule_data['Is_Neutral_Game']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the distance to neutral site locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### refactor the code to include the distance between the two teams\n",
    "\n",
    "\n",
    "# Helper function to calculate the distance between two points (lat, lon)\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    if pd.notnull(lat1) and pd.notnull(lon1) and pd.notnull(lat2) and pd.notnull(lon2):\n",
    "        return geodesic((lat1, lon1), (lat2, lon2)).miles\n",
    "    else:\n",
    "        return None  # Return None if any coordinates are missing\n",
    "\n",
    "# Function to merge team location data and neutral arenas\n",
    "def merge_team_and_arena_data(schedule_df, team_df, arena_df):\n",
    "    # Merge team locations (away and home teams)\n",
    "    schedule_df = schedule_df.merge(\n",
    "        team_df[['Team', 'Latitude', 'Longitude']], \n",
    "        left_on='Away_Team', right_on='Team', how='left', suffixes=('', '_away')\n",
    "    )\n",
    "    schedule_df = schedule_df.merge(\n",
    "        team_df[['Team', 'Latitude', 'Longitude']], \n",
    "        left_on='Home_Team', right_on='Team', how='left', suffixes=('', '_home')\n",
    "    )\n",
    "\n",
    "    # Merge on 'Conference' column first\n",
    "    schedule_df = schedule_df.merge(\n",
    "        arena_df[['Flag', 'latitude', 'longitude']], \n",
    "        left_on='Conference', right_on='Flag', how='left'\n",
    "    )\n",
    "\n",
    "    # Handle rows where the Conference merge did not work by checking 'Game_Notes'\n",
    "    missing_coords_df = schedule_df[schedule_df['latitude'].isnull()].copy()\n",
    "\n",
    "    def match_flag_in_game_notes(row, arena_df):\n",
    "        for _, flag_row in arena_df.iterrows():\n",
    "            if flag_row['Flag'] in str(row['Game_Notes']):\n",
    "                return flag_row['latitude'], flag_row['longitude']\n",
    "        return None, None\n",
    "\n",
    "    # Apply partial matching function for missing coordinates\n",
    "    missing_coords_df[['latitude', 'longitude']] = missing_coords_df.apply(\n",
    "        lambda row: match_flag_in_game_notes(row, arena_df), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "\n",
    "    # Fill missing latitude/longitude\n",
    "    schedule_df.loc[schedule_df['latitude'].isnull(), ['latitude', 'longitude']] = missing_coords_df[['latitude', 'longitude']]\n",
    "\n",
    "    return schedule_df\n",
    "\n",
    "# Output results\n",
    "# output_path = '../TEMP/neutral_site_games_distances_TEST2.csv'\n",
    "# neutral_site_games.to_csv(output_path, index=False)\n",
    "\n",
    "## PRINT DF INFOR BEFORE THE CLEANING\n",
    "# print(neutral_site_games.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CLEANING BASED ON LOOK AT OUTPUT FROM CELL ABOVE\n",
    "\n",
    "\n",
    "# Remove Rows that have TBD or a / in one of the team columns\n",
    "neutral_site_games = neutral_site_games[~neutral_site_games['Home_Team'].str.contains('/')]\n",
    "neutral_site_games = neutral_site_games[~neutral_site_games['Away_Team'].str.contains('/')]\n",
    "neutral_site_games = neutral_site_games[~neutral_site_games['Home_Team'].str.contains('TBD')]\n",
    "neutral_site_games = neutral_site_games[~neutral_site_games['Away_Team'].str.contains('TBD')]\n",
    "\n",
    "# Print DF INFO AFTER CLEANING\n",
    "# print(neutral_site_games.info())\n",
    "\n",
    "# OUTPUT CSV FOR CHECKING INTO TEMP FOLDER\n",
    "# output_path = '../TEMP/neutral_site_games.csv'\n",
    "# neutral_site_games.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neutral_site_games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New Approach - create a new table and structure for the neutral site games - add them to the agg count at the end\n",
    "\n",
    "## Assign a location to each game - based on the FLag column from neutral_arenas_df\n",
    "\n",
    "# Drop the columns that are not needed\n",
    "neutral_site_games = neutral_site_games.drop(columns=['Away_Team_Link', 'Away_Score', 'Home_Team_Link', 'Home_Score', 'OT', 'Box_Link', 'Metrics_Link'])\n",
    "\n",
    "# Reinex the DF\n",
    "neutral_site_games.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# If Game_Notes is NaN fill with Conference\n",
    "neutral_site_games['Game_Notes'] = neutral_site_games['Game_Notes'].fillna(neutral_site_games['Conference'])\n",
    "\n",
    "# Assign a location to each game\n",
    "# Look for Game_Notes that contain the Flag from neutral_arenas_df\n",
    "# If there is a match, assign the location to the game\n",
    "\n",
    "# Helper function to assign latitude and longitude to each game\n",
    "def assign_location(row, arena_df):\n",
    "    for _, flag_row in arena_df.iterrows():\n",
    "        if flag_row['Flag'] in str(row['Game_Notes']):\n",
    "            return flag_row['latitude'], flag_row['longitude']\n",
    "    return None, None\n",
    "\n",
    "# Extract the list of flags from the neutral arenas table (assuming already loaded neutral_arenas_df)\n",
    "neutral_flags = neutral_arenas_df['Flag'].tolist()\n",
    "\n",
    "# Apply the function to the schedule data to identify neutral site games\n",
    "neutral_site_games[['latitude', 'longitude']] = neutral_site_games.apply(assign_location, axis=1, arena_df=neutral_arenas_df, result_type=\"expand\")\n",
    "\n",
    "# If Gama_Notes is empty or an empty string, fill with Conference value\n",
    "# neutral_site_games['Game_Notes'] = neutral_site_games['Game_Notes'].replace('', neutral_site_games['Conference']) # NOT WORKING AT ALL - THROWING ERROR\n",
    "# neutral_site_games['Game_Notes'] = neutral_site_games['Game_Notes'].fillna(neutral_site_games['Conference']) # Not working must be empty string not NaN\n",
    "\n",
    "\n",
    "# neutral_site_games.head()\n",
    "# neutral_site_games.tail()\n",
    "# neutral_site_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the distance between the two teams for each game\n",
    "\n",
    "# Helper function to calculate the distance between two points (lat, lon)\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    if pd.notnull(lat1) and pd.notnull(lon1) and pd.notnull(lat2) and pd.notnull(lon2):\n",
    "        return geodesic((lat1, lon1), (lat2, lon2)).miles\n",
    "    else:\n",
    "        return None  # Return None if any coordinates are missing\n",
    "\n",
    "# Function to calculate distances to neutral site\n",
    "def calculate_team_distances(schedule_df):\n",
    "    schedule_df['Away_Distance'] = schedule_df.apply(\n",
    "        lambda row: calculate_distance(row['Latitude'], row['Longitude'], row['latitude'], row['longitude']), axis=1\n",
    "    )\n",
    "    schedule_df['Home_Distance'] = schedule_df.apply(\n",
    "        lambda row: calculate_distance(row['Latitude_home'], row['Longitude_home'], row['latitude'], row['longitude']), axis=1\n",
    "    )\n",
    "\n",
    "    return schedule_df\n",
    "\n",
    "# Refactor into steps\n",
    "neutral_site_games = merge_team_and_arena_data(schedule_data, arena_data, neutral_arenas_df)\n",
    "neutral_site_games = calculate_team_distances(neutral_site_games)\n",
    "\n",
    "# Filter out rows with missing distances\n",
    "neutral_site_games = neutral_site_games.dropna(subset=['Away_Distance', 'Home_Distance'])\n",
    "\n",
    "\n",
    "# Output results\n",
    "# output_path = '../TEMP/neutral_site_games_distances_TESTv3.csv'\n",
    "# neutral_site_games.to_csv(output_path, index=False)\n",
    "\n",
    "# neutral_site_games.head()\n",
    "# neutral_site_games.tail()\n",
    "# neutral_site_games.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbanc\\AppData\\Local\\Temp\\ipykernel_15520\\815556465.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  neutral_site_games_agg_1 = pd.concat([neutral_site_games_agg, pd.DataFrame(rows)], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>Game_Notes</th>\n",
       "      <th>Team</th>\n",
       "      <th>N_Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-11</td>\n",
       "      <td>2024-10-11_Massachusetts_Omaha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Omaha</td>\n",
       "      <td>1093.593499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-11</td>\n",
       "      <td>2024-10-11_Massachusetts_Omaha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>2304.523378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-11</td>\n",
       "      <td>2024-10-11_Air Force_Minnesota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>1302.776665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-11</td>\n",
       "      <td>2024-10-11_Air Force_Minnesota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>600.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-12</td>\n",
       "      <td>2024-10-12_North Dakota_Providence</td>\n",
       "      <td>US Hockey Hall of Fame game</td>\n",
       "      <td>Providence</td>\n",
       "      <td>1319.532097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                             Game_ID  \\\n",
       "0  2024-10-11      2024-10-11_Massachusetts_Omaha   \n",
       "1  2024-10-11      2024-10-11_Massachusetts_Omaha   \n",
       "2  2024-10-11      2024-10-11_Air Force_Minnesota   \n",
       "3  2024-10-11      2024-10-11_Air Force_Minnesota   \n",
       "4  2024-10-12  2024-10-12_North Dakota_Providence   \n",
       "\n",
       "                    Game_Notes           Team   N_Distance  \n",
       "0                          NaN          Omaha  1093.593499  \n",
       "1                          NaN  Massachusetts  2304.523378  \n",
       "2                          NaN      Minnesota  1302.776665  \n",
       "3                          NaN      Air Force   600.521127  \n",
       "4  US Hockey Hall of Fame game     Providence  1319.532097  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DESIRED OUTPUT\n",
    "# Date, Game_ID, Game_Notes, Team, Distance for each team in each game\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "neutral_site_games_agg = pd.DataFrame(columns=['Date', 'Game_ID', 'Game_Notes', 'Team', 'N_Distance'])\n",
    "\n",
    "# Iterate through the neutral_site_games DataFrame and add the data to the new DataFrame\n",
    "rows = []  # Use a list to accumulate rows for better performance\n",
    "for index, row in neutral_site_games.iterrows():\n",
    "    # Add the Away Team data\n",
    "    rows.append({\n",
    "        'Date': row['Date'],\n",
    "        'Game_ID': row['Game_ID'],\n",
    "        'Game_Notes': row['Game_Notes'],\n",
    "        'Team': row['Away_Team'],\n",
    "        'N_Distance': row['Away_Distance']\n",
    "    })\n",
    "    \n",
    "    # Add the Home Team data\n",
    "    rows.append({\n",
    "        'Date': row['Date'],\n",
    "        'Game_ID': row['Game_ID'],\n",
    "        'Game_Notes': row['Game_Notes'],\n",
    "        'Team': row['Home_Team'],\n",
    "        'N_Distance': row['Home_Distance']\n",
    "    })\n",
    "\n",
    "# Convert the list of rows into a DataFrame and concatenate\n",
    "neutral_site_games_agg_1 = pd.concat([neutral_site_games_agg, pd.DataFrame(rows)], ignore_index=True)\n",
    "\n",
    "# Output results\n",
    "output_path = '../TEMP/neutral_site_games_agg.csv'\n",
    "neutral_site_games_agg_1.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the first and last few rows of the DataFrame\n",
    "neutral_site_games_agg_1.head()\n",
    "# neutral_site_games_agg_1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NON NEUTRAL GAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the schedule data with the arena data to include home and away team locations\n",
    "\n",
    "# First, ensure team names match between datasets\n",
    "# We will merge on the 'Team' column in the arena data and 'Home_Team'/'Away_Team' in the schedule data\n",
    "merged_data = schedule_data.merge(arena_data[['Team', 'Latitude', 'Longitude']], left_on='Home_Team', right_on='Team', how='left')\n",
    "merged_data = merged_data.rename(columns={'Latitude': 'Home_Latitude', 'Longitude': 'Home_Longitude'})\n",
    "\n",
    "# Merge again for the away teams\n",
    "merged_data = merged_data.merge(arena_data[['Team', 'Latitude', 'Longitude']], left_on='Away_Team', right_on='Team', how='left')\n",
    "merged_data = merged_data.rename(columns={'Latitude': 'Away_Latitude', 'Longitude': 'Away_Longitude'})\n",
    "\n",
    "# Drop the unnecessary 'Team' columns from the merged data\n",
    "merged_data = merged_data.drop(columns=['Team_x', 'Team_y'])\n",
    "\n",
    "# Display the first few rows of the merged data to verify the result\n",
    "# merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the distance between each school\n",
    "- Using Haversine equation to calculate the straight line distance between two sets of lat/lon coodinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>Away_Team</th>\n",
       "      <th>Distance_Miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>Michigan State</td>\n",
       "      <td>259.792866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>Minnesota State</td>\n",
       "      <td>534.090775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>Arizona State</td>\n",
       "      <td>548.654698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Union</td>\n",
       "      <td>Providence</td>\n",
       "      <td>144.151530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boston University</td>\n",
       "      <td>Holy Cross</td>\n",
       "      <td>36.229678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Home_Team        Away_Team  Distance_Miles\n",
       "0      Lake Superior   Michigan State      259.792866\n",
       "1           Michigan  Minnesota State      534.090775\n",
       "2          Air Force    Arizona State      548.654698\n",
       "3              Union       Providence      144.151530\n",
       "4  Boston University       Holy Cross       36.229678"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## VERSION 2 USING GEOPY\n",
    "# Function to calculate distance with NaN check\n",
    "def calculate_distance(row):\n",
    "    # Check for NaN values in lat/long coordinates\n",
    "    if (np.isnan(row['Home_Latitude']) or np.isnan(row['Home_Longitude']) or\n",
    "        np.isnan(row['Away_Latitude']) or np.isnan(row['Away_Longitude'])):\n",
    "        return np.nan  # Return NaN if any of the coordinates are missing\n",
    "    else:\n",
    "        # Calculate the distance if all coordinates are present\n",
    "        return geodesic((row['Home_Latitude'], row['Home_Longitude']), \n",
    "                        (row['Away_Latitude'], row['Away_Longitude'])).miles\n",
    "\n",
    "# Apply the function to calculate the distance between the home and away arenas\n",
    "merged_data['Distance_Miles'] = merged_data.apply(calculate_distance, axis=1)\n",
    "\n",
    "# Display the updated data with the calculated distance\n",
    "merged_data[['Home_Team', 'Away_Team', 'Distance_Miles']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out results to avoid double counting games on weekend series\n",
    "\n",
    "- Travel_Flag to account for consecutive games played at the same venue within a 3-day span. If a team plays multiple games at the same venue within this period, travel is only counted for the first game.\n",
    "\n",
    "- The Adjusted_Travel_Distance column reflects the distance a team will travel for each game, considering the consecutive game rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VERSION 2\n",
    "# Update logic to handle non-consecutive rows by grouping first\n",
    "\n",
    "# Convert 'Date' column to datetime format for easier manipulation\n",
    "merged_data['Date'] = pd.to_datetime(merged_data['Date'])\n",
    "\n",
    "# Reset the travel flag\n",
    "merged_data['Travel_Flag'] = 1\n",
    "\n",
    "# Sort the data by 'Away_Team', 'Home_Team', and 'Date' to ensure games are grouped correctly\n",
    "merged_data = merged_data.sort_values(by=['Away_Team', 'Home_Team', 'Date'])\n",
    "\n",
    "# Group by 'Away_Team' and 'Home_Team', then iterate through each group to set the travel flag\n",
    "for (away_team, home_team), group in merged_data.groupby(['Away_Team', 'Home_Team']):\n",
    "    group = group.sort_values(by='Date')  # Sort by date within each group\n",
    "    \n",
    "    # Iterate through the group to check for consecutive games\n",
    "    for i in range(1, len(group)):\n",
    "        current_game = group.iloc[i]\n",
    "        previous_game = group.iloc[i - 1]\n",
    "        \n",
    "        # Check if the games are within 3 days\n",
    "        if (current_game['Date'] - previous_game['Date']).days <= 3:\n",
    "            # Set the travel flag to 0 for the current game\n",
    "            merged_data.loc[current_game.name, 'Travel_Flag'] = 0\n",
    "\n",
    "# Only consider rows where travel flag is 1 for calculating total travel distance\n",
    "merged_data['Adjusted_Travel_Distance'] = merged_data['Distance_Miles'] * merged_data['Travel_Flag']\n",
    "\n",
    "# Display the updated data with the travel flag and adjusted distance\n",
    "merged_data[['Away_Team', 'Home_Team', 'Date', 'Distance_Miles', 'Travel_Flag', 'Adjusted_Travel_Distance']].head()\n",
    "\n",
    "# OUTPUT TABLE TO TEMP FILE FOR TESTING\n",
    "output_path = os.path.join('..', 'TEMP', 'schedule_w_distance.csv')\n",
    "merged_data.to_csv(output_path, index=False)\n",
    "\n",
    "schedule_w_distance = merged_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Total Travel Distance for Each Team AND\n",
    "## Calculate and store the Trip Count and the Average trip distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Total_Travel_Distance</th>\n",
       "      <th>Trip_Count</th>\n",
       "      <th>Average_Trip_Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>25759.663688</td>\n",
       "      <td>12</td>\n",
       "      <td>2146.638641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>9555.349393</td>\n",
       "      <td>9</td>\n",
       "      <td>1061.705488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arizona State</td>\n",
       "      <td>8102.296536</td>\n",
       "      <td>9</td>\n",
       "      <td>900.255171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Penn State</td>\n",
       "      <td>6464.519475</td>\n",
       "      <td>9</td>\n",
       "      <td>718.279942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Denver</td>\n",
       "      <td>7047.934161</td>\n",
       "      <td>10</td>\n",
       "      <td>704.793416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Team  Total_Travel_Distance  Trip_Count  Average_Trip_Distance\n",
       "1          Alaska           25759.663688          12            2146.638641\n",
       "0       Air Force            9555.349393           9            1061.705488\n",
       "4   Arizona State            8102.296536           9             900.255171\n",
       "54     Penn State            6464.519475           9             718.279942\n",
       "23         Denver            7047.934161          10             704.793416"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only consider rows where travel flag is 1 for calculating total travel distance\n",
    "merged_data['Adjusted_Travel_Distance'] = merged_data['Distance_Miles'] * merged_data['Travel_Flag']\n",
    "\n",
    "# Calculate the total travel distance per team\n",
    "team_travel_distances = merged_data.groupby('Away_Team')['Adjusted_Travel_Distance'].sum().reset_index()\n",
    "team_travel_distances.columns = ['Team', 'Total_Travel_Distance']\n",
    "\n",
    "# Step 4: Adding Trip Count and Average Trip Distance\n",
    "\n",
    "# Calculate the number of trips for each team\n",
    "trip_count = merged_data[merged_data['Travel_Flag'] == 1].groupby('Away_Team').size().reset_index(name='Trip_Count')\n",
    "\n",
    "# Merge trip count with travel distances\n",
    "team_travel_data = pd.merge(team_travel_distances, trip_count, left_on='Team', right_on='Away_Team', how='left').drop(columns='Away_Team')\n",
    "\n",
    "# Calculate average trip distance\n",
    "team_travel_data['Average_Trip_Distance'] = team_travel_data['Total_Travel_Distance'] / team_travel_data['Trip_Count']\n",
    "\n",
    "# Display the top 5 teams with the highest average trip distance\n",
    "team_travel_data = team_travel_data.sort_values(by='Average_Trip_Distance', ascending=False)\n",
    "team_travel_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find The Closest Other Team to Each team and Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "import pandas as pd\n",
    "\n",
    "# Helper function to calculate the distance between two points (lat, lon)\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    if pd.notnull(lat1) and pd.notnull(lon1) and pd.notnull(lat2) and pd.notnull(lon2):\n",
    "        return geodesic((lat1, lon1), (lat2, lon2)).miles\n",
    "    else:\n",
    "        return None  # Return None if any coordinates are missing\n",
    "\n",
    "# Function to find the closest team to a specific team in the arena data\n",
    "def find_closest_team(current_team_row, team_data):\n",
    "    # Initialize variables to store the closest team and distance\n",
    "    closest_team = None\n",
    "    closest_distance = np.inf\n",
    "    \n",
    "    # Iterate over each row in the team data\n",
    "    for _, row in team_data.iterrows():\n",
    "        # Calculate the distance between the current team and the other team\n",
    "        distance = calculate_distance(current_team_row['Latitude'], current_team_row['Longitude'], row['Latitude'], row['Longitude'])\n",
    "        \n",
    "        # Update the closest team if the distance is smaller\n",
    "        if distance is not None and distance < closest_distance:\n",
    "            closest_team = row['Team']\n",
    "            closest_distance = distance\n",
    "    \n",
    "    return closest_team, closest_distance\n",
    "\n",
    "# Find the closest team to each team in the arena data\n",
    "closest_teams = []\n",
    "closest_distances = []\n",
    "\n",
    "# Iterate over each row in the arena data to find the closest team\n",
    "for _, row in arena_data.iterrows():\n",
    "    # Exclude the current team from the comparison\n",
    "    other_teams = arena_data[arena_data['Team'] != row['Team']]\n",
    "    closest_team, closest_distance = find_closest_team(row, other_teams)\n",
    "    \n",
    "    closest_teams.append(closest_team)\n",
    "    closest_distances.append(closest_distance)\n",
    "\n",
    "# Add the closest team and distance to the arena data\n",
    "arena_data['Closest_Team'] = closest_teams\n",
    "arena_data['Closest_Distance'] = closest_distances\n",
    "\n",
    "# Merge the closest team data with the team travel data\n",
    "team_travel_data = team_travel_data.merge(arena_data[['Team', 'Closest_Team', 'Closest_Distance']], on='Team', how='left')\n",
    "\n",
    "# Sort by closest distance to another team\n",
    "team_travel_data = team_travel_data.sort_values(by='Closest_Distance')\n",
    "\n",
    "# Display the top 5 teams with the highest average trip distance and closest team information\n",
    "# team_travel_data.tail(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add The neutral site data to the aggrigated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REFACTOR\n",
    "\n",
    "# Group by team to calculate total neutral site distances and count neutral site games\n",
    "\n",
    "neutral_site_games_agg = neutral_site_games_agg_1.groupby('Team').agg({'N_Distance': 'sum', 'Game_ID': 'nunique'}).reset_index()\n",
    "neutral_site_games_agg.rename(columns={'Game_ID': 'Neutral_Site_Trips'}, inplace=True)\n",
    "\n",
    "# Merge the neutral site data (distances and game counts) with the team travel data\n",
    "team_travel_data_refactored = pd.merge(team_travel_data, neutral_site_games_agg, on='Team', how='left')\n",
    "\n",
    "# Fill missing values for teams without neutral site games\n",
    "team_travel_data_refactored['N_Distance'] = team_travel_data_refactored['N_Distance'].fillna(0)\n",
    "team_travel_data_refactored['Neutral_Site_Trips'] = team_travel_data_refactored['Neutral_Site_Trips'].fillna(0)\n",
    "\n",
    "# Calculate regular trip stats (excluding neutral site games)\n",
    "team_travel_data_refactored['Reg_Distance'] = team_travel_data_refactored['Total_Travel_Distance']\n",
    "team_travel_data_refactored['Reg_Trips'] = team_travel_data_refactored['Trip_Count']\n",
    "team_travel_data_refactored['Reg_AVG'] = team_travel_data_refactored['Reg_Distance'] / team_travel_data_refactored['Reg_Trips']\n",
    "\n",
    "# Calculate total distance and average with neutral site trips included\n",
    "team_travel_data_refactored['Total_Distance'] = team_travel_data_refactored['Reg_Distance'] + team_travel_data_refactored['N_Distance']\n",
    "team_travel_data_refactored['N_AVG'] = team_travel_data_refactored['N_Distance'] / team_travel_data_refactored['Neutral_Site_Trips']\n",
    "team_travel_data_refactored['Overall_AVG'] = team_travel_data_refactored['Total_Distance'] / (team_travel_data_refactored['Reg_Trips'] + team_travel_data_refactored['Neutral_Site_Trips'])\n",
    "\n",
    "# Select and reorder the columns\n",
    "team_travel_data_refactored = team_travel_data_refactored[[\n",
    "    'Team', \n",
    "    'Reg_Distance', \n",
    "    'Reg_Trips', \n",
    "    'Reg_AVG', \n",
    "    'N_Distance', \n",
    "    'Neutral_Site_Trips', \n",
    "    'N_AVG', \n",
    "    'Total_Distance', \n",
    "    'Overall_AVG'\n",
    "]]\n",
    "\n",
    "# Add the Closest Team and CTeam_Distance columns back at the end of the table\n",
    "team_travel_data_refactored = pd.merge(team_travel_data_refactored, \n",
    "                                       team_travel_data[['Team', 'Closest_Team', 'Closest_Distance']], \n",
    "                                       on='Team', how='left')\n",
    "\n",
    "# Reorder the columns to place Closest Team and CTeam_Distance at the end\n",
    "team_travel_data_refactored = team_travel_data_refactored[[\n",
    "    'Team', \n",
    "    'Reg_Distance', \n",
    "    'Reg_Trips', \n",
    "    'Reg_AVG', \n",
    "    'N_Distance', \n",
    "    'Neutral_Site_Trips', \n",
    "    'N_AVG', \n",
    "    'Total_Distance', \n",
    "    'Overall_AVG', \n",
    "    'Closest_Team', \n",
    "    'Closest_Distance'\n",
    "]]\n",
    "\n",
    "# Drop rows with 0 regular travel distance\n",
    "team_travel_data = team_travel_data_refactored[team_travel_data_refactored['Reg_Distance'] != 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find How many times each team plays their closest rival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbanc\\AppData\\Local\\Temp\\ipykernel_15520\\413263137.py:56: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_closest_match_total['Home_vs_Closest'].fillna(0, inplace=True)\n",
      "C:\\Users\\jbanc\\AppData\\Local\\Temp\\ipykernel_15520\\413263137.py:57: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_closest_match_total['Away_vs_Closest'].fillna(0, inplace=True)\n",
      "C:\\Users\\jbanc\\AppData\\Local\\Temp\\ipykernel_15520\\413263137.py:73: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  team_travel_data_final['Total_Closest_Matches'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## Rename Schedule dataframe\n",
    "\n",
    "df_schedule = schedule_data.copy()\n",
    "\n",
    "# Remove Exhibition games from schedule\n",
    "df_schedule = df_schedule[df_schedule['Conference'] != 'Exhibition']\n",
    "\n",
    "\n",
    "# Match the teams in the schedule with their closest team from the travel distance data\n",
    "# Extract the teams from the schedule and cross-check against the closest team\n",
    "\n",
    "# Merging schedule data with closest team info for both home and away teams\n",
    "df_schedule_merged = schedule_data.merge(\n",
    "    team_travel_data[['Team', 'Closest_Team']],\n",
    "    left_on='Home_Team',\n",
    "    right_on='Team',\n",
    "    how='left',\n",
    "    suffixes=('', '_Closest_Home')\n",
    ")\n",
    "\n",
    "df_schedule_merged.rename(columns={'Closest_Team': 'Closest_Team_Home'}, inplace=True)\n",
    "\n",
    "df_schedule_merged = df_schedule_merged.merge(\n",
    "    team_travel_data[['Team', 'Closest_Team']],\n",
    "    left_on='Away_Team',\n",
    "    right_on='Team',\n",
    "    how='left',\n",
    "    suffixes=('', '_Closest_Away')\n",
    ")\n",
    "\n",
    "df_schedule_merged.rename(columns={'Closest_Team': 'Closest_Team_Away'}, inplace=True)\n",
    "\n",
    "# Now, let's ensure both teams (home and away) are being compared properly\n",
    "df_schedule_merged['Home_vs_Closest'] = df_schedule_merged['Away_Team'] == df_schedule_merged['Closest_Team_Home']\n",
    "df_schedule_merged['Away_vs_Closest'] = df_schedule_merged['Home_Team'] == df_schedule_merged['Closest_Team_Away']\n",
    "\n",
    "# Count how many times each team plays its closest opponent as either home or away\n",
    "df_closest_match_count_home = df_schedule_merged.groupby('Home_Team').agg({\n",
    "    'Home_vs_Closest': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "df_closest_match_count_away = df_schedule_merged.groupby('Away_Team').agg({\n",
    "    'Away_vs_Closest': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Merge both home and away counts to ensure consistency for both teams\n",
    "df_closest_match_total = pd.merge(\n",
    "    df_closest_match_count_home, \n",
    "    df_closest_match_count_away, \n",
    "    left_on='Home_Team', \n",
    "    right_on='Away_Team', \n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Replace missing values with 0 before summing up\n",
    "df_closest_match_total['Home_vs_Closest'].fillna(0, inplace=True)\n",
    "df_closest_match_total['Away_vs_Closest'].fillna(0, inplace=True)\n",
    "\n",
    "# Calculate the total closest matches by summing up both columns\n",
    "df_closest_match_total['Total_Closest_Matches'] = df_closest_match_total['Home_vs_Closest'] + df_closest_match_total['Away_vs_Closest']\n",
    "\n",
    "# Rename columns for clarity and drop unneeded ones\n",
    "df_closest_match_total = df_closest_match_total[['Home_Team', 'Total_Closest_Matches']].rename(columns={'Home_Team': 'Team'})\n",
    "\n",
    "# Merge this back into the travel data\n",
    "team_travel_data_final = team_travel_data.merge(\n",
    "    df_closest_match_total[['Team', 'Total_Closest_Matches']],\n",
    "    on='Team',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values with 0\n",
    "team_travel_data_final['Total_Closest_Matches'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# # Merge the schedule with the closest team data for both home and away teams\n",
    "# df_schedule_merged = df_schedule.merge(team_travel_data[['Team', 'Closest_Team']], \n",
    "#                                        left_on='Home_Team', right_on='Team', how='left')\n",
    "\n",
    "# # Now, let's check how many games each team plays against their closest team (both home and away)\n",
    "# df_schedule_merged['Home_vs_Closest'] = df_schedule_merged['Away_Team'] == df_schedule_merged['Closest_Team']\n",
    "\n",
    "# # Do the same for the away teams\n",
    "# df_schedule_merged = df_schedule_merged.merge(team_travel_data[['Team', 'Closest_Team']], \n",
    "#                                               left_on='Away_Team', right_on='Team', how='left', suffixes=('_home', '_away'))\n",
    "\n",
    "# df_schedule_merged['Away_vs_Closest'] = df_schedule_merged['Home_Team'] == df_schedule_merged['Closest_Team_away']\n",
    "\n",
    "# # Now count how many times each team plays against their closest team, either as home or away\n",
    "# df_closest_match_count = df_schedule_merged.groupby('Team_home').agg({\n",
    "#     'Home_vs_Closest': 'sum',\n",
    "#     'Away_vs_Closest': 'sum'\n",
    "# }).reset_index()\n",
    "\n",
    "# df_closest_match_count['Total_Closest_Matches'] = df_closest_match_count['Home_vs_Closest'] + df_closest_match_count['Away_vs_Closest']\n",
    "\n",
    "# # Merge this back into the original travel data\n",
    "# team_travel_data = team_travel_data.merge(df_closest_match_count[['Team_home', 'Total_Closest_Matches']],\n",
    "#                                           left_on='Team', right_on='Team_home', how='left').drop(columns=['Team_home'])\n",
    "\n",
    "team_travel_data_final.head()\n",
    "\n",
    "## OUTPUT TO TEMP DIRECTORY\n",
    "output_path = os.path.join('..', 'TEMP', 'team_travel_data_test_new_v3.csv')\n",
    "team_travel_data_final.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team_travel_data_expanded_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Each Teams Longest Trip of the Year\n",
    "- and add to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbanc\\AppData\\Local\\Temp\\ipykernel_15520\\702457372.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neutral_team_info['Opponent'] = neutral_team_info['Game_ID'].str.split('_').str[2]  # Assuming the other team is in the Game_ID\n"
     ]
    }
   ],
   "source": [
    "# For regular season games, capture Away team, Home team, and distance\n",
    "away_team_info = schedule_w_distance[schedule_w_distance['Travel_Flag'] == 1][['Away_Team', 'Home_Team', 'Distance_Miles']]\n",
    "away_team_info['Game_Type'] = 'Regular'\n",
    "\n",
    "# For neutral site games, capture both teams and distance, along with the Game_Type\n",
    "neutral_team_info = neutral_site_games_agg_1[['Game_ID', 'Team', 'N_Distance']]\n",
    "\n",
    "# Create a dataframe with both Team 1 and Team 2 as opponents for neutral site games\n",
    "neutral_team_info['Opponent'] = neutral_team_info['Game_ID'].str.split('_').str[2]  # Assuming the other team is in the Game_ID\n",
    "\n",
    "# Duplicate rows to handle both teams in neutral site games\n",
    "neutral_team_info_team1 = neutral_team_info[['Game_ID', 'Team', 'Opponent', 'N_Distance']].rename(columns={'N_Distance': 'Distance'})\n",
    "neutral_team_info_team2 = neutral_team_info[['Game_ID', 'Opponent', 'Team', 'N_Distance']].rename(columns={'N_Distance': 'Distance', 'Opponent': 'Team', 'Team': 'Opponent'})\n",
    "\n",
    "# Combine both team datasets for neutral site games\n",
    "neutral_combined = pd.concat([neutral_team_info_team1, neutral_team_info_team2])\n",
    "neutral_combined['Game_Type'] = 'Neutral'\n",
    "\n",
    "# Regular season away games: Home_Team is the opponent\n",
    "away_team_info = away_team_info.rename(columns={'Away_Team': 'Team', 'Home_Team': 'Opponent', 'Distance_Miles': 'Distance'})\n",
    "\n",
    "# Combine both datasets (regular season and neutral site games)\n",
    "combined_info = pd.concat([away_team_info[['Team', 'Opponent', 'Distance', 'Game_Type']], \n",
    "                           neutral_combined[['Team', 'Opponent', 'Distance', 'Game_Type']]])\n",
    "\n",
    "# Clean the combined dataset by dropping rows with missing values in 'Team' or 'Distance'\n",
    "combined_info_cleaned = combined_info.dropna(subset=['Team', 'Distance'])\n",
    "\n",
    "# **Hotfix: Filter out games where the distance is 0**\n",
    "combined_info_cleaned = combined_info_cleaned[combined_info_cleaned['Distance'] > 0]\n",
    "\n",
    "## If Both Team and Opponent match drop the row\n",
    "combined_info_cleaned = combined_info_cleaned[combined_info_cleaned['Team'] != combined_info_cleaned['Opponent']]\n",
    "# Drop any rows with a /\n",
    "combined_info_cleaned = combined_info_cleaned[~combined_info_cleaned['Opponent'].str.contains('/')]\n",
    "combined_info_cleaned = combined_info_cleaned[~combined_info_cleaned['Team'].str.contains('/')]\n",
    "\n",
    "# Now find the longest trip for each team, including the opponent and game type\n",
    "longest_trip_info_cleaned = combined_info_cleaned.loc[combined_info_cleaned.groupby('Team')['Distance'].idxmax()].reset_index(drop=True)\n",
    "\n",
    "# Merge the cleaned longest trip information back into the team_travel_data\n",
    "team_travel_data_expanded_cleaned = pd.merge(team_travel_data_final, longest_trip_info_cleaned, on='Team', how='left')\n",
    "\n",
    "# Drop the duplicate rows that were created\n",
    "team_travel_data_expanded_cleaned = team_travel_data_expanded_cleaned.drop_duplicates(subset=['Team'])\n",
    "# Reindex the DataFrame\n",
    "team_travel_data_expanded_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# team_travel_data_expanded_cleaned.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Reg_Distance</th>\n",
       "      <th>Reg_Trips</th>\n",
       "      <th>Reg_AVG</th>\n",
       "      <th>N_Distance</th>\n",
       "      <th>Neutral_Site_Trips</th>\n",
       "      <th>N_AVG</th>\n",
       "      <th>Total_Distance</th>\n",
       "      <th>Overall_AVG</th>\n",
       "      <th>Closest_Team</th>\n",
       "      <th>Closest_Distance</th>\n",
       "      <th>Total_Closest_Matches</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Game_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>2495.793588</td>\n",
       "      <td>17</td>\n",
       "      <td>146.811388</td>\n",
       "      <td>2994.249148</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2994.249148</td>\n",
       "      <td>5490.042736</td>\n",
       "      <td>305.002374</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>1.075804</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Notre Dame</td>\n",
       "      <td>3606.351007</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boston University</td>\n",
       "      <td>2092.731396</td>\n",
       "      <td>13</td>\n",
       "      <td>160.979338</td>\n",
       "      <td>2994.604500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2994.604500</td>\n",
       "      <td>5087.335896</td>\n",
       "      <td>363.381135</td>\n",
       "      <td>Harvard</td>\n",
       "      <td>1.075804</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Merrimack</td>\n",
       "      <td>2994.604500</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Northeastern</td>\n",
       "      <td>2610.852411</td>\n",
       "      <td>16</td>\n",
       "      <td>163.178276</td>\n",
       "      <td>111.693419</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.693419</td>\n",
       "      <td>2722.545830</td>\n",
       "      <td>160.149755</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>1.756704</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Denver</td>\n",
       "      <td>1768.308428</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brown</td>\n",
       "      <td>1675.803811</td>\n",
       "      <td>13</td>\n",
       "      <td>128.907985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1675.803811</td>\n",
       "      <td>128.907985</td>\n",
       "      <td>Providence</td>\n",
       "      <td>2.043651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clarkson</td>\n",
       "      <td>267.072502</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Providence</td>\n",
       "      <td>2121.166102</td>\n",
       "      <td>15</td>\n",
       "      <td>141.411073</td>\n",
       "      <td>1666.883994</td>\n",
       "      <td>3.0</td>\n",
       "      <td>555.627998</td>\n",
       "      <td>3788.050096</td>\n",
       "      <td>210.447228</td>\n",
       "      <td>Brown</td>\n",
       "      <td>2.043651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>1319.532097</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Team  Reg_Distance  Reg_Trips     Reg_AVG   N_Distance  \\\n",
       "0            Harvard   2495.793588         17  146.811388  2994.249148   \n",
       "1  Boston University   2092.731396         13  160.979338  2994.604500   \n",
       "2       Northeastern   2610.852411         16  163.178276   111.693419   \n",
       "3              Brown   1675.803811         13  128.907985     0.000000   \n",
       "4         Providence   2121.166102         15  141.411073  1666.883994   \n",
       "\n",
       "   Neutral_Site_Trips        N_AVG  Total_Distance  Overall_AVG  \\\n",
       "0                 1.0  2994.249148     5490.042736   305.002374   \n",
       "1                 1.0  2994.604500     5087.335896   363.381135   \n",
       "2                 1.0   111.693419     2722.545830   160.149755   \n",
       "3                 0.0          NaN     1675.803811   128.907985   \n",
       "4                 3.0   555.627998     3788.050096   210.447228   \n",
       "\n",
       "        Closest_Team  Closest_Distance  Total_Closest_Matches      Opponent  \\\n",
       "0  Boston University          1.075804                    1.0    Notre Dame   \n",
       "1            Harvard          1.075804                    1.0     Merrimack   \n",
       "2  Boston University          1.756704                    2.0        Denver   \n",
       "3         Providence          2.043651                    1.0      Clarkson   \n",
       "4              Brown          2.043651                    1.0  North Dakota   \n",
       "\n",
       "      Distance Game_Type  \n",
       "0  3606.351007   Neutral  \n",
       "1  2994.604500   Neutral  \n",
       "2  1768.308428   Regular  \n",
       "3   267.072502   Regular  \n",
       "4  1319.532097   Regular  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by Distance\n",
    "\n",
    "team_travel_data_expanded_cleaned.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added data clean and transform steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Reg_Distance</th>\n",
       "      <th>Reg_Trips</th>\n",
       "      <th>Reg_AVG</th>\n",
       "      <th>N_Distance</th>\n",
       "      <th>Neutral_Site_Trips</th>\n",
       "      <th>N_AVG</th>\n",
       "      <th>Total_Distance</th>\n",
       "      <th>Overall_AVG</th>\n",
       "      <th>Closest_Team</th>\n",
       "      <th>Closest_Distance</th>\n",
       "      <th>Total_Closest_Matches</th>\n",
       "      <th>Longest_Trip_Opponent</th>\n",
       "      <th>Distance_Longest_Trip</th>\n",
       "      <th>Game_Type_Longest_Trip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>2495.79</td>\n",
       "      <td>17</td>\n",
       "      <td>146.81</td>\n",
       "      <td>2994.25</td>\n",
       "      <td>1</td>\n",
       "      <td>2994.25</td>\n",
       "      <td>5490.04</td>\n",
       "      <td>305.00</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1</td>\n",
       "      <td>Notre Dame</td>\n",
       "      <td>3606.35</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boston University</td>\n",
       "      <td>2092.73</td>\n",
       "      <td>13</td>\n",
       "      <td>160.98</td>\n",
       "      <td>2994.60</td>\n",
       "      <td>1</td>\n",
       "      <td>2994.60</td>\n",
       "      <td>5087.34</td>\n",
       "      <td>363.38</td>\n",
       "      <td>Harvard</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1</td>\n",
       "      <td>Merrimack</td>\n",
       "      <td>2994.60</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Northeastern</td>\n",
       "      <td>2610.85</td>\n",
       "      <td>16</td>\n",
       "      <td>163.18</td>\n",
       "      <td>111.69</td>\n",
       "      <td>1</td>\n",
       "      <td>111.69</td>\n",
       "      <td>2722.55</td>\n",
       "      <td>160.15</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2</td>\n",
       "      <td>Denver</td>\n",
       "      <td>1768.31</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brown</td>\n",
       "      <td>1675.80</td>\n",
       "      <td>13</td>\n",
       "      <td>128.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1675.80</td>\n",
       "      <td>128.91</td>\n",
       "      <td>Providence</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1</td>\n",
       "      <td>Clarkson</td>\n",
       "      <td>267.07</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Providence</td>\n",
       "      <td>2121.17</td>\n",
       "      <td>15</td>\n",
       "      <td>141.41</td>\n",
       "      <td>1666.88</td>\n",
       "      <td>3</td>\n",
       "      <td>555.63</td>\n",
       "      <td>3788.05</td>\n",
       "      <td>210.45</td>\n",
       "      <td>Brown</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>1319.53</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Boston College</td>\n",
       "      <td>1212.77</td>\n",
       "      <td>13</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1212.77</td>\n",
       "      <td>93.29</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2</td>\n",
       "      <td>Michigan State</td>\n",
       "      <td>679.87</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>3584.03</td>\n",
       "      <td>12</td>\n",
       "      <td>298.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3584.03</td>\n",
       "      <td>298.67</td>\n",
       "      <td>Boston College</td>\n",
       "      <td>4.32</td>\n",
       "      <td>0</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>1771.36</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1185.82</td>\n",
       "      <td>11</td>\n",
       "      <td>107.80</td>\n",
       "      <td>33.72</td>\n",
       "      <td>1</td>\n",
       "      <td>33.72</td>\n",
       "      <td>1219.53</td>\n",
       "      <td>101.63</td>\n",
       "      <td>Quinnipiac</td>\n",
       "      <td>6.74</td>\n",
       "      <td>2</td>\n",
       "      <td>Clarkson</td>\n",
       "      <td>253.88</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Quinnipiac</td>\n",
       "      <td>1945.51</td>\n",
       "      <td>16</td>\n",
       "      <td>121.59</td>\n",
       "      <td>100.03</td>\n",
       "      <td>2</td>\n",
       "      <td>50.02</td>\n",
       "      <td>2045.54</td>\n",
       "      <td>113.64</td>\n",
       "      <td>Yale</td>\n",
       "      <td>6.74</td>\n",
       "      <td>2</td>\n",
       "      <td>Maine</td>\n",
       "      <td>322.28</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>3993.51</td>\n",
       "      <td>11</td>\n",
       "      <td>363.05</td>\n",
       "      <td>1302.78</td>\n",
       "      <td>1</td>\n",
       "      <td>1302.78</td>\n",
       "      <td>5296.29</td>\n",
       "      <td>441.36</td>\n",
       "      <td>St Thomas</td>\n",
       "      <td>9.02</td>\n",
       "      <td>0</td>\n",
       "      <td>Penn State</td>\n",
       "      <td>830.01</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Team  Reg_Distance  Reg_Trips  Reg_AVG  N_Distance  \\\n",
       "0            Harvard       2495.79         17   146.81     2994.25   \n",
       "1  Boston University       2092.73         13   160.98     2994.60   \n",
       "2       Northeastern       2610.85         16   163.18      111.69   \n",
       "3              Brown       1675.80         13   128.91        0.00   \n",
       "4         Providence       2121.17         15   141.41     1666.88   \n",
       "5     Boston College       1212.77         13    93.29        0.00   \n",
       "6            Bentley       3584.03         12   298.67        0.00   \n",
       "7               Yale       1185.82         11   107.80       33.72   \n",
       "8         Quinnipiac       1945.51         16   121.59      100.03   \n",
       "9          Minnesota       3993.51         11   363.05     1302.78   \n",
       "\n",
       "   Neutral_Site_Trips    N_AVG  Total_Distance  Overall_AVG  \\\n",
       "0                   1  2994.25         5490.04       305.00   \n",
       "1                   1  2994.60         5087.34       363.38   \n",
       "2                   1   111.69         2722.55       160.15   \n",
       "3                   0     0.00         1675.80       128.91   \n",
       "4                   3   555.63         3788.05       210.45   \n",
       "5                   0     0.00         1212.77        93.29   \n",
       "6                   0     0.00         3584.03       298.67   \n",
       "7                   1    33.72         1219.53       101.63   \n",
       "8                   2    50.02         2045.54       113.64   \n",
       "9                   1  1302.78         5296.29       441.36   \n",
       "\n",
       "        Closest_Team  Closest_Distance  Total_Closest_Matches  \\\n",
       "0  Boston University              1.08                      1   \n",
       "1            Harvard              1.08                      1   \n",
       "2  Boston University              1.76                      2   \n",
       "3         Providence              2.04                      1   \n",
       "4              Brown              2.04                      1   \n",
       "5  Boston University              2.86                      2   \n",
       "6     Boston College              4.32                      0   \n",
       "7         Quinnipiac              6.74                      2   \n",
       "8               Yale              6.74                      2   \n",
       "9          St Thomas              9.02                      0   \n",
       "\n",
       "  Longest_Trip_Opponent  Distance_Longest_Trip Game_Type_Longest_Trip  \n",
       "0            Notre Dame                3606.35                Neutral  \n",
       "1             Merrimack                2994.60                Neutral  \n",
       "2                Denver                1768.31                Regular  \n",
       "3              Clarkson                 267.07                Regular  \n",
       "4          North Dakota                1319.53                Regular  \n",
       "5        Michigan State                 679.87                Regular  \n",
       "6             Air Force                1771.36                Regular  \n",
       "7              Clarkson                 253.88                Regular  \n",
       "8                 Maine                 322.28                Regular  \n",
       "9            Penn State                 830.01                Regular  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Some added transformation steps\n",
    "# Fill Nan Values with 0\n",
    "team_travel_data_expanded_cleaned = team_travel_data_expanded_cleaned.fillna(0)\n",
    "\n",
    "# Set Neutral Site Trips to integer\n",
    "team_travel_data_expanded_cleaned['Neutral_Site_Trips'] = team_travel_data_expanded_cleaned['Neutral_Site_Trips'].astype(int)\n",
    "team_travel_data_expanded_cleaned['Total_Closest_Matches'] = team_travel_data_expanded_cleaned['Total_Closest_Matches'].astype(int)\n",
    "\n",
    "# Round the floats to 2 decimal places\n",
    "team_travel_data_expanded_cleaned = team_travel_data_expanded_cleaned.round({'Reg_Distance': 2, 'Reg_Trips': 2, 'Reg_AVG': 2,\n",
    "                                                                          'N_Distance': 2, 'Neutral_Site_Trips': 2, 'N_AVG': 2,\n",
    "                                                                          'Total_Distance': 2, 'Overall_AVG': 2, 'Closest_Distance': 2,\n",
    "                                                                          'Total_Closest_Matches': 2, 'Distance': 2})\n",
    "\n",
    "## Rename some Columns\n",
    "# Opponent to Longest_Trip_Opponent\n",
    "# Distance_Longest_Trip\n",
    "# Game_Type to Game_Type_Longest_Trip\n",
    "team_travel_data_expanded_cleaned = team_travel_data_expanded_cleaned.rename(columns={'Opponent': 'Longest_Trip_Opponent',\n",
    "                                                                                    'Distance': 'Distance_Longest_Trip',\n",
    "                                                                                    'Game_Type': 'Game_Type_Longest_Trip'})\n",
    "\n",
    "# Display The Resulting DataFrame\n",
    "team_travel_data_expanded_cleaned.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output the Final Table to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to: ..\\data\\output\\Team_Travel_Information_v1.csv\n"
     ]
    }
   ],
   "source": [
    "# # TEMP FOLDER Output\n",
    "# output_path = os.path.join('..', 'TEMP', 'FINAL_OUT_team_travel_data_v2.csv')\n",
    "# team_travel_data_expanded_cleaned.to_csv(output_path, index=False)\n",
    "# print(f\"Output saved to: {output_path}\")\n",
    "\n",
    "# OUTPUT INTO DATA OUTPUT FOLDER\n",
    "output_path = os.path.join('..', 'data', 'output', 'Team_Travel_Information_v1.csv')\n",
    "team_travel_data_expanded_cleaned.to_csv(output_path, index=False)\n",
    "print(f\"Output saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
