{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRATCH BOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home_Conference  Atlantic  Big Ten  CCHA  ECAC  Hockey East  Independents  \\\n",
      "Away_Conference                                                             \n",
      "Atlantic                0        0     0     5            2             0   \n",
      "Big Ten                 0        0     2     0            0             2   \n",
      "CCHA                    2        2     1     0            0             0   \n",
      "ECAC                    0        0     0     0            2             0   \n",
      "Hockey East             1        0     0     0            0             0   \n",
      "Independents            0        0     0     0            1             0   \n",
      "NCHC                    2        0     1     0            0             2   \n",
      "\n",
      "Home_Conference  NCHC  \n",
      "Away_Conference        \n",
      "Atlantic            0  \n",
      "Big Ten             0  \n",
      "CCHA                1  \n",
      "ECAC                0  \n",
      "Hockey East         0  \n",
      "Independents        0  \n",
      "NCHC                0  \n",
      "Total games played: 26\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Load Schedult/results data and compare conferences\n",
    "path = os.path.join('..', 'data', 'schedule', 'Week 1 Scores.csv')\n",
    "\n",
    "# Load the data\n",
    "schedule_df = pd.read_csv(path)\n",
    "\n",
    "# filter out exhibition games\n",
    "schedule_df = schedule_df[schedule_df['Conference'] != 'Exhibition']\n",
    "# Clean up Team names (remove ' and periods)\n",
    "schedule_df['Away_Team'] = schedule_df['Away_Team'].str.replace(\"'\", \"\").str.replace(\".\", \"\")\n",
    "schedule_df['Home_Team'] = schedule_df['Home_Team'].str.replace(\"'\", \"\").str.replace(\".\", \"\")\n",
    "# strip leading and trailing spaces\n",
    "schedule_df['Away_Team'] = schedule_df['Away_Team'].str.strip()\n",
    "schedule_df['Home_Team'] = schedule_df['Home_Team'].str.strip()\n",
    "# Drop any rows containing a / or TBD\n",
    "schedule_df = schedule_df[~schedule_df['Away_Team'].str.contains('/')]\n",
    "schedule_df = schedule_df[~schedule_df['Home_Team'].str.contains('/')]\n",
    "schedule_df = schedule_df[~schedule_df['Away_Team'].str.contains('TBD')]\n",
    "schedule_df = schedule_df[~schedule_df['Home_Team'].str.contains('TBD')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the conferences\n",
    "conference_teams = {\n",
    "    'Atlantic': ['Air Force', \"American Intl\", 'Army', 'Bentley', 'Canisius', 'Holy Cross', 'Mercyhurst', \n",
    "                 'Niagara', 'RIT', 'Robert Morris', 'Sacred Heart'],\n",
    "    'Big Ten': ['Michigan', 'Michigan State', 'Minnesota', 'Notre Dame', 'Ohio State', 'Penn State', 'Wisconsin'],\n",
    "    'CCHA': ['Augustana', 'Bemidji State', 'Bowling Green', 'Ferris State', 'Lake Superior', 'Michigan Tech', \n",
    "             'Minnesota State', 'Northern Michigan', 'St Thomas'],\n",
    "    'ECAC': ['Brown', 'Clarkson', 'Colgate', 'Cornell', 'Dartmouth', 'Harvard', 'Princeton', 'Quinnipiac',\n",
    "             'Rensselaer', 'St Lawrence', 'Union', 'Yale'],\n",
    "    'Hockey East': ['Boston College', 'Boston University', 'Connecticut', 'Maine', 'Massachusetts', 'Mass Lowell',\n",
    "                    'Merrimack', 'New Hampshire', 'Northeastern', 'Providence', 'Vermont'],\n",
    "    'NCHC': ['Arizona State', 'Colorado College', 'Denver', 'Miami', 'Minnesota Duluth', 'North Dakota', 'Omaha', \n",
    "             'St Cloud State', 'Western Michigan'],\n",
    "    'Independents': ['Alaska Anchorage', 'Alaska', 'Lindenwood', 'Long Island', 'Stonehill']\n",
    "}\n",
    "\n",
    "# Function to get the conference of a team\n",
    "def get_conference(team):\n",
    "    for conference, teams in conference_teams.items():\n",
    "        if team in teams:\n",
    "            return conference\n",
    "    return 'Unknown'  # For teams not in the provided lists\n",
    "\n",
    "# Add columns for conference of both the away and home teams\n",
    "schedule_df['Away_Conference'] = schedule_df['Away_Team'].apply(get_conference)\n",
    "schedule_df['Home_Conference'] = schedule_df['Home_Team'].apply(get_conference)\n",
    "\n",
    "# Drop rows with Unknown conferences - Stonehill and Long Island annonmaly\n",
    "schedule_df = schedule_df[schedule_df['Away_Conference'] != 'Unknown']\n",
    "schedule_df = schedule_df[schedule_df['Home_Conference'] != 'Unknown']\n",
    "\n",
    "# Rename to completed_games_df\n",
    "completed_games_df = schedule_df\n",
    "\n",
    "# Matrix for away team wins\n",
    "away_wins_matrix = pd.crosstab(index=completed_games_df['Away_Conference'],\n",
    "                               columns=completed_games_df['Home_Conference'],\n",
    "                               values=(completed_games_df['Away_Score'] > completed_games_df['Home_Score']).astype(int),\n",
    "                               aggfunc='sum', dropna=False)\n",
    "\n",
    "# Matrix for home team wins\n",
    "home_wins_matrix = pd.crosstab(index=completed_games_df['Home_Conference'],\n",
    "                               columns=completed_games_df['Away_Conference'],\n",
    "                               values=(completed_games_df['Home_Score'] > completed_games_df['Away_Score']).astype(int),\n",
    "                               aggfunc='sum', dropna=False)\n",
    "\n",
    "# Transpose the home wins matrix so that it aligns with the away wins matrix for summation\n",
    "home_wins_matrix = home_wins_matrix.T\n",
    "\n",
    "# Sum both matrices to get the total wins\n",
    "total_wins_matrix = away_wins_matrix.add(home_wins_matrix, fill_value=0)\n",
    "# total_wins_matrix = total_wins_matrix.astype(int) # Convert to integers\n",
    "\n",
    "\n",
    "# Display the results matrix\n",
    "print(total_wins_matrix)\n",
    "# calculate and print the total number of games played\n",
    "total_games = total_wins_matrix.sum().sum()\n",
    "print(f'Total games played: {total_games}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Series([], Name: count, dtype: int64)\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# # Find the team without a conference\n",
    "# # Display rows with 'Unknown' in either column\n",
    "# unknown_teams = schedule_df[(schedule_df['Away_Conference'] == 'Unknown') | (schedule_df['Home_Conference'] == 'Unknown')]\n",
    "# print(len(unknown_teams))  # Number of rows with unknown teams\n",
    "\n",
    "# # value count of unknown teams\n",
    "# print(unknown_teams['Away_Team'].value_counts())\n",
    "# print(unknown_teams['Home_Team'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join 2023 Player Stats to 2024 Rosters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Team</th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>First_Name</th>\n",
       "      <th>No</th>\n",
       "      <th>Position</th>\n",
       "      <th>Yr</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Height_Inches</th>\n",
       "      <th>Draft_Year</th>\n",
       "      <th>NHL_Team</th>\n",
       "      <th>D_Round</th>\n",
       "      <th>Last Team</th>\n",
       "      <th>League</th>\n",
       "      <th>City</th>\n",
       "      <th>State_Province</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>Barone</td>\n",
       "      <td>Adam</td>\n",
       "      <td>6</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Fr</td>\n",
       "      <td>1-Jun</td>\n",
       "      <td>174</td>\n",
       "      <td>5/6/2004</td>\n",
       "      <td>Sault Ste. Marie, Ont.</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trail</td>\n",
       "      <td>BCHL</td>\n",
       "      <td>Sault Ste. Marie</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>Blanchett</td>\n",
       "      <td>Jack</td>\n",
       "      <td>16</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>So</td>\n",
       "      <td>11-May</td>\n",
       "      <td>185</td>\n",
       "      <td>5/12/2003</td>\n",
       "      <td>Monroe, Mich.</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Powell</td>\n",
       "      <td>BCHL</td>\n",
       "      <td>Monroe</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Mike</td>\n",
       "      <td>3</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Jr</td>\n",
       "      <td>2-Jun</td>\n",
       "      <td>209</td>\n",
       "      <td>4/3/2001</td>\n",
       "      <td>Belmont, Mass.</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Merrimack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belmont</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>Bushy</td>\n",
       "      <td>Evan</td>\n",
       "      <td>5</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>So</td>\n",
       "      <td>1-Jun</td>\n",
       "      <td>195</td>\n",
       "      <td>3/26/2002</td>\n",
       "      <td>Mankato, Minn.</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trail</td>\n",
       "      <td>BCHL</td>\n",
       "      <td>Mankato</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>Conrad</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>4</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Fr</td>\n",
       "      <td>11-May</td>\n",
       "      <td>180</td>\n",
       "      <td>5/18/2002</td>\n",
       "      <td>Green Bay, Wis.</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fairbanks</td>\n",
       "      <td>NAHL</td>\n",
       "      <td>Green Bay</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Current Team  Last_Name First_Name  No    Position  Yr      Ht   Wt  \\\n",
       "0  Lake Superior     Barone       Adam   6  Defensemen  Fr   1-Jun  174   \n",
       "1  Lake Superior  Blanchett       Jack  16  Defensemen  So  11-May  185   \n",
       "2  Lake Superior      Brown       Mike   3  Defensemen  Jr   2-Jun  209   \n",
       "3  Lake Superior      Bushy       Evan   5  Defensemen  So   1-Jun  195   \n",
       "4  Lake Superior     Conrad      Jacob   4  Defensemen  Fr  11-May  180   \n",
       "\n",
       "         DOB                Hometown  Height_Inches  Draft_Year NHL_Team  \\\n",
       "0   5/6/2004  Sault Ste. Marie, Ont.             73         NaN      NaN   \n",
       "1  5/12/2003           Monroe, Mich.             71         NaN      NaN   \n",
       "2   4/3/2001          Belmont, Mass.             74         NaN      NaN   \n",
       "3  3/26/2002          Mankato, Minn.             73         NaN      NaN   \n",
       "4  5/18/2002         Green Bay, Wis.             71         NaN      NaN   \n",
       "\n",
       "   D_Round  Last Team League              City State_Province Country  \n",
       "0      NaN      Trail   BCHL  Sault Ste. Marie        Ontario  Canada  \n",
       "1      NaN     Powell   BCHL            Monroe       Michigan     USA  \n",
       "2      NaN  Merrimack    NaN           Belmont  Massachusetts     USA  \n",
       "3      NaN      Trail   BCHL           Mankato      Minnesota     USA  \n",
       "4      NaN  Fairbanks   NAHL         Green Bay      Wisconsin     USA  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "## Path to the data\n",
    "roster_path = os.path.join(\"..\", \"data\", \"roster_2024_current_v3.csv\")\n",
    "stat_path = os.path.join(\"..\", \"data\", \"player_stats_2023_v1.csv\")\n",
    "\n",
    "# Load the data\n",
    "roster_df = pd.read_csv(roster_path)\n",
    "stat_df = pd.read_csv(stat_path)\n",
    "\n",
    "# Check the data\n",
    "roster_df.head()\n",
    "# stat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split stats Clean_Player into first and last name\n",
    "stat_df['First_Name'] = stat_df['Clean_Player'].str.split(\" \").str[0]\n",
    "stat_df['Last_Name'] = stat_df['Clean_Player'].str.split(\" \").str[1:]\n",
    "\n",
    "\n",
    "stat_df['Last_Name'] = stat_df['Last_Name'].str[0].str.replace('[','').str.replace(']','') # Remove the brackets from the last name\n",
    "# Remove periods dashes ect from both names\n",
    "stat_df['First_Name'] = stat_df['First_Name'].str.replace('.','').str.replace('-',' ')\n",
    "stat_df['Last_Name'] = stat_df['Last_Name'].str.replace('.','').str.replace('-',' ')\n",
    "roster_df['First_Name'] = roster_df['First_Name'].str.replace('.','').str.replace('-',' ')\n",
    "roster_df['Last_Name'] = roster_df['Last_Name'].str.replace('.','').str.replace('-',' ')\n",
    "# strip white space\n",
    "stat_df['First_Name'] = stat_df['First_Name'].str.strip()\n",
    "stat_df['Last_Name'] = stat_df['Last_Name'].str.strip()\n",
    "roster_df['First_Name'] = roster_df['First_Name'].str.strip()\n",
    "roster_df['Last_Name'] = roster_df['Last_Name'].str.strip()\n",
    "\n",
    "# Rename Team to Team_2023 for clarity\n",
    "stat_df.rename(columns={'Team':'Team_2023'}, inplace=True)\n",
    "# Rename Current_Team to Team_2024 for clarity\n",
    "roster_df.rename(columns={'Current Team':'Team_2024'}, inplace=True)\n",
    "\n",
    "stat_df.head()\n",
    "# OUTPUT THE DATA TO TEMP CSVs\n",
    "roster_df.to_csv(os.path.join(\"..\", \"TEMP\", \"TEST_roster_2024_current_v4.csv\"), index=False)\n",
    "stat_df.to_csv(os.path.join(\"..\", \"TEMP\", \"TEST_player_stats_2023_v2.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of players in the roster: 1820\n",
      "Number of players in the stats: 1729\n",
      "Number of players in the merged data: 2309\n",
      "Number of players with mismatched teams: 1374\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2309 entries, 0 to 2308\n",
      "Data columns (total 28 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Team_2024       1825 non-null   object \n",
      " 1   Last_Name       2309 non-null   object \n",
      " 2   First_Name      2309 non-null   object \n",
      " 3   No              1825 non-null   float64\n",
      " 4   Position        1825 non-null   object \n",
      " 5   Yr              1825 non-null   object \n",
      " 6   Ht              1822 non-null   object \n",
      " 7   Wt              1825 non-null   float64\n",
      " 8   DOB             1735 non-null   object \n",
      " 9   Hometown        1825 non-null   object \n",
      " 10  Height_Inches   1825 non-null   float64\n",
      " 11  Draft_Year      225 non-null    float64\n",
      " 12  NHL_Team        225 non-null    object \n",
      " 13  D_Round         225 non-null    float64\n",
      " 14  Last Team       1815 non-null   object \n",
      " 15  League          1767 non-null   object \n",
      " 16  City            1825 non-null   object \n",
      " 17  State_Province  1825 non-null   object \n",
      " 18  Country         1825 non-null   object \n",
      " 19  Clean_Player    1735 non-null   object \n",
      " 20  Team_2023       1735 non-null   object \n",
      " 21  G               1735 non-null   float64\n",
      " 22  A               1735 non-null   float64\n",
      " 23  Pts             1735 non-null   float64\n",
      " 24  plus_minus      1735 non-null   float64\n",
      " 25  Sh              1735 non-null   float64\n",
      " 26  PIM             1735 non-null   float64\n",
      " 27  Games_Played    1735 non-null   float64\n",
      "dtypes: float64(12), object(16)\n",
      "memory usage: 505.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_2024</th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>First_Name</th>\n",
       "      <th>No</th>\n",
       "      <th>Position</th>\n",
       "      <th>Yr</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>...</th>\n",
       "      <th>Country</th>\n",
       "      <th>Clean_Player</th>\n",
       "      <th>Team_2023</th>\n",
       "      <th>G</th>\n",
       "      <th>A</th>\n",
       "      <th>Pts</th>\n",
       "      <th>plus_minus</th>\n",
       "      <th>Sh</th>\n",
       "      <th>PIM</th>\n",
       "      <th>Games_Played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Long Island</td>\n",
       "      <td>Casperson</td>\n",
       "      <td>AJ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Jr</td>\n",
       "      <td>2-Jun</td>\n",
       "      <td>190.0</td>\n",
       "      <td>7/19/2001</td>\n",
       "      <td>Flower Mound, Texas</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>AJ Casperson</td>\n",
       "      <td>Long Island</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Hodges</td>\n",
       "      <td>AJ</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Forwards</td>\n",
       "      <td>Gr</td>\n",
       "      <td>Jun-00</td>\n",
       "      <td>175.0</td>\n",
       "      <td>8/24/2001</td>\n",
       "      <td>Littleton, Colo.</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>A.J. Hodges</td>\n",
       "      <td>Bentley</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bemidji State</td>\n",
       "      <td>Macaulay</td>\n",
       "      <td>AJ</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Sr</td>\n",
       "      <td>9-May</td>\n",
       "      <td>185.0</td>\n",
       "      <td>4/12/2002</td>\n",
       "      <td>Bonnyville, Alb.</td>\n",
       "      <td>...</td>\n",
       "      <td>Canada</td>\n",
       "      <td>A.J. Macaulay</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quinnipiac</td>\n",
       "      <td>Bohlinger</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Gr</td>\n",
       "      <td>9-May</td>\n",
       "      <td>165.0</td>\n",
       "      <td>8/25/2000</td>\n",
       "      <td>Walden, N.Y.</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>Aaron Bohlinger</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Long Island</td>\n",
       "      <td>Grounds</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Forwards</td>\n",
       "      <td>Sr</td>\n",
       "      <td>2-Jun</td>\n",
       "      <td>190.0</td>\n",
       "      <td>12/24/1999</td>\n",
       "      <td>Jamestown, N.D.</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>Aaron Grounds</td>\n",
       "      <td>Long Island</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Team_2024  Last_Name First_Name    No    Position  Yr      Ht     Wt  \\\n",
       "0    Long Island  Casperson         AJ   3.0  Defensemen  Jr   2-Jun  190.0   \n",
       "1        Bentley     Hodges         AJ  20.0    Forwards  Gr  Jun-00  175.0   \n",
       "2  Bemidji State   Macaulay         AJ  12.0  Defensemen  Sr   9-May  185.0   \n",
       "3     Quinnipiac  Bohlinger      Aaron   5.0  Defensemen  Gr   9-May  165.0   \n",
       "4    Long Island    Grounds      Aaron  23.0    Forwards  Sr   2-Jun  190.0   \n",
       "\n",
       "          DOB             Hometown  ...  Country     Clean_Player  \\\n",
       "0   7/19/2001  Flower Mound, Texas  ...      USA     AJ Casperson   \n",
       "1   8/24/2001     Littleton, Colo.  ...      USA      A.J. Hodges   \n",
       "2   4/12/2002     Bonnyville, Alb.  ...   Canada    A.J. Macaulay   \n",
       "3   8/25/2000         Walden, N.Y.  ...      USA  Aaron Bohlinger   \n",
       "4  12/24/1999      Jamestown, N.D.  ...      USA    Aaron Grounds   \n",
       "\n",
       "       Team_2023    G     A   Pts plus_minus    Sh   PIM Games_Played  \n",
       "0    Long Island  0.0   1.0   1.0        1.0   7.0   2.0         12.0  \n",
       "1        Bentley  6.0   9.0  15.0       -1.0  57.0   2.0         29.0  \n",
       "2         Alaska  5.0  10.0  15.0        9.0  44.0  14.0         34.0  \n",
       "3  Massachusetts  3.0   5.0   8.0        1.0  22.0   4.0         34.0  \n",
       "4    Long Island  1.0   2.0   3.0       -5.0  14.0  16.0         11.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Try a quick merge\n",
    "merged_df = pd.merge(roster_df, stat_df, left_on=['First_Name', 'Last_Name'], right_on=['First_Name', 'Last_Name'], how='outer', suffixes=('_2024', '_2023'))\n",
    "merged_df.head()\n",
    "\n",
    "# Print report of the merge\n",
    "print(f\"Number of players in the roster: {len(roster_df)}\")\n",
    "print(f\"Number of players in the stats: {len(stat_df)}\")\n",
    "print(f\"Number of players in the merged data: {len(merged_df)}\")\n",
    "\n",
    "\n",
    "# Find Number Number of players whos Team_2023 does not match Team_2024\n",
    "mismatched_teams = merged_df[merged_df['Team_2023'] != merged_df['Team_2024']]\n",
    "print(f\"Number of players with mismatched teams: {len(mismatched_teams)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(merged_df.info())\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1825 entries, 0 to 2308\n",
      "Data columns (total 28 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Team_2024       1825 non-null   object \n",
      " 1   Last_Name       1825 non-null   object \n",
      " 2   First_Name      1825 non-null   object \n",
      " 3   No              1825 non-null   float64\n",
      " 4   Position        1825 non-null   object \n",
      " 5   Yr              1825 non-null   object \n",
      " 6   Ht              1822 non-null   object \n",
      " 7   Wt              1825 non-null   float64\n",
      " 8   DOB             1735 non-null   object \n",
      " 9   Hometown        1825 non-null   object \n",
      " 10  Height_Inches   1825 non-null   float64\n",
      " 11  Draft_Year      225 non-null    float64\n",
      " 12  NHL_Team        225 non-null    object \n",
      " 13  D_Round         225 non-null    float64\n",
      " 14  Last Team       1815 non-null   object \n",
      " 15  League          1767 non-null   object \n",
      " 16  City            1825 non-null   object \n",
      " 17  State_Province  1825 non-null   object \n",
      " 18  Country         1825 non-null   object \n",
      " 19  Clean_Player    1251 non-null   object \n",
      " 20  Team_2023       1251 non-null   object \n",
      " 21  G               1251 non-null   float64\n",
      " 22  A               1251 non-null   float64\n",
      " 23  Pts             1251 non-null   float64\n",
      " 24  plus_minus      1251 non-null   float64\n",
      " 25  Sh              1251 non-null   float64\n",
      " 26  PIM             1251 non-null   float64\n",
      " 27  Games_Played    1251 non-null   float64\n",
      "dtypes: float64(12), object(16)\n",
      "memory usage: 413.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Drop players who aren't playing this year (No Team_2024)\n",
    "merged_df = merged_df.dropna(subset=['Team_2024'])\n",
    "print(merged_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_2024</th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>First_Name</th>\n",
       "      <th>No</th>\n",
       "      <th>Position</th>\n",
       "      <th>Yr</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>...</th>\n",
       "      <th>Country</th>\n",
       "      <th>Clean_Player</th>\n",
       "      <th>Team_2023</th>\n",
       "      <th>G</th>\n",
       "      <th>A</th>\n",
       "      <th>Pts</th>\n",
       "      <th>plus_minus</th>\n",
       "      <th>Sh</th>\n",
       "      <th>PIM</th>\n",
       "      <th>Games_Played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Long Island</td>\n",
       "      <td>Casperson</td>\n",
       "      <td>AJ</td>\n",
       "      <td>3</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Jr</td>\n",
       "      <td>2-Jun</td>\n",
       "      <td>190</td>\n",
       "      <td>7/19/2001</td>\n",
       "      <td>Flower Mound, Texas</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>AJ Casperson</td>\n",
       "      <td>Long Island</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Hodges</td>\n",
       "      <td>AJ</td>\n",
       "      <td>20</td>\n",
       "      <td>Forwards</td>\n",
       "      <td>Gr</td>\n",
       "      <td>Jun-00</td>\n",
       "      <td>175</td>\n",
       "      <td>8/24/2001</td>\n",
       "      <td>Littleton, Colo.</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>A.J. Hodges</td>\n",
       "      <td>Bentley</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bemidji State</td>\n",
       "      <td>Macaulay</td>\n",
       "      <td>AJ</td>\n",
       "      <td>12</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Sr</td>\n",
       "      <td>9-May</td>\n",
       "      <td>185</td>\n",
       "      <td>4/12/2002</td>\n",
       "      <td>Bonnyville, Alb.</td>\n",
       "      <td>...</td>\n",
       "      <td>Canada</td>\n",
       "      <td>A.J. Macaulay</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quinnipiac</td>\n",
       "      <td>Bohlinger</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>5</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Gr</td>\n",
       "      <td>9-May</td>\n",
       "      <td>165</td>\n",
       "      <td>8/25/2000</td>\n",
       "      <td>Walden, N.Y.</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>Aaron Bohlinger</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Long Island</td>\n",
       "      <td>Grounds</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>23</td>\n",
       "      <td>Forwards</td>\n",
       "      <td>Sr</td>\n",
       "      <td>2-Jun</td>\n",
       "      <td>190</td>\n",
       "      <td>12/24/1999</td>\n",
       "      <td>Jamestown, N.D.</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>Aaron Grounds</td>\n",
       "      <td>Long Island</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Team_2024  Last_Name First_Name  No    Position  Yr      Ht   Wt  \\\n",
       "0    Long Island  Casperson         AJ   3  Defensemen  Jr   2-Jun  190   \n",
       "1        Bentley     Hodges         AJ  20    Forwards  Gr  Jun-00  175   \n",
       "2  Bemidji State   Macaulay         AJ  12  Defensemen  Sr   9-May  185   \n",
       "3     Quinnipiac  Bohlinger      Aaron   5  Defensemen  Gr   9-May  165   \n",
       "4    Long Island    Grounds      Aaron  23    Forwards  Sr   2-Jun  190   \n",
       "\n",
       "          DOB             Hometown  ...  Country     Clean_Player  \\\n",
       "0   7/19/2001  Flower Mound, Texas  ...      USA     AJ Casperson   \n",
       "1   8/24/2001     Littleton, Colo.  ...      USA      A.J. Hodges   \n",
       "2   4/12/2002     Bonnyville, Alb.  ...   Canada    A.J. Macaulay   \n",
       "3   8/25/2000         Walden, N.Y.  ...      USA  Aaron Bohlinger   \n",
       "4  12/24/1999      Jamestown, N.D.  ...      USA    Aaron Grounds   \n",
       "\n",
       "       Team_2023  G   A Pts plus_minus  Sh PIM Games_Played  \n",
       "0    Long Island  0   1   1          1   7   2           12  \n",
       "1        Bentley  6   9  15         -1  57   2           29  \n",
       "2         Alaska  5  10  15          9  44  14           34  \n",
       "3  Massachusetts  3   5   8          1  22   4           34  \n",
       "4    Long Island  1   2   3         -5  14  16           11  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convert all number columns to int\n",
    "int_columns = ['No', 'Height_Inches', 'Wt', 'Draft_Year', 'D_Round', \n",
    "               'G', 'A', 'Pts', 'plus_minus', 'Sh', 'PIM', 'Games_Played']\n",
    "\n",
    "for col in int_columns:\n",
    "    merged_df[col] = merged_df[col].astype('Int64')\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTPUT CSV TO TEMP FOR INSPECTION\n",
    "merged_df.to_csv(os.path.join(\"..\", \"data\", \"roster_2024_with_2023_stats.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform congressional demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import geopandas as gpd\n",
    "\n",
    "\n",
    "# ## PATHS ##\n",
    "# # ## 118 Congress Shapefile\n",
    "# # shape_path = os.path.join('..', 'data', 'vault', '118th_congress', 'USA_118th_Congressional_Districts.shp')\n",
    "# # ## Load Shapefile\n",
    "# # gdf = gpd.read_file(shape_path)\n",
    "\n",
    "# # Income data table - 5 Year Average 2022\n",
    "# income_path = os.path.join('..', 'data', 'vault', '118th_congress', 'income_data', 'ACSST5Y2022.S1903-Data.csv')\n",
    "# income_df = pd.read_csv(income_path, skiprows=1) # Load Income Data\n",
    "\n",
    "# # Summary table with Populations and Representative Names\n",
    "# summary_path = os.path.join('..', 'data', 'vault', 'USA_118th_Congressional_Districts_info_table.csv')\n",
    "# summary_df = pd.read_csv(summary_path)\n",
    "\n",
    "# # Check \n",
    "# # gdf.head()\n",
    "# # income_df.head()\n",
    "# # summary_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check \n",
    "# gdf.head()\n",
    "# income_df.head()\n",
    "# # summary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulate Image icons so they are all 300 x 300 px squares\n",
    "- making sure they are all squares will make resizing issues easier later on\n",
    "    - The aspect ratio is getting screwed up during resizing for icons that are not square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All logos made square by adding transparent space equally to each side.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "\n",
    "# Directory where the logos are stored\n",
    "logo_dir = os.path.join('..', 'images', 'logos')\n",
    "\n",
    "# Make logos square by adding transparent space equally on both sides\n",
    "for logo_file in os.listdir(logo_dir):\n",
    "    logo_path = os.path.join(logo_dir, logo_file)\n",
    "    \n",
    "    # Check if the path is a file and not a directory\n",
    "    if os.path.isfile(logo_path):\n",
    "        with Image.open(logo_path) as img:\n",
    "            # Ensure the image has an alpha channel (for transparency)\n",
    "            img = img.convert(\"RGBA\")\n",
    "            \n",
    "            width, height = img.size\n",
    "            \n",
    "            # If the image is already square, no changes are needed\n",
    "            if width == height:\n",
    "                continue\n",
    "            \n",
    "            # Calculate padding to add on the shorter side to make the image square\n",
    "            if width > height:\n",
    "                padding = (width - height) // 2\n",
    "                new_img = ImageOps.expand(img, border=(0, padding, 0, padding), fill=(0, 0, 0, 0))\n",
    "            else:\n",
    "                padding = (height - width) // 2\n",
    "                new_img = ImageOps.expand(img, border=(padding, 0, padding, 0), fill=(0, 0, 0, 0))\n",
    "            \n",
    "            # Save the padded square image, overwriting the original\n",
    "            new_img.save(logo_path)\n",
    "\n",
    "print(\"All logos made square by adding transparent space equally to each side.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the coordinates for the rinks in arena_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dependencies\n",
    "# import os\n",
    "# import requests\n",
    "# import pandas as pd\n",
    "\n",
    "# # Path to arena file\n",
    "# arena_file = os.path.join('..','data', 'arena_school_info.csv')\n",
    "# arena_df = pd.read_csv(arena_file)\n",
    "\n",
    "# # Open Roster File To Clean State/Provences Names\n",
    "# roster_file = os.path.join('..','data', 'roster_2024_current_v2.csv')\n",
    "# roster_df = pd.read_csv(roster_file)\n",
    "\n",
    "# roster_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Get list of Unique State/Province Names\n",
    "# unique_states = roster_df['State_Province'].unique()\n",
    "# unique_states\n",
    "\n",
    "# ## Dictionary to standardize state/province names\n",
    "\n",
    "# standardized_locations = {\n",
    "#     'Ont.': 'Ontario', 'Mich.': 'Michigan', 'Mass.': 'Massachusetts', 'Minn.': 'Minnesota', \n",
    "#     'Wis.': 'Wisconsin', 'Sweden': 'Sweden', 'Germany': 'Germany', 'B.C.': 'British Columbia',\n",
    "#     'N.Y.': 'New York', 'Wash.': 'Washington', 'Que.': 'Quebec', 'Alb.': 'Alberta', \n",
    "#     'N.J.': 'New Jersey', 'Sask.': 'Saskatchewan', 'Conn.': 'Connecticut', 'Mo.': 'Missouri',\n",
    "#     'Texas': 'Texas', 'Calif.': 'California', 'DC': 'District of Columbia', 'Fla.': 'Florida',\n",
    "#     'Ohio': 'Ohio', 'Ill.': 'Illinois', 'Pa.': 'Pennsylvania', 'Ga.': 'Georgia',\n",
    "#     'Mont.': 'Montana', 'Tenn.': 'Tennessee', 'Colo.': 'Colorado', 'Va.': 'Virginia', \n",
    "#     'Vt.': 'Vermont', 'R.I.': 'Rhode Island', 'Md.': 'Maryland', 'Ariz.': 'Arizona', \n",
    "#     'Wisc.': 'Wisconsin', 'Iowa': 'Iowa', 'Man.': 'Manitoba', 'Slovakia': 'Slovakia', \n",
    "#     'N.D.': 'North Dakota', 'N.C.': 'North Carolina', 'P.E.I.': 'Prince Edward Island',\n",
    "#     'N.H.': 'New Hampshire', 'Alaska': 'Alaska', 'Belarus': 'Belarus', 'MB': 'Manitoba',\n",
    "#     'Russia': 'Russia', 'Finland': 'Finland', 'Newf.': 'Newfoundland and Labrador', \n",
    "#     'Hungary': 'Hungary', 'SUI': 'Switzerland', 'S.C.': 'South Carolina', 'Latvia': 'Latvia',\n",
    "#     'Czech Republic': 'Czech Republic', 'N.B.': 'New Brunswick', 'Great Britain': 'United Kingdom', \n",
    "#     'NB': 'New Brunswick', 'Norway': 'Norway', 'N.S.': 'Nova Scotia', 'Ind.': 'Indiana', \n",
    "#     'NWT': 'Northwest Territories', 'AUT': 'Austria', 'Idaho': 'Idaho', 'S.D.': 'South Dakota', \n",
    "#     'Switzerland': 'Switzerland', 'Ore.': 'Oregon', 'Wyo.': 'Wyoming', 'Utah': 'Utah', \n",
    "#     'ITA': 'Italy', 'Slovenia': 'Slovenia', 'YT': 'Yukon', 'Del.': 'Delaware', 'Maine': 'Maine',\n",
    "#     'Poland': 'Poland', 'Yukon': 'Yukon', 'Ukraine': 'Ukraine', 'Japan': 'Japan', 'Neb.': 'Nebraska'\n",
    "# }\n",
    "\n",
    "# ## Apply the standardization to the State/Province column\n",
    "# roster_df['State_Province'] = roster_df['State_Province'].replace(standardized_locations)\n",
    "\n",
    "# # Check the unique values after standardization\n",
    "# roster_df['State_Province'].unique()\n",
    "# print(roster_df['State_Province'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output the cleaned roster to a new CSV file\n",
    "cleaned_roster_file = os.path.join('..','data', 'roster_cleaned_state_prov_2024.csv')\n",
    "roster_df.to_csv(cleaned_roster_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import pandas as pd\n",
    "\n",
    "# import requests\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define the function to check the location using Google Places API\n",
    "# def check_location(lat, lng, api_key):\n",
    "#     url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "#     params = {\n",
    "#         'location': f'{lat},{lng}',\n",
    "#         'radius': 500,  # Distance in meters from the provided coordinates\n",
    "#         'type': 'stadium',  # Filter search to stadiums/arenas\n",
    "#         'key': api_key\n",
    "#     }\n",
    "    \n",
    "#     # Debugging: Print the URL and parameters\n",
    "#     print(f\"Requesting URL: {url}\")\n",
    "#     print(f\"Parameters: {params}\")\n",
    "    \n",
    "#     response = requests.get(url, params=params)\n",
    "    \n",
    "#     # Debugging: Print the response code and content\n",
    "#     print(f\"Response status code: {response.status_code}\")\n",
    "#     print(f\"Response content: {response.text}\")\n",
    "    \n",
    "#     if response.status_code == 200:\n",
    "#         results = response.json().get('results')\n",
    "#         if results:\n",
    "#             return results[0].get('name'), results[0].get('vicinity')\n",
    "#         else:\n",
    "#             return None, \"No results found\"\n",
    "#     else:\n",
    "#         return None, f\"API request failed with status {response.status_code}\"\n",
    "\n",
    "# # Define the function to verify coordinates in the DataFrame\n",
    "# def verify_coordinates(df, api_key):\n",
    "#     results = []\n",
    "#     for index, row in df.iterrows():\n",
    "#         lat = row['Latitude']\n",
    "#         lng = row['Longitude']\n",
    "#         arena_name = row['Arena']\n",
    "        \n",
    "#         # Debugging: Print the current coordinates and arena being checked\n",
    "#         print(f\"Checking coordinates for arena: {arena_name}\")\n",
    "#         print(f\"Latitude: {lat}, Longitude: {lng}\")\n",
    "        \n",
    "#         # Get the name and vicinity of the nearest stadium/arena\n",
    "#         name, vicinity = check_location(lat, lng, api_key)\n",
    "        \n",
    "#         # Append the original data and verification results\n",
    "#         results.append({\n",
    "#             'Arena': arena_name,\n",
    "#             'Latitude': lat,\n",
    "#             'Longitude': lng,\n",
    "#             'Google Places Name': name,\n",
    "#             'Vicinity': vicinity\n",
    "#         })\n",
    "#     return pd.DataFrame(results)\n",
    "\n",
    "# # Load your API key\n",
    "\n",
    "\n",
    "# # Assuming arena_df is your DataFrame\n",
    "# verified_df = verify_coordinates(arena_df, api_key)\n",
    "\n",
    "# # Output the results\n",
    "# print(verified_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verified_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Version 2 of Arena Location verifications\n",
    "# ## Returns 5 closest Google Places to coordinates given\n",
    "\n",
    "# import requests\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define the function to check the 5 closest places using Google Places API\n",
    "# def check_nearby_places(lat, lng, api_key):\n",
    "#     url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "#     params = {\n",
    "#         'location': f'{lat},{lng}',\n",
    "#         'radius': 500,  # Distance in meters from the provided coordinates\n",
    "#         'key': api_key\n",
    "#     }\n",
    "    \n",
    "#     # Debugging: Print the URL and parameters being sent to the API\n",
    "#     print(f\"Requesting places near lat: {lat}, lng: {lng}\")\n",
    "#     print(f\"Request URL: {url}\")\n",
    "#     print(f\"Parameters: {params}\")\n",
    "    \n",
    "#     response = requests.get(url, params=params)\n",
    "    \n",
    "#     # Debugging: Print the response status and content\n",
    "#     print(f\"Response status code: {response.status_code}\")\n",
    "#     print(f\"Response content: {response.text}\\n\")  # This shows the full response from the API\n",
    "    \n",
    "#     if response.status_code == 200:\n",
    "#         results = response.json().get('results')\n",
    "#         if results:\n",
    "#             # Return the top 5 closest places\n",
    "#             return [(result.get('name'), result.get('vicinity')) for result in results[:5]]\n",
    "#         else:\n",
    "#             return [(\"None\", \"No results found\")]\n",
    "#     else:\n",
    "#         return [(\"None\", f\"API request failed with status {response.status_code}\")]\n",
    "\n",
    "# # Define the function to verify coordinates and return the 5 closest places\n",
    "# def verify_coordinates(df, api_key):\n",
    "#     results = []\n",
    "#     for index, row in df.iterrows():\n",
    "#         lat = row['Latitude']\n",
    "#         lng = row['Longitude']\n",
    "#         arena_name = row['Arena']\n",
    "#         school_name = row['School']\n",
    "        \n",
    "#         # Debugging: Print the current arena and coordinates being checked\n",
    "#         print(f\"\\nChecking nearby places for arena: {arena_name} (School: {school_name})\")\n",
    "#         print(f\"Latitude: {lat}, Longitude: {lng}\")\n",
    "        \n",
    "#         # Get the 5 closest places\n",
    "#         nearby_places = check_nearby_places(lat, lng, api_key)\n",
    "        \n",
    "#         # Add each place to the results, along with the original data\n",
    "#         for place in nearby_places:\n",
    "#             results.append({\n",
    "#                 'Arena': arena_name,\n",
    "#                 'School': school_name,\n",
    "#                 'Latitude': lat,\n",
    "#                 'Longitude': lng,\n",
    "#                 'Google Places Name': place[0],\n",
    "#                 'Vicinity': place[1]\n",
    "#             })\n",
    "            \n",
    "#     return pd.DataFrame(results)\n",
    "\n",
    "# # Load your API key\n",
    "# api_key = ''\n",
    "\n",
    "# # Assuming arena_df is your DataFrame\n",
    "# verified_df = verify_coordinates(arena_df, api_key)\n",
    "\n",
    "# # Output the results\n",
    "# print(verified_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'verified_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mverified_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m## OUTPUT TO TEMP FOLDER FOR MANUAL REVIEW\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# output_file = os.path.join('..','TEMP', 'arena_school_info_place_checkV3.csv')\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# verified_df.to_csv(output_file, index=False)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'verified_df' is not defined"
     ]
    }
   ],
   "source": [
    "verified_df.head(10)\n",
    "\n",
    "## OUTPUT TO TEMP FOLDER FOR MANUAL REVIEW\n",
    "# output_file = os.path.join('..','TEMP', 'arena_school_info_place_checkV3.csv')\n",
    "# verified_df.to_csv(output_file, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
