{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusted Game Score \n",
    "- Taken from notebook done in 2023-24 Season in the Old Repo\n",
    "    - Starting addaptation from that on 2-14-25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('player_stats_ytd',), ('master_roster',), ('advanced_metrics',), ('game_details',), ('goalie_stats',), ('line_chart',), ('linescore',), ('penalty_summary',), ('player_stats',), ('scoring_summary',)]\n"
     ]
    }
   ],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "# Get DB Path from config\n",
    "from config import last_game_date, recent_clean_db\n",
    "\n",
    "# Create a connection to the SQLite database\n",
    "conn = sqlite3.connect(recent_clean_db)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")# Select All Tables\n",
    "print(cur.fetchall())# print table names to check connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shots Data Extraction - Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the advanced_metrics table to create a dataframe with shots (on_net, missed, blocked) in the EVEN and CLOSE situations\n",
    "\n",
    "# Load the 'advanced_metrics_combined' table into a DataFrame excluding 'TOTAL' rows\n",
    "df_amc = pd.read_sql(\"SELECT * FROM advanced_metrics WHERE player != 'TOTAL'\", conn)\n",
    "\n",
    "# Convert columns to numeric for calculations (replacing empty strings with 0)\n",
    "columns_to_convert = ['EVEN_Saved', 'EVEN_Goals', 'EVEN_Miss', 'EVEN_Block', 'EVEN_Goals', \n",
    "                      'CLOSE_Saved', 'CLOSE_Miss', 'CLOSE_Block', 'CLOSE_Goals', 'CLOSE_Goals',\n",
    "                        'D_Blocks']\n",
    "for col in columns_to_convert:\n",
    "    df_amc[col] = pd.to_numeric(df_amc[col].replace('', '0'))\n",
    "\n",
    "# Create a new DataFrame with the columns we want to use\n",
    "shots_df = df_amc[['Team', 'Player', 'Game_ID', \n",
    "                   'EVEN_Saved', 'EVEN_Miss', 'EVEN_Block', 'EVEN_Goals',\n",
    "                   'CLOSE_Saved', 'CLOSE_Miss', 'CLOSE_Block', 'CLOSE_Goals',\n",
    "                   'D_Blocks']]\n",
    "\n",
    "# Creat SHOTS ON NET column (Saved + Goals)\n",
    "shots_df['EVEN_On_Net'] = shots_df['EVEN_Saved'] + shots_df['EVEN_Goals']\n",
    "shots_df['CLOSE_On_Net'] = shots_df['CLOSE_Saved'] + shots_df['CLOSE_Goals']\n",
    "\n",
    "\n",
    "# ############ BLOCK TO CALCULATE THE WEIGHTED SHOTS SCORE ############\n",
    "\n",
    "# SCORE = \"CLOSE_On_Net * 0.1 + CLOSE_Miss * 0.08 + CLOSE_Block * 0.05 \n",
    "#   + EVEN_On_Net * 0.1 + EVEN_Miss * 0.08 + EVEN_Block * 0.05 (NOT D_Blocks - Going to Use in TEAM COMPONANT)\"\n",
    "\n",
    "# Do the calualtions for the weighted shots score and add it to the DataFrame\n",
    "shots_df['EVEN_Score'] = shots_df['EVEN_On_Net'] * 0.1 + shots_df['EVEN_Miss'] * 0.08 + shots_df['EVEN_Block'] * 0.05\n",
    "shots_df['CLOSE_Score'] = shots_df['CLOSE_On_Net'] * 0.15 + shots_df['CLOSE_Miss'] * 0.1 + shots_df['CLOSE_Block'] * 0.08\n",
    "\n",
    "# Add the EVEN and CLOSE scores together to get the total weighted shots score\n",
    "shots_df['SHOT_Score'] = shots_df['EVEN_Score'] + shots_df['CLOSE_Score']\n",
    "\n",
    "\n",
    "# shots_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faceoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calulate Faceoff Score\n",
    "# SCORE = \"Faceoff_Wins * 0.075 - Faceoff_Losses * 0.075\"\n",
    "\n",
    "# Create a new DataFrame with the columns we want to use from player_stats table in the database\n",
    "df_fo = pd.read_sql(\"SELECT Team, Player, Game_ID, FOW, FOL FROM player_stats\", conn)\n",
    "\n",
    "# Convert columns to numeric for calculations (replacing empty strings with 0)\n",
    "columns_to_convert = ['FOW', 'FOL']\n",
    "for col in columns_to_convert:\n",
    "    df_fo[col] = pd.to_numeric(df_fo[col].replace('', '0'))\n",
    "\n",
    "# Do the calualtions for the faceoff score and add it to the DataFrame\n",
    "df_fo['FACEOFF_Score'] = df_fo['FOW'] * 0.075 - df_fo['FOL'] * 0.075\n",
    "\n",
    "# Fil Nan values with 0\n",
    "df_fo = df_fo.fillna(0)\n",
    "\n",
    "# df_fo.head(15)\n",
    "# df_fo.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEAM\n",
    "- Uses Plus/Minus and Defensive Blocks\n",
    "-\n",
    "- #### +/- *.25 + Blocked Shots * .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TEAM Score \n",
    "# Plus-Minus + Defensive Blocks\n",
    "\n",
    "# Get plus_minus from player_stas table\n",
    "df_plus_minus = pd.read_sql(\"SELECT * FROM player_stats WHERE player != 'TOTAL'\", conn)\n",
    "# Simplify the DataFrame to only the columns we need\n",
    "df_plus_minus = df_plus_minus[['Team', 'Player', 'Game_ID', 'plus_minus']]\n",
    "\n",
    "# Get Defensive block column from previous dataframe (df_amc)\n",
    "df_blocks = df_amc[['Team', 'Player', 'Game_ID', 'D_Blocks']]\n",
    "\n",
    "# Merge the two DataFrames together\n",
    "df_team = pd.merge(df_plus_minus, df_blocks, how='outer', on=['Team', 'Player', 'Game_ID'])\n",
    "\n",
    "# Fill any NaN values with 0\n",
    "df_team = df_team.fillna(0)\n",
    "# Convert D_Blocks to to int\n",
    "df_team['D_Blocks'] = df_team['D_Blocks'].astype(int)\n",
    "# Conver plus_minus to int\n",
    "df_team['plus_minus'] = df_team['plus_minus'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "df_team['TEAM_Score'] = df_team['plus_minus'] * 0.25 + df_team['D_Blocks'] * 0.1\n",
    "\n",
    "# df_team.sample(25)\n",
    "# df_team.info()\n",
    "\n",
    "# df_blocks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalty Score\n",
    "- Number of Minor Penalties x The overall succes rate of all teams\n",
    "    - Major penalties get multiplied by 2.5 (based on 5:2 ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUB FUNCTION To calculate the the Overall Power Play Success Rate for entire dataset\n",
    "# - Used to Weight the PENALTY_SCORE\n",
    "cursor = conn.cursor()\n",
    "# Count the total number of Power Play (PP) goals from the scoring_summary table.\n",
    "pp_goals_count = cursor.execute(\"SELECT COUNT(*) FROM scoring_summary WHERE PP != '';\").fetchone()[0]\n",
    "# Count the total number of Power Plays from the penalty_summary table.\n",
    "total_pp_count = cursor.execute(\"SELECT COUNT(*) FROM penalty_summary;\").fetchone()[0]\n",
    "# Calculate the Power Play success rate.\n",
    "pp_success_rate = pp_goals_count / total_pp_count\n",
    "\n",
    "## OVERALL NCAA WIDE POWER PLAY SUCCESS RATE TO USE IN FACTOR\n",
    "print(f'Overall PP % All Games: {pp_success_rate}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Penalty Summary table to get every individual penalty incident\n",
    "## Count and differentiate between minor and major penalties\n",
    "\n",
    "# Load the 'penalty_summary' table into a DataFrame\n",
    "df_pen = pd.read_sql(\"SELECT * FROM penalty_summary\", conn)\n",
    "\n",
    "# Create Two Columns to count the number of minor and major penalties\n",
    "df_pen['Minor_Pen'] = np.where(df_pen['Pen_Length'] == '2', 1, 0)\n",
    "df_pen['Major_Pen'] = np.where(df_pen['Pen_Length'] == '5', 1, 0)\n",
    "\n",
    "# Group by player, team, and game_id to get the total number of minor and major penalties\n",
    "df_pen = df_pen.groupby(['Player', 'Team', 'Game_ID']).agg({'Minor_Pen': 'sum', 'Major_Pen': 'sum'}).reset_index()\n",
    "\n",
    "# Calulate the Penalty Score\n",
    "# SCORE = \"Penalty_Score = Minor_Pen * pp_succes_rate + Major_Pen * pp_success_rate * 2.5\"\n",
    "df_pen['PENALTY_Score'] = df_pen['Minor_Pen'] * pp_success_rate + df_pen['Major_Pen'] * pp_success_rate * 2.5\n",
    "\n",
    "# df_pen.head(50)\n",
    "# df_pen.info()\n",
    "\n",
    "# # How many players have a major penalty?\n",
    "# df_pen[df_pen['Major_Pen'] > 0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCORING\n",
    "\n",
    "### Method\n",
    "- use the scoring_summary table to get all scoring incidents\n",
    "- Identify Scoring Incidents in CLOSE Games - 1 goal game +/-\n",
    "    - Store as C_Goal, C_Asst1, C_Asst2\n",
    "- Indentify Scoring that was shorthanded (PP Column will be 'SH')\n",
    "    - Store as SH_Goal, SH_Asst1, SH_Asst2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the code to correctly classify each goal into one of the three categories\n",
    "from collections import defaultdict\n",
    "# Reset the dataframe for reprocessing\n",
    "df_scoring_updated =  pd.read_sql(\"SELECT * FROM scoring_summary\", conn)\n",
    "\n",
    "# # Fill NaN values with empty strings in Assists columns\n",
    "# df_scoring_updated['Assist1'].fillna('NONE', inplace=True)\n",
    "# df_scoring_updated['Assist2'].fillna('NONE', inplace=True)\n",
    "\n",
    "# Preparing to track scores for each game\n",
    "game_scores = defaultdict(lambda: {'teams': [], 'scores': {}})\n",
    "teams_per_game = df_scoring_updated.groupby('Game_ID')['Team'].unique()\n",
    "\n",
    "# Rename Player Column to Goal\n",
    "df_scoring_updated.rename(columns={'Player': 'Goal'}, inplace=True)\n",
    "\n",
    "# Function to update and check scores for close game situation\n",
    "def update_and_check_score(row, game_scores):\n",
    "    # Skip if it's a shorthanded goal\n",
    "    if row['PP'] == 'SH':\n",
    "        return False\n",
    "\n",
    "    game_id = row['Game_ID']\n",
    "    team = row['Team']\n",
    "\n",
    "    # Ensure the game has exactly two teams\n",
    "    if len(game_scores[game_id]['teams']) != 2:\n",
    "        return False  # Cannot determine close game status without knowing both teams\n",
    "\n",
    "    # Identify the other team\n",
    "    other_team = game_scores[game_id]['teams'][0] if team != game_scores[game_id]['teams'][0] else game_scores[game_id]['teams'][1]\n",
    "\n",
    "    # Update the score for the scoring team\n",
    "    game_scores[game_id]['scores'][team] += 1\n",
    "\n",
    "    # Calculate score difference\n",
    "    score_diff = abs(game_scores[game_id]['scores'][team] - game_scores[game_id]['scores'][other_team])\n",
    "\n",
    "    # Check if it's a close game situation\n",
    "    return score_diff <= 1\n",
    "\n",
    "# Initialize score tracking and process each scoring incident\n",
    "for game_id, teams in teams_per_game.items():\n",
    "    if len(teams) == 2:  # Ensure only games with two teams are processed\n",
    "        game_scores[game_id]['teams'] = teams.tolist()\n",
    "        game_scores[game_id]['scores'] = {team: 0 for team in teams}\n",
    "\n",
    "df_scoring_updated['CLOSE'] = df_scoring_updated.apply(lambda row: update_and_check_score(row, game_scores), axis=1)\n",
    "df_scoring_updated['SHORT'] = df_scoring_updated['PP'] == 'SH'\n",
    "# Create New Column to identify 'LOW Goals' - If Close_Game = False and SH_Scoring = False\n",
    "# df_scoring_updated['Low_Goals'] = df_scoring_updated.apply(lambda x: 1 if not x['Close_Game'] and not x['SH_Scoring'] else 0, axis=1)\n",
    "\n",
    "# Select only the columns we will use later\n",
    "df_scoring_updated = df_scoring_updated[['Team', 'Game_ID', 'Goal', 'Assist1', 'Assist2', 'CLOSE', 'SHORT']]\n",
    "\n",
    "df = df_scoring_updated\n",
    "\n",
    "# OUTPUT CSV to TEMP folder for inspection\n",
    "df.to_csv('../TEMP/df_scoring_updatedXX.csv')\n",
    "\n",
    "\n",
    "# df.sample(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggrigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to count occurrences of each player for each statistic, including the NOT situation\n",
    "def count_player_stats_including_not(df, player_column):\n",
    "    # Creating a 'NOT' column indicating whether the situation is neither SHORT nor CLOSE\n",
    "    df['NOT'] = ~(df['SHORT'] | df['CLOSE'])\n",
    "\n",
    "    # Preparing the dataset for counting\n",
    "    stats_df = df.melt(id_vars=['Game_ID', 'Team', player_column], \n",
    "                       value_vars=['SHORT', 'CLOSE', 'NOT'], \n",
    "                       var_name='Situation', value_name='Count')\n",
    "\n",
    "    # Filtering only true values and counting occurrences\n",
    "    stats_df = stats_df[stats_df['Count']].groupby(['Game_ID', 'Team', player_column, 'Situation']).size().reset_index(name='Counts')\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "# Applying the modified function for Goal, Assist1, and Assist2\n",
    "goal_stats = count_player_stats_including_not(df, 'Goal')\n",
    "assist1_stats = count_player_stats_including_not(df, 'Assist1')\n",
    "assist2_stats = count_player_stats_including_not(df, 'Assist2')\n",
    "\n",
    "# Renaming columns for clarity\n",
    "goal_stats.rename(columns={'Goal': 'Player_Name', 'Counts': 'Goal_Count'}, inplace=True)\n",
    "assist1_stats.rename(columns={'Assist1': 'Player_Name', 'Counts': 'Assist1_Count'}, inplace=True)\n",
    "assist2_stats.rename(columns={'Assist2': 'Player_Name', 'Counts': 'Assist2_Count'}, inplace=True)\n",
    "\n",
    "# Merging the DataFrames\n",
    "merged_stats = pd.concat([goal_stats, assist1_stats, assist2_stats])\n",
    "\n",
    "# Pivoting the table to get the final format\n",
    "final_df_with_not = merged_stats.pivot_table(index=['Game_ID', 'Team', 'Player_Name'], \n",
    "                                             columns='Situation', \n",
    "                                             values=['Goal_Count', 'Assist1_Count', 'Assist2_Count'], \n",
    "                                             fill_value=0).reset_index()\n",
    "\n",
    "# Flattening the multi-level column headers\n",
    "final_df_with_not.columns = ['_'.join(col).strip() for col in final_df_with_not.columns.values]\n",
    "\n",
    "# Displaying the refactored DataFrame\n",
    "final_df_with_not.head()\n",
    "\n",
    "# Rename to final_df\n",
    "final_df = final_df_with_not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the Total Points for each player to QC the data\n",
    "\n",
    "# Create a new column to calculate the total points for each player\n",
    "final_df['Total_Points'] = final_df['Goal_Count_CLOSE'] + final_df['Goal_Count_SHORT'] +final_df['Goal_Count_NOT'] \\\n",
    "    + final_df['Assist1_Count_CLOSE'] + final_df['Assist1_Count_SHORT'] + final_df['Assist1_Count_NOT'] \\\n",
    "        + final_df['Assist2_Count_CLOSE'] + final_df['Assist2_Count_SHORT'] + final_df['Assist2_Count_NOT']\n",
    "\n",
    "# Sort the DataFrame by Total_Points\n",
    "# final_df.sort_values(by='Total_Points', ascending=False).head(25)\n",
    "\n",
    "# # Reorder The columns so the Total_Points is the first column\n",
    "# final_df = final_df[['Total_Points', 'Game_ID', 'Team', 'Player_Name', 'Goal_Count_CLOSE', 'Goal_Count_SHORT', 'Assist1_Count_CLOSE', 'Assist1_Count_SHORT', 'Assist2_Count_CLOSE', 'Assist2_Count_SHORT']]\n",
    "\n",
    "# Histogram of Total Points\n",
    "final_df['Total_Points'].hist(bins=20)\n",
    "\n",
    "# Value Counts of Total Points\n",
    "final_df['Total_Points'].value_counts().sort_index()\n",
    "# Rename the Game_ID, Team, and Player_Name to drop the _ at the end\n",
    "final_df.rename(columns={'Game_ID_': 'Game_ID', 'Team_': 'Team', 'Player_Name_': 'Player_Name'}, inplace=True)\n",
    "\n",
    "\n",
    "# Describe the entire dataframe\n",
    "# final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate SCORING Score\n",
    "\n",
    "score_df = final_df\n",
    "\n",
    "# Fill Nan values with 0\n",
    "# score_df = score_df.fillna(0)\n",
    "\n",
    "non_int_cols = ['Player_Name', 'Team', 'Game_ID']\n",
    "\n",
    "# Convert all columns to int except for non_int_cols\n",
    "for col in score_df.columns:\n",
    "    if col not in non_int_cols:\n",
    "        score_df[col] = score_df[col].astype(int)\n",
    "\n",
    "# Calculate the Scoring Score\n",
    "## Factors - GOALS = .555, ASSIST1 = .455, ASSIST2 = .355\n",
    "## CLOSE GAME MULTIPLIER = 1.5\n",
    "## SH GOAL MULTIPLIER = 1.75\n",
    "\n",
    "## Rename the columns to match the expected Names\n",
    "# dict = {''}\n",
    "\n",
    "\n",
    "############ OLD COLUMN NAMES ############\n",
    "score_df['SCORING_Score'] = score_df['Goal_Count_CLOSE'] * 1.5 * 0.555 + score_df['Assist1_Count_CLOSE'] * 1.5 * 0.455 + score_df['Assist2_Count_CLOSE'] * 1.5 * 0.355 + \\\n",
    "                            score_df['Goal_Count_SHORT'] * 1.75 * 0.555 + score_df['Assist1_Count_SHORT'] * 1.75 * 0.455 + score_df['Assist2_Count_SHORT'] * 1.75 * 0.355 + \\\n",
    "                            score_df['Goal_Count_NOT'] * 0.555 + score_df['Assist1_Count_NOT'] * 0.455 + score_df['Assist2_Count_NOT'] * 0.355\n",
    "\n",
    "# Rename Player_Name to Player\n",
    "score_df.rename(columns={'Player_Name': 'Player'}, inplace=True)\n",
    "\n",
    "# score_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine to single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMBINE ALL THE DATAFRAMES TOGETHER\n",
    "\n",
    "# Merge the shots_df and df_fo DataFrames together\n",
    "df_combined = pd.merge(shots_df, df_fo, how='outer', on=['Team', 'Player', 'Game_ID'])\n",
    "\n",
    "# Merge the df_combined and df_team DataFrames together\n",
    "df_combined = pd.merge(df_combined, df_team, how='outer', on=['Team', 'Player', 'Game_ID'])\n",
    "\n",
    "# Merge the df_combined and df_pen DataFrames together\n",
    "df_combined = pd.merge(df_combined, df_pen, how='outer', on=['Team', 'Player', 'Game_ID'])\n",
    "\n",
    "# Merge the df_combined and score_df DataFrames together\n",
    "df_combined = pd.merge(df_combined, score_df, how='outer', on=['Team', 'Player', 'Game_ID'])\n",
    "\n",
    "# Fill any NaN values with 0\n",
    "df_combined = df_combined.fillna(0)\n",
    "\n",
    "# Filter To Just The SCORE Columns\n",
    "keep_col = ['Team', 'Player', 'Game_ID', 'SCORING_Score', 'SHOT_Score', 'FACEOFF_Score', 'TEAM_Score', 'PENALTY_Score']\n",
    "df_combined = df_combined[keep_col]\n",
    "\n",
    "# Calulate the TOTAL Score\n",
    "## SCORE = \"TOTAL_Score = SHOT_Score + FACEOFF_Score + TEAM_Score - PENALTY_Score\"\n",
    "df_combined['TOTAL_Score'] = df_combined['SCORING_Score'] \\\n",
    "    + df_combined['SHOT_Score'] + df_combined['FACEOFF_Score'] \\\n",
    "        + df_combined['TEAM_Score'] - df_combined['PENALTY_Score']\n",
    "\n",
    "# df_combined.head(10)\n",
    "\n",
    "# df_combined.sample(10)\n",
    "# # df_combined.info()\n",
    "\n",
    "# df_combined.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning and whatnot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all 0s with NaN\n",
    "df_combined = df_combined.replace(0, np.nan)\n",
    "\n",
    "\n",
    "# Score Distribution\n",
    "df_combined['TOTAL_Score'].describe()\n",
    "\n",
    " # Histogram Plot of Score Distribution\n",
    "df_combined['TOTAL_Score'].hist(bins=30)\n",
    "\n",
    "# Histograms of all the scores\n",
    "df_combined.hist(bins=30, figsize=(20,15))\n",
    "\n",
    "# Replace all 0s with NaN\n",
    "df_combined = df_combined.replace(0, np.nan)\n",
    "\n",
    "# Drop all NaN values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by Player and Calculate Grand Totals for Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Player Season Totals\n",
    "df_working = df_combined.copy()\n",
    "\n",
    "# Replace non-breaking spaces with regular spaces in the Player column of compiled_df\n",
    "df_working['Player'] = df_working['Player'].str.replace('\\xa0', ' ')\n",
    "\n",
    "# Strip Whitespace from Player and Team because seeing double Rows for some players\n",
    "df_working['Player'] = df_working['Player'].str.strip()\n",
    "df_working['Team'] = df_working['Team'].str.strip()\n",
    "\n",
    "# Group by Player and Team to get the total scores for each player\n",
    "df_working = df_working.groupby(['Player', 'Team']).sum().reset_index()\n",
    "\n",
    "# Sort the DataFrame by TOTAL_Score\n",
    "df_working = df_working.sort_values(by='TOTAL_Score', ascending=False)\n",
    "\n",
    "\n",
    "# df_working.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histograms of each column to compare distrobution of totals\n",
    "df_working.hist(bins=30, figsize=(20,15))\n",
    "df_working.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OutPut CSV Files FOr Each Team "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename datafram\n",
    "df = df_combined\n",
    "\n",
    "# Take out those annoying character if there are any\n",
    "# Replace non-breaking spaces with regular spaces in the Player column of compiled_df\n",
    "df['Player'] = df['Player'].str.replace('\\xa0', ' ')\n",
    "# Flatten the rows with matching Player\n",
    "df = df.groupby(['Team', 'Player', 'Game_ID']).sum().reset_index()\n",
    "\n",
    "# Rename TOTAL_Score to Game_Score\n",
    "df.rename(columns={'TOTAL_Score': 'Game_Score'}, inplace=True)\n",
    "\n",
    "# Generate team-specific tables using a pivot table\n",
    "team_tables = {}\n",
    "\n",
    "unique_teams = df['Team'].unique()\n",
    "\n",
    "for team in unique_teams:\n",
    "    team_df = df[df['Team'] == team]\n",
    "    pivot_table = team_df.pivot(index='Player', columns='Game_ID', values='Game_Score')\n",
    "    team_tables[team] = pivot_table\n",
    "\n",
    "\n",
    "# Print List of Teams\n",
    "unique_teams\n",
    "\n",
    "\n",
    "# Fill NaN values with 0\n",
    "for team in unique_teams:\n",
    "    team_tables[team] = team_tables[team].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the column names of all the team tables\n",
    "# Want to remove:\n",
    "# - all digits\n",
    "# - all Dashes\n",
    "# - the teams name\n",
    "\n",
    "# Create a dictionary to store the new column names\n",
    "new_column_names = {}\n",
    "\n",
    "# Loop through each team table\n",
    "for team in unique_teams:\n",
    "    # Create a list to store the new column names\n",
    "    new_column_names[team] = []\n",
    "    \n",
    "    # Loop through each column name\n",
    "    for column_name in team_tables[team].columns:\n",
    "\n",
    "        # Remove all digits from the column name\n",
    "        new_column_name = ''.join([i for i in column_name if not i.isdigit()])\n",
    "        \n",
    "        # Remove all dashes from the column name\n",
    "        new_column_name = new_column_name.replace('-', '')\n",
    "        \n",
    "        # Remove the team name from the column name\n",
    "        new_column_name = new_column_name.replace(str(team), '')\n",
    "        \n",
    "        # Add the new column name to the list\n",
    "        new_column_names[team].append(new_column_name)\n",
    "    \n",
    "    # Assign the new column names to the team table\n",
    "    team_tables[team].columns = new_column_names[team]\n",
    "\n",
    "## Add the team name to each table\n",
    "for team in unique_teams:\n",
    "    team_tables[team]['Team'] = team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save each table to a csv with the team name and the season\n",
    "\n",
    "## Folder to save to\n",
    "# folder_path = '../TEMP/2022_csv_dump/' # Folder for 2022\n",
    "folder_path = '../TEMP/GAME_SCORE_dump/' # Folder for 2023 Year To Date\n",
    "\n",
    "# Create folder pate if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "    \n",
    "## Loop through each team and save the csv\n",
    "for team in unique_teams:\n",
    "    team_tables[team].to_csv(f'{folder_path}{team}_GAME_SCORES.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
