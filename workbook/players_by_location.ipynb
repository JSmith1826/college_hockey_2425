{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Players by Location\n",
    "- create a map using folium that plots the hometown location of every US (and maybe Canadian) player in D1 (2024-25 season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "\n",
    "## System Libraries\n",
    "import sys\n",
    "import os\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "# Plotting and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "## Map visualization\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from folium.plugins import HeatMap\n",
    "from folium.features import CustomIcon\n",
    "\n",
    "### ROSTERFILE\n",
    "# Path to the roster file\n",
    "roster_path = os.path.join('..', 'data', 'roster_2024_current_v3.csv')\n",
    "roster_df = pd.read_csv(roster_path) # Load the roster file\n",
    "\n",
    "\n",
    "############### NOT USED IN THIS SCRIPT ################\n",
    "#### 2023 STATS FILE\n",
    "# stats_path = os.path.join('..', 'data', 'player_stats_2023_v1.csv')\n",
    "# stats_df = pd.read_csv(stats_path) # Load the stats file\n",
    "\n",
    "########## ROSTER SET WITH 2023 STATS FILE\n",
    "roster_stats_path = os.path.join('..', 'data', 'roster_2024_with_2023_stats.csv')\n",
    "roster_stats_df = pd.read_csv(roster_stats_path) # Load the roster file with stats\n",
    "\n",
    "\n",
    "### SCHOOL INFO TABLE FOR LOGO PATHS\n",
    "school_info_path = os.path.join('..', 'data', 'arena_school_info.csv')\n",
    "school_info_df = pd.read_csv(school_info_path) # Load school info\n",
    "\n",
    "# Path to logo folder\n",
    "logo_folder = os.path.join('..', 'images', 'logos')\n",
    "\n",
    "### SHAPEFILES\n",
    "# Path to .geojson file with State Boundries\n",
    "geojson_path = os.path.join('..', 'data', 'vault', 'combined-us-canada.geojson')\n",
    "# Load the states shapefile\n",
    "gdf_states = gpd.read_file(geojson_path)\n",
    "\n",
    "# Path to shapefile with all US counties\n",
    "shapefile_path = os.path.join('..', 'data', 'vault', 'cb_2018_us_county_500k.shp')\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "# Set the initial CRS (assuming it's in EPSG:4326, but you may need to verify the original CRS)\n",
    "gdf = gdf.set_crs(epsg=4326)\n",
    "\n",
    "## CHECK SHAPEFILES FOR COMPATIBILITY\n",
    "# Set the CRS for both dataframes if it's missing\n",
    "if gdf.crs is None:\n",
    "    gdf.set_crs(epsg=4326, inplace=True)  # Assuming coordinates are in WGS 84 (lat/lon)\n",
    "\n",
    "if gdf_states.crs is None:\n",
    "    gdf_states.set_crs(epsg=4326, inplace=True)  # Assuming coordinates are in WGS 84 (lat/lon)\n",
    "\n",
    "\n",
    "\n",
    "# Check the first few rows of the DataFrames\n",
    "# roster_df.head()\n",
    "# gdf_states.head()\n",
    "# gdf.head()\n",
    "school_info_df.head()\n",
    "roster_stats_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up and prepare the data for mapping\n",
    "\n",
    "# Drop rows with missing geographic data\n",
    "geo_columns = ['City', 'State_Province', 'Country']\n",
    "roster_cleaned_df = roster_df.dropna(subset=geo_columns)\n",
    "\n",
    "#########################\n",
    "###### TEST #####\n",
    "## Sub the roster with stats file for the cleaned roster\n",
    "roster_cleaned_df = roster_stats_df.copy()\n",
    "\n",
    "# Create a simplified dataframe with relevant location columns for easier mapping\n",
    "# roster_cleaned_df = roster_cleaned_df[['Current Team', 'First_Name', 'Last_Name', 'City', 'State_Province', 'Country']]\n",
    "\n",
    "# Group by City, State_Province, and Country to count the number of players from each location\n",
    "location_counts = roster_cleaned_df.groupby(['City', 'State_Province', 'Country']).size().reset_index(name='Player_Count')\n",
    "\n",
    "\n",
    "## CHECK DATA TRANSFORMATION\n",
    "# # Display the cleaned and grouped dataframe\n",
    "# location_counts.head()\n",
    "# # Sort the location counts in descending order\n",
    "location_counts_sorted = location_counts.sort_values(by='Player_Count', ascending=False)\n",
    "location_counts_sorted.head(10) # Display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geocode Conversion\n",
    "- 9-26-24 NOTE - Some issuse spoted with Geocoder. Canton, MI is being assigned a lat and long somewhere in Lansing.\n",
    "    - MSU's Russian player comes from far Eastern Russia and does not appear on map at all\n",
    "- takes the names of places and converts to lat long coordinates\n",
    "- uses a rate limiter to avoid overloading service\n",
    "- takes about 15 min to run - output is saved in the data folder - load from there "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GEOCODING USING GOOGLE MAPS API \n",
    "\n",
    "import googlemaps\n",
    "import pandas as pd\n",
    "import config\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the Google Places API client\n",
    "gmaps = googlemaps.Client(key=config.g_key)\n",
    "\n",
    "def geocode_google_places(row):\n",
    "    try:\n",
    "        location_str = f\"{row['City']}, {row['State_Province']}, {row['Country']}\"\n",
    "        print(f\"Querying location: {location_str}\")  # Debugging output\n",
    "        geocode_result = gmaps.geocode(location_str)\n",
    "        \n",
    "        # Check the API response\n",
    "        print(f\"Geocode result: {geocode_result}\")  # Debugging output\n",
    "        \n",
    "        # Check if we got a valid result\n",
    "        if geocode_result and 'geometry' in geocode_result[0]:\n",
    "            location = geocode_result[0]['geometry']['location']\n",
    "            return pd.Series([location['lat'], location['lng']])\n",
    "        else:\n",
    "            return pd.Series([None, None])  # Return None if no valid result\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered: {e}\")  # Debugging output\n",
    "        return pd.Series([None, None])  # Handle errors gracefully\n",
    "\n",
    "## ORIG CODE\n",
    "# # Function to geocode a city and state combination using Google Places API\n",
    "# def geocode_google_places(row):\n",
    "#     try:\n",
    "#         location_str = f\"{row['City']}, {row['State_Province']}, {row['Country']}\"\n",
    "#         geocode_result = gmaps.geocode(location_str)\n",
    "        \n",
    "#         # Check if we got a valid result\n",
    "#         if geocode_result and 'geometry' in geocode_result[0]:\n",
    "#             location = geocode_result[0]['geometry']['location']\n",
    "#             return pd.Series([location['lat'], location['lng']])\n",
    "#         else:\n",
    "#             return pd.Series([None, None])  # Return None if no valid result\n",
    "#     except Exception as e:\n",
    "#         return pd.Series([None, None])  # Handle errors gracefully\n",
    "\n",
    "# Apply the geocode function to the data using Google Places API\n",
    "location_counts[['Latitude', 'Longitude']] = location_counts.apply(geocode_google_places, axis=1)\n",
    "\n",
    "# Filter out rows with missing coordinates if needed\n",
    "location_counts_cleaned = location_counts.dropna(subset=['Latitude', 'Longitude'])\n",
    "\n",
    "# Display the cleaned data with coordinates\n",
    "location_counts_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LCHECK FOR AND LOAD GEOCODED DATA BEFORE RUNNING - THIS TAKES 15+ MINUTES\n",
    "\n",
    "# from geopy.geocoders import Nominatim\n",
    "# from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "# # Initialize geocoder\n",
    "# geolocator = Nominatim(user_agent=\"college_hockey_map\")\n",
    "\n",
    "# # Create a rate-limited geocode function to avoid overloading the service\n",
    "# geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "\n",
    "# # Function to geocode a city and state combination\n",
    "# def geocode_location(row):\n",
    "#     try:\n",
    "#         location_str = f\"{row['City']}, {row['State_Province']}, {row['Country']}\"\n",
    "#         location = geocode(location_str)\n",
    "#         if location:\n",
    "#             return pd.Series([location.latitude, location.longitude])\n",
    "#         else:\n",
    "#             return pd.Series([None, None])\n",
    "#     except Exception as e:\n",
    "#         return pd.Series([None, None])\n",
    "\n",
    "# # Apply the geocode function to the data\n",
    "# location_counts[['Latitude', 'Longitude']] = location_counts.apply(geocode_location, axis=1)\n",
    "\n",
    "# # Filter out rows with missing coordinates\n",
    "# location_counts_cleaned = location_counts.dropna(subset=['Latitude', 'Longitude'])\n",
    "\n",
    "# # Display cleaned data with coordinates\n",
    "# location_counts_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Geocoded Data to CSV to avoid having to run geocoding repeatedly\n",
    "\n",
    "# # Save the cleaned and geocoded data to a CSV file\n",
    "# output_path = os.path.join('..', 'data', 'player_geocoded_location_counts_v3.0.csv')\n",
    "# location_counts_cleaned.to_csv(output_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the previously geocoded table from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path to the geocoded data\n",
    "geocoded_data_path = os.path.join('..', 'data', 'player_geocoded_location_counts_v3.0.csv')\n",
    "location_counts_cleaned = pd.read_csv(geocoded_data_path)\n",
    "\n",
    "##### HOTFIX 9-30-24\n",
    "### Canton, MI is not being geocoded correctly.  I will manually update the coordinates for this location\n",
    "# 42.309147747338855, -83.47945385169615\n",
    "location_counts_cleaned.loc[location_counts_cleaned['City'] == 'Canton', 'Latitude'] = 42.309147747338855\n",
    "location_counts_cleaned.loc[location_counts_cleaned['City'] == 'Canton', 'Longitude'] = -83.47945385169615\n",
    "##### STOCKHOLM, SWEDEN IS GEOCODED TO STOCKHOLM MAINE \n",
    "# 59.32736015579712, 18.058473904470663\n",
    "location_counts_cleaned.loc[location_counts_cleaned['City'] == 'Stockholm', 'Latitude'] = 59.32736015579712\n",
    "location_counts_cleaned.loc[location_counts_cleaned['City'] == 'Stockholm', 'Longitude'] = 18.058473904470663\n",
    "########## FAIRBUILT, MN\n",
    "# 44.29627256152846, -93.27016563553472\n",
    "location_counts_cleaned.loc[location_counts_cleaned['City'] == 'Faribault', 'Latitude'] = 44.29627256152846\n",
    "location_counts_cleaned.loc[location_counts_cleaned['City'] == 'Faribault', 'Longitude'] = -93.27016563553472\n",
    "\n",
    "\n",
    "# Check the first few rows of the geocoded data\n",
    "# location_counts_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Player name, team, ect data into the location counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add 2023 stats to current roster\n",
    "- Going to do this in a seperate notebook for ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roster_cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge roster_df with location_counts_cleaned\n",
    "merged_df = pd.merge(roster_cleaned_df, location_counts_cleaned, \n",
    "                     on=['City', 'State_Province', 'Country'], how='inner')\n",
    "\n",
    "### NOT USING THIS TOOLTIP FORMAT - CREATING TOOLTIP IN THE MAP FUNCTION\n",
    "# # Prepare the tooltip text with a header row for each location\n",
    "# merged_df['Tooltip'] = merged_df.apply(\n",
    "#     lambda row: f\"Name - Position - Year - Team<br>{row['First_Name']} {row['Last_Name']} - {row['Position']} - {row['Yr']} - {row['Current Team']}\", axis=1\n",
    "# )\n",
    "\n",
    "# # Display the merged dataframe to check if the tooltips are correctly generated\n",
    "# merged_df[['First_Name', 'Last_Name', 'Tooltip', 'Latitude', 'Longitude']].head()\n",
    "#\n",
    "### Change the Position name and Yr to be more readable in the tooltip\n",
    "merged_df['Position'] = merged_df['Position'].replace({'Forwards': 'Forward', 'Defensemen':'Defense', 'Goaltenders': 'Goalie'})\n",
    "merged_df['Yr'] = merged_df['Yr'].replace({'Fr': 'Freshman', 'So': 'Sophomore', 'Jr': 'Junior', 'Sr': 'Senior', 'Gr': 'Graduate'})\n",
    "# merged_df.head(35)\n",
    "########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map with team logo as markers\n",
    "- thurs 9-26-24 start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roster_df.head()\n",
    "# merged_df.head(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Function to apply a circular offset to markers with the same location\n",
    "def add_circular_offset(lat, lon, count, index, radius=0.007):\n",
    "    \"\"\"\n",
    "    Distributes markers in a circular pattern around a central point.\n",
    "    The radius increases slightly with the number of markers to prevent overlap.\n",
    "    \"\"\"\n",
    "    # Calculate angle in radians (360 degrees divided by number of markers)\n",
    "    angle = (360 / count) * index\n",
    "    radians = math.radians(angle)\n",
    "\n",
    "    # Dynamic adjustment of the radius: the more markers, the larger the radius\n",
    "    dynamic_radius = radius * (1 + (count / 5))  # Scale the radius based on the number of markers\n",
    "\n",
    "    # Offset latitude and longitude using circular placement\n",
    "    lat_offset = lat + (dynamic_radius * math.cos(radians))  # Offset based on cosine\n",
    "    lon_offset = lon + (dynamic_radius * math.sin(radians))  # Offset based on sine\n",
    "\n",
    "    return lat_offset, lon_offset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### REFACTOR W 01 PREVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign unique index per player in each city group\n",
    "merged_df['city_group_index'] = merged_df.groupby(['City', 'State_Province', 'Country']).cumcount()\n",
    "\n",
    "# Assign 'Player_Count' per city directly to 'merged_df' using 'transform'\n",
    "merged_df['Player_Count'] = merged_df.groupby(['City', 'State_Province', 'Country'])['First_Name'].transform('count')\n",
    "\n",
    "# Set Logo Size (tuple of width and height in pixels)\n",
    "logo_size = (55, 55)  # Adjust as needed\n",
    "\n",
    "# Convert all number columns to int\n",
    "int_columns = ['No', 'Height_Inches', 'Wt', 'Draft_Year', 'D_Round', \n",
    "               'G', 'A', 'Pts', 'plus_minus', 'Sh', 'PIM', 'Games_Played']\n",
    "\n",
    "for col in int_columns:\n",
    "    merged_df[col] = merged_df[col].astype('Int64')\n",
    "\n",
    "import math\n",
    "\n",
    "def create_map_with_team_logos(merged_df, school_info_df, logo_folder, gdf_states, map_center=[45.0, -93.0], zoom_start=4):\n",
    "    # Initialize the map\n",
    "    folium_map = folium.Map(location=map_center, zoom_start=zoom_start, tiles='OpenStreetMap', name='Default Map')\n",
    "\n",
    "    # ---- ADD BASE LAYERS ----\n",
    "    # Add additional base layers (you can add more as needed)\n",
    "    # folium.TileLayer('OpenStreetMap', name='Default Map').add_to(folium_map)\n",
    "    # folium.TileLayer('Stamen Terrain', name='Terrain', attr=\".\").add_to(folium_map)\n",
    "    # folium.TileLayer('Stamen Toner', name='Toner', attr=\".\").add_to(folium_map)\n",
    "    folium.TileLayer('CartoDB dark_matter', name='Dark Theme', attr=\".\").add_to(folium_map)\n",
    "    folium.TileLayer('CartoDB positron', name='Light Theme', attr=\".\").add_to(folium_map)\n",
    "    \n",
    "\n",
    "    # ---- ADD CHOROPLETH LAYER ----\n",
    "    # Create 'state_counts_df' from 'merged_df'\n",
    "    state_counts = merged_df['State_Province'].value_counts()\n",
    "    state_counts_df = pd.DataFrame(state_counts).reset_index()\n",
    "    state_counts_df.columns = ['State_Province', 'Player_Count']\n",
    "\n",
    "    # Create Custom Bins for Choropleth to better control look\n",
    "    # Define custom bins to handle the wide distribution\n",
    "    custom_bins = [0, 1, 5, 10, 20, 50, 100, 200, 250] # Adjust as needed\n",
    "\n",
    "    # Convert the GeoDataFrame to GeoJSON using __geo_interface__\n",
    "    geojson_data = gdf_states.__geo_interface__\n",
    "\n",
    "    ### ORIGINAL CODE ###\n",
    "    # Add the Choropleth directly to the map with a name for LayerControl\n",
    "    folium.Choropleth(\n",
    "        geo_data=geojson_data,\n",
    "        data=state_counts_df,\n",
    "        columns=['State_Province', 'Player_Count'],\n",
    "        key_on='feature.properties.name',  # Adjust this if necessary\n",
    "        fill_color='YlGn',\n",
    "        fill_opacity=0.5,\n",
    "        line_opacity=0.2,\n",
    "        legend_name='Number of Players by State/Province',\n",
    "        bins=custom_bins,  # Apply custom bins\n",
    "        reset=True,  # Ensure the choropleth is reset based on new bins\n",
    "        name='Shade by Player Count'\n",
    "    ).add_to(folium_map)\n",
    "\n",
    "    ############## NEW CODE ##############\n",
    "    # ---- ADD STATE LABELS LAYER ----\n",
    "    # Merge 'state_counts_df' with 'gdf_states' to get centroids\n",
    "    gdf_states_subset = gdf_states[['name', 'geometry']]  # Adjust 'name' if your GeoDataFrame has a different column name\n",
    "    state_counts_gdf = gdf_states_subset.merge(state_counts_df, left_on='name', right_on='State_Province')\n",
    "\n",
    "    # Calculate centroids\n",
    "    state_counts_gdf['centroid'] = state_counts_gdf.geometry.centroid\n",
    "\n",
    "    # Create a FeatureGroup for the labels\n",
    "    labels_layer = folium.FeatureGroup(name='Players Count by State')\n",
    "\n",
    "    # Add labels to the labels_layer\n",
    "    for idx, row in state_counts_gdf.iterrows():\n",
    "        # Get centroid coordinates\n",
    "        lat = row['centroid'].y\n",
    "        lon = row['centroid'].x\n",
    "        # Get player count\n",
    "        player_count = row['Player_Count']\n",
    "        # Create a text label\n",
    "        label = folium.Marker(\n",
    "            location=[lat, lon],\n",
    "            icon=folium.DivIcon(\n",
    "                html=f'''\n",
    "                    <div style=\"\n",
    "                        font-family: Optima, sans-serif;\n",
    "                        font-weight: bold;\n",
    "                        font-size: 16px;\n",
    "                        color: black;\n",
    "                        text-align: center;\n",
    "                        \n",
    "                        padding: 2px;\n",
    "                        \n",
    "                    \">\n",
    "                        {player_count}\n",
    "                    </div>\n",
    "                '''\n",
    "            )\n",
    "        )\n",
    "        labels_layer.add_child(label)\n",
    "\n",
    "    # Add the labels_layer to the map\n",
    "    labels_layer.add_to(folium_map)\n",
    "\n",
    "\n",
    "########### NOT BIG FAN OF COLOR SCHEME\n",
    "    # # ---- ADD HEATMAP LAYER ----\n",
    "    # # Create heat_data from merged_df\n",
    "    # heat_data = [[row['Latitude'], row['Longitude']] for idx, row in merged_df.iterrows()]\n",
    "\n",
    "    # # Create a FeatureGroup for the heatmap layer\n",
    "    # heatmap_layer = folium.FeatureGroup(name='Heatmap')\n",
    "\n",
    "    # # Define a custom gradient for better color transitions\n",
    "    # custom_gradient = {\n",
    "    #     0.2: '#ADD8E6',  # Light Blue for low intensity\n",
    "    #     0.4: '#00FF00',  # Green for mid-low intensity\n",
    "    #     0.6: '#FFFF00',  # Yellow for mid-high intensity\n",
    "    #     0.8: '#FFA500',  # Orange for high intensity\n",
    "    #     1.0: '#FF0000'   # Red for maximum intensity\n",
    "    # }\n",
    "\n",
    "    # # Add the HeatMap to the FeatureGroup with adjusted parameters\n",
    "    # HeatMap(\n",
    "    #     heat_data, \n",
    "    #     radius=15,                # Increase radius for smoother heat blobs\n",
    "    #     blur=15,                  # Slightly increase blur to smooth transitions\n",
    "    #     max_intensity=100,         # Adjust max intensity for better scaling\n",
    "    #     gradient=custom_gradient, # Use the custom gradient\n",
    "    #     min_opacity=0.4           # Slight opacity for low intensity\n",
    "    # ).add_to(heatmap_layer)\n",
    "\n",
    "    # # Add the heatmap layer to the map\n",
    "    # heatmap_layer.add_to(folium_map)\n",
    "    \n",
    "    \n",
    "    # ---- ADD HEATMAP LAYER ----\n",
    "    # Create heat_data from merged_df\n",
    "    heat_data = [[row['Latitude'], row['Longitude']] for idx, row in merged_df.iterrows()]\n",
    "\n",
    "    # Create a FeatureGroup for the heatmap layer\n",
    "    heatmap_layer = folium.FeatureGroup(name='Heatmap')\n",
    "\n",
    "    # Add the HeatMap to the FeatureGroup\n",
    "    HeatMap(heat_data, radius=25, blur=15, max_intensity=20).add_to(heatmap_layer)\n",
    "\n",
    "    # Add the heatmap layer to the map\n",
    "    heatmap_layer.add_to(folium_map)\n",
    "\n",
    "    # ---- MARKER CLUSTER LAYER ----\n",
    "    cluster_group = folium.FeatureGroup(name='Individual Players', control=True, show=False)\n",
    "    marker_cluster = MarkerCluster(\n",
    "        spiderfy_on_max_zoom=True,\n",
    "        show_coverage_on_hover=False,\n",
    "        max_cluster_radius=20,\n",
    "        disableClusteringAtZoom=14,\n",
    "        animateAddingMarkers=True,\n",
    "        zoomToBoundsOnClick=True\n",
    "    ).add_to(cluster_group)\n",
    "\n",
    "    # Compute the mean latitude and longitude for centering the map\n",
    "    Latitude = merged_df['Latitude'].mean()\n",
    "    Longitude = merged_df['Longitude'].mean()\n",
    "\n",
    "    # Create the map centered on the computed mean Latitude and Longitude\n",
    "    map_instance = folium.Map(location=[Latitude, Longitude], zoom_start=12)\n",
    "\n",
    "    # Add the cluster group to the map but initially hidden\n",
    "    map_instance.add_child(cluster_group)\n",
    "\n",
    "    # Define a custom script to toggle the visibility of the cluster group on zoom\n",
    "    map_instance.get_root().html.add_child(folium.Element(f'''\n",
    "        <script>\n",
    "            var clusterLayer = {cluster_group.get_name()};\n",
    "            var map = {map_instance.get_name()};\n",
    "            map.on('zoomend', function() {{\n",
    "                if (map.getZoom() >= 14) {{\n",
    "                    if (!map.hasLayer(clusterLayer)) {{\n",
    "                        map.addLayer(clusterLayer);\n",
    "                    }}\n",
    "                }} else {{\n",
    "                    if (map.hasLayer(clusterLayer)) {{\n",
    "                        map.removeLayer(clusterLayer);\n",
    "                    }}\n",
    "                }}\n",
    "            }});\n",
    "        </script>\n",
    "    '''))\n",
    "\n",
    "\n",
    "    # Loop through the merged_df to place markers\n",
    "    for idx, row in merged_df.iterrows():\n",
    "        # Retrieve team and logo information\n",
    "        team_name = row['Team_2024']\n",
    "        logo_info = school_info_df[school_info_df['Team'] == team_name]['logo_abv'].values\n",
    "\n",
    "        if len(logo_info) > 0:\n",
    "            logo_abv = logo_info[0]\n",
    "            logo_path = os.path.join(logo_folder, f\"{logo_abv}.png\")\n",
    "\n",
    "            if os.path.exists(logo_path):\n",
    "                logo_icon = CustomIcon(logo_path, icon_size=logo_size)\n",
    "\n",
    "                player_count = row['Player_Count']\n",
    "                current_index = row['city_group_index']\n",
    "\n",
    "                # Apply circular offset for overlapping markers\n",
    "                if player_count > 1:\n",
    "                    lat_offset, lon_offset = add_circular_offset(\n",
    "                        row['Latitude'], row['Longitude'], player_count, current_index\n",
    "                    )\n",
    "                else:\n",
    "                    lat_offset, lon_offset = row['Latitude'], row['Longitude']  # No offset if only one player\n",
    "\n",
    "                # Enhance the tooltip with player information, including hometown\n",
    "                tooltip_html = f\"\"\"\n",
    "                <div style=\"font-size: 14px; font-family: Arial;\">\n",
    "                    <strong>{row['First_Name']} {row['Last_Name']} - {row['Team_2024']}</strong><br>\n",
    "                    {row['Hometown']}<br>\n",
    "                    {row['Yr']} {row['Position']}<br>\n",
    "                    {f\"<div style='font-size: 12px; color: gray; margin-top: 5px;'>2023 SEASON:<br> {row['Games_Played']} GP, {row['G']} G, {row['A']} A, {row['Pts']} PTS, {row['PIM']} PIM</div>\" if pd.notna(row['Games_Played']) else \"\"}\n",
    "                </div>\n",
    "                \"\"\"\n",
    "\n",
    "###################### OLD / ORIG CODE ###########\n",
    "                # <div style=\"font-size: 14px; font-family: Arial;\">\n",
    "                #     <strong>{row['First_Name']} {row['Last_Name']} - {row['Team_2024']}</strong><br>\n",
    "                #     {row['Hometown']}<br>\n",
    "                #     {row['Yr']} {row['Position']}<br>\n",
    "                #     2023 STATS: {row['Games_Played']} GP, {row['G']} G, {row['A']} A, {row['Pts']} PTS\n",
    "                    \n",
    "                # </div>\n",
    "                # \"\"\"\n",
    "\n",
    "                # Add player marker with the custom logo icon and enhanced tooltip\n",
    "                folium.Marker(\n",
    "                    location=[lat_offset, lon_offset],\n",
    "                    tooltip=folium.Tooltip(tooltip_html),\n",
    "                    icon=logo_icon\n",
    "                ).add_to(marker_cluster)\n",
    "\n",
    "    # Add the marker cluster layer to the map\n",
    "    cluster_group.add_to(folium_map)\n",
    "\n",
    "    # ---- ADD LAYER CONTROL ----\n",
    "            \n",
    "    folium.LayerControl().add_to(folium_map)\n",
    "\n",
    "    # Inject custom CSS for styling the LayerControl\n",
    "    custom_css = \"\"\"\n",
    "    <style>\n",
    "    /* Style for the Layer Control List */\n",
    "    .leaflet-control-layers-list {\n",
    "        font-size: 18px;  /* Increase font size */\n",
    "        line-height: 1.5; /* Ensure adequate spacing between lines */\n",
    "    }\n",
    "\n",
    "    /* Style for the checkboxes and radio buttons */\n",
    "    .leaflet-control-layers input[type=\"radio\"], \n",
    "    .leaflet-control-layers input[type=\"checkbox\"] {\n",
    "        transform: scale(1.5);  /* Scale the size of the checkbox/radio button */\n",
    "        margin-right: 8px;      /* Add space between the button and label */\n",
    "    }\n",
    "\n",
    "    /* Optional: Style the background of the layer control to make it stand out */\n",
    "    .leaflet-control-layers {\n",
    "        background-color: white;  /* Ensure the control has a visible background */\n",
    "        border-radius: 5px;       /* Slight rounding of the control edges */\n",
    "        padding: 10x;\n",
    "        box-shadow: 0px 0px 5px rgba(0,0,0,0.3);  /* Add a shadow for better visibility */\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "\n",
    "    # Add the custom CSS to the map's HTML\n",
    "    folium_map.get_root().html.add_child(folium.Element(custom_css))\n",
    "\n",
    "    # Return the map after processing all markers\n",
    "    return folium_map\n",
    "\n",
    "# Assuming 'gdf_states' is already defined in your code\n",
    "enhanced_player_map = create_map_with_team_logos(merged_df, school_info_df, logo_folder, gdf_states)\n",
    "\n",
    "# Save the map to an HTML file for visualization\n",
    "enhanced_map_file_path = os.path.join('..', 'TEMP', 'player_origin_map_with_stats_v3.html')\n",
    "enhanced_player_map.save(enhanced_map_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Very Simple V0.1 Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Function to create the player origin map with tooltips\n",
    "# def create_player_origin_map_with_tooltip(data, map_center=[45.0, -93.0], zoom_start=4):\n",
    "#     # Map settings block for customization\n",
    "#     folium_map = folium.Map(location=map_center, zoom_start=zoom_start, tiles='cartodb positron')\n",
    "    \n",
    "#     # Create MarkerCluster\n",
    "#     marker_cluster = MarkerCluster(disableClusteringAtZoom=10).add_to(folium_map)\n",
    "\n",
    "#     # Add player markers with tooltips to the MarkerCluster\n",
    "#     for _, row in data.iterrows():\n",
    "#         folium.Marker(\n",
    "#             location=[row['Latitude'], row['Longitude']],\n",
    "#             tooltip=row['Tooltip']\n",
    "#         ).add_to(marker_cluster)\n",
    "    \n",
    "#     return folium_map\n",
    "\n",
    "# # Create the player origins map with tooltips\n",
    "# player_map = create_player_origin_map_with_tooltip(merged_df)\n",
    "\n",
    "# # # Save the map to an HTML file for visualization\n",
    "# # map_file_path = os.path.join('..', 'TEMP', 'player_origin_map_v1.html')\n",
    "# # player_map.save(map_file_path)\n",
    "\n",
    "# # map_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map with Custom Java for Cluster behavior\n",
    "- not behaving well - probably not worth the time to get smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to create the player origin map with custom cluster zoom levels\n",
    "# def create_player_origin_map_with_tooltip(data, map_center=[45.0, -93.0], zoom_start=4):\n",
    "#     # Map settings block for customization\n",
    "#     folium_map = folium.Map(location=map_center, zoom_start=zoom_start, tiles='cartodb positron')\n",
    "    \n",
    "#     # Create MarkerCluster without adding it to the map right away\n",
    "#     marker_cluster = MarkerCluster().add_to(folium.FeatureGroup(name=\"Clusters\"))\n",
    "\n",
    "#     # Add player markers with tooltips to the MarkerCluster\n",
    "#     for _, row in data.iterrows():\n",
    "#         folium.Marker(\n",
    "#             location=[row['Latitude'], row['Longitude']],\n",
    "#             tooltip=row['Tooltip']\n",
    "#         ).add_to(marker_cluster)\n",
    "\n",
    "#     # Custom JavaScript to toggle marker clusters based on zoom level\n",
    "#     toggle_cluster_js = \"\"\"\n",
    "#     function toggleClusters(map) {\n",
    "#         var clusterGroup = map._layers[Object.keys(map._layers).find(key => map._layers[key].options && map._layers[key].options.spiderfyOnMaxZoom !== undefined)];\n",
    "        \n",
    "#         map.on('zoomend', function () {\n",
    "#             var currentZoom = map.getZoom();\n",
    "            \n",
    "#             // Define the zoom range where clusters should be shown\n",
    "#             var minZoom = 5;  // Set the zoom level when clusters appear\n",
    "#             var maxZoom = 7;  // Set the zoom level when clusters disappear again\n",
    "            \n",
    "#             if (currentZoom < minZoom || currentZoom > maxZoom) {\n",
    "#                 map.removeLayer(clusterGroup);\n",
    "#             } else {\n",
    "#                 map.addLayer(clusterGroup);\n",
    "#             }\n",
    "#         });\n",
    "\n",
    "#         // Hide the clusters initially\n",
    "#         map.removeLayer(clusterGroup);\n",
    "#     }\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Add the JavaScript to the map\n",
    "#     folium_map.get_root().html.add_child(folium.Element(f'<script>{toggle_cluster_js}</script>'))\n",
    "\n",
    "#     # Call the function that runs the zoom toggle functionality\n",
    "#     folium_map.add_child(folium.Element(f'<script>toggleClusters({{map_name}});</script>'.format(map_name=folium_map.get_name())))\n",
    "\n",
    "#     # Add the marker cluster group to the map\n",
    "#     marker_cluster.add_to(folium_map)\n",
    "\n",
    "#     return folium_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggrigate data on state by state basis \n",
    "- will use to color specific states - regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_counts = location_counts_cleaned['State_Province'].value_counts()\n",
    "# Create df of the state counts\n",
    "state_counts_df = pd.DataFrame(state_counts).reset_index()\n",
    "state_counts_df.columns = ['State_Province', 'Player_Count']\n",
    "state_counts_df.head()\n",
    "\n",
    "# location_counts_cleaned.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check player dataframe and school info dataframe\n",
    "merged_df.head()\n",
    "# school_info_df.head()\n",
    "\n",
    "# ## Save both to Temp folder for checking\n",
    "# merged_df.to_csv('../TEMP/merged_df.csv', index=False)\n",
    "# school_info_df.to_csv('../TEMP/school_info_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the average distance a player is from their home town for each team\n",
    "\n",
    "# Find the distance from Hometown to home arena for each player\n",
    "# Create a new column 'Distance' in merged_df\n",
    "\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# add home rink coordinates to merged_df\n",
    "# reaname columns to match - Current Team to Team\n",
    "merged_df = merged_df.rename(columns={'Current Team': 'Team'})\n",
    "## rename coords in school_info_df to Rink_Lat and Rink_Long\n",
    "school_info_df = school_info_df.rename(columns={'Latitude': 'Rink_Lat', 'Longitude': 'Rink_Long'})\n",
    "\n",
    "# Merge Rink coordinates into merged_df\n",
    "merged_df = pd.merge(merged_df, school_info_df[['Team', 'Rink_Lat', 'Rink_Long']], on='Team', how='left')\n",
    "\n",
    "merged_df.head()\n",
    "# merged_df.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()\n",
    "# merged_df.info()\n",
    "\n",
    "# Calculate the distance between the player's hometown and their home rink\n",
    "merged_df['Distance'] = merged_df.apply(\n",
    "    lambda row: geodesic((row['Latitude'], row['Longitude']), (row['Rink_Lat'], row['Rink_Long'])).miles, axis=1\n",
    ")\n",
    "\n",
    "# Calculate the average distance for each team\n",
    "team_avg_distance = merged_df.groupby('Team')['Distance'].mean().reset_index()\n",
    "\n",
    "# Calculate the median distance for each team\n",
    "team_median_distance = merged_df.groupby('Team')['Distance'].median().reset_index()\n",
    "\n",
    "# Combine the average and median distances into a single DataFrame\n",
    "team_avg_distance = team_avg_distance.merge(team_median_distance, on='Team', suffixes=('_Avg', '_Median'))\n",
    "\n",
    "# Sort by average distance in ascending order\n",
    "team_avg_distance = team_avg_distance.sort_values(by='Distance_Avg')\n",
    "\n",
    "# Round to two decimal places for better readability\n",
    "team_avg_distance = team_avg_distance.round(2)\n",
    "# Reindex the DataFrame for better display\n",
    "team_avg_distance = team_avg_distance.reset_index(drop=True)\n",
    "\n",
    "# Display the average and median distances for each team\n",
    "# team_avg_distance.head(20)\n",
    "team_avg_distance.tail(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
