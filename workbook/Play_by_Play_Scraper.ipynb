{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCAA.com Play-by-play Data Scraper\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example schedule URL\n",
    "## First Day of season\n",
    "# https://www.ncaa.com/scoreboard/icehockey-men/d1/2024/10/04/all-conf\n",
    "\n",
    "# Last Regular Season Day\n",
    "# https://www.ncaa.com/scoreboard/icehockey-men/d1/2025/03/08/all-conf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "from config import recent_clean_db, last_game_date\n",
    "\n",
    "# File paths\n",
    "data_folder = os.path.join('..', 'data/') # Data Folder Path\n",
    "temp_folder = os.path.join('..', 'TEMP/',) # Temp Folder Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schedule_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the NCAA.com schedule section\n",
    "- Creates a dataframe with Data - Teams and Game_ID_Number\n",
    "\n",
    "- Turned off because it takes 6-7 minutes to run and we can use a previously scraped and locally stored schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Base URL for NCAA schedule\n",
    "# base_url = \"https://www.ncaa.com/scoreboard/icehockey-men/d1\"\n",
    "\n",
    "# # Function to scrape a single day's schedule with rate limiting\n",
    "# def scrape_schedule(date):\n",
    "#     url = f\"{base_url}/{date}/all-conf\"\n",
    "#     response = requests.get(url)\n",
    "#     if response.status_code != 200:\n",
    "#         print(f\"Failed to fetch data for {date}: {response.status_code}\")\n",
    "#         return []\n",
    "\n",
    "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#     games = []\n",
    "\n",
    "#     # Locate game containers based on the provided HTML structure\n",
    "#     game_containers = soup.select('#scoreboardGames .gamePod')\n",
    "#     for game in game_containers:\n",
    "#         try:\n",
    "#             game_id = game.select_one('a.gamePod-link')['href'].split('/')[-1]\n",
    "#             teams = game.select('ul.gamePod-game-teams li')\n",
    "            \n",
    "#             home_team = teams[0].select_one('span.gamePod-game-team-name').text.strip()\n",
    "#             away_team = teams[1].select_one('span.gamePod-game-team-name').text.strip()\n",
    "            \n",
    "#             games.append({\n",
    "#                 'Date': date,\n",
    "#                 'Home_Team': home_team,\n",
    "#                 'Away_Team': away_team,            \n",
    "\n",
    "#                 'game_id_number': game_id\n",
    "#             })\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing game: {e}\")\n",
    "\n",
    "#     return games\n",
    "\n",
    "# # Function to scrape a range of dates with rate limiting and progress bar\n",
    "# def scrape_schedule_range(start_date, end_date):\n",
    "#     date_range = pd.date_range(start=start_date, end=end_date).strftime('%Y/%m/%d')\n",
    "#     all_games = []\n",
    "    \n",
    "#     # Progress bar setup\n",
    "#     for date in tqdm(date_range, desc=\"Scraping schedule\", unit=\"day\"):\n",
    "#         games = scrape_schedule(date)\n",
    "#         all_games.extend(games)\n",
    "#         time.sleep(1)  # Rate limiter: 1-second delay between requests\n",
    "\n",
    "#     return pd.DataFrame(all_games)\n",
    "\n",
    "# # Example usage\n",
    "# start_date = \"2024-10-04\"  # First day of the season\n",
    "# end_date = \"2025-03-08\"    # Last regular season day\n",
    "# schedule_df = scrape_schedule_range(start_date, end_date)\n",
    "\n",
    "# # Display the resulting dataframe\n",
    "# schedule_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / Load Local Copy of Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the schedule to a CSV file for later use\n",
    "# schedule_df.to_csv(os.path.join(data_folder, 'schedule_from_ncaa_with_game_number.csv'), index=False)\n",
    "\n",
    "# Load the locally stored schedule to avoid having to scrape again\n",
    "schedule_df = pd.read_csv(os.path.join(data_folder, 'schedule_from_ncaa_with_game_number.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Home_Team_Away_Team</th>\n",
       "      <th>game_id_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>2025/03/01</td>\n",
       "      <td>Minnesota vs Penn St.</td>\n",
       "      <td>6344204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>2025/03/01</td>\n",
       "      <td>Providence vs Merrimack</td>\n",
       "      <td>6345234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>2025/03/06</td>\n",
       "      <td>UConn vs Vermont</td>\n",
       "      <td>6345255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>2025/03/06</td>\n",
       "      <td>Providence vs Boston U.</td>\n",
       "      <td>6345253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>2025/03/06</td>\n",
       "      <td>Northeastern vs Merrimack</td>\n",
       "      <td>6345254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>2025/03/07</td>\n",
       "      <td>New Hampshire vs UMass Lowell</td>\n",
       "      <td>6345257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>2025/03/07</td>\n",
       "      <td>Western Mich. vs Miami (OH)</td>\n",
       "      <td>6345259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>2025/03/07</td>\n",
       "      <td>Omaha vs North Dakota</td>\n",
       "      <td>6345260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>2025/03/07</td>\n",
       "      <td>Minn. Duluth vs St. Cloud St.</td>\n",
       "      <td>6345261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>2025/03/07</td>\n",
       "      <td>Colorado Col. vs Denver</td>\n",
       "      <td>6345258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>2025/03/07</td>\n",
       "      <td>Maine vs Massachusetts</td>\n",
       "      <td>6345256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>Merrimack vs Boston College</td>\n",
       "      <td>6345263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>Providence vs Northeastern</td>\n",
       "      <td>6345262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>Minn. Duluth vs St. Cloud St.</td>\n",
       "      <td>6345265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>Boston U. vs Vermont</td>\n",
       "      <td>6345268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>UMass Lowell vs New Hampshire</td>\n",
       "      <td>6345269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>Western Mich. vs Miami (OH)</td>\n",
       "      <td>6345270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>Omaha vs North Dakota</td>\n",
       "      <td>6345267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>Denver vs Colorado Col.</td>\n",
       "      <td>6345266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>Maine vs Massachusetts</td>\n",
       "      <td>6345264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date            Home_Team_Away_Team  game_id_number\n",
       "1059  2025/03/01          Minnesota vs Penn St.         6344204\n",
       "1060  2025/03/01        Providence vs Merrimack         6345234\n",
       "1061  2025/03/06               UConn vs Vermont         6345255\n",
       "1062  2025/03/06        Providence vs Boston U.         6345253\n",
       "1063  2025/03/06      Northeastern vs Merrimack         6345254\n",
       "1064  2025/03/07  New Hampshire vs UMass Lowell         6345257\n",
       "1065  2025/03/07    Western Mich. vs Miami (OH)         6345259\n",
       "1066  2025/03/07          Omaha vs North Dakota         6345260\n",
       "1067  2025/03/07  Minn. Duluth vs St. Cloud St.         6345261\n",
       "1068  2025/03/07        Colorado Col. vs Denver         6345258\n",
       "1069  2025/03/07         Maine vs Massachusetts         6345256\n",
       "1070  2025/03/08    Merrimack vs Boston College         6345263\n",
       "1071  2025/03/08     Providence vs Northeastern         6345262\n",
       "1072  2025/03/08  Minn. Duluth vs St. Cloud St.         6345265\n",
       "1073  2025/03/08           Boston U. vs Vermont         6345268\n",
       "1074  2025/03/08  UMass Lowell vs New Hampshire         6345269\n",
       "1075  2025/03/08    Western Mich. vs Miami (OH)         6345270\n",
       "1076  2025/03/08          Omaha vs North Dakota         6345267\n",
       "1077  2025/03/08        Denver vs Colorado Col.         6345266\n",
       "1078  2025/03/08         Maine vs Massachusetts         6345264"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule_df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transgformation\n",
    "- NOT NESS IF WORKING WITH NEW SCRAPE \n",
    "    - Seperate team column into Home_Team, Away_Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>game_id_number</th>\n",
       "      <th>Away_Team</th>\n",
       "      <th>Home_Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024/10/04</td>\n",
       "      <td>6344272</td>\n",
       "      <td>Michigan St</td>\n",
       "      <td>Lake Superior St</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024/10/04</td>\n",
       "      <td>6344249</td>\n",
       "      <td>Minnesota St</td>\n",
       "      <td>Michigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024/10/04</td>\n",
       "      <td>6344336</td>\n",
       "      <td>Bowling Green</td>\n",
       "      <td>Mercyhurst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024/10/04</td>\n",
       "      <td>6344337</td>\n",
       "      <td>Colgate</td>\n",
       "      <td>UConn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024/10/04</td>\n",
       "      <td>6344354</td>\n",
       "      <td>Miami OH</td>\n",
       "      <td>Ferris St</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024/10/04</td>\n",
       "      <td>6344335</td>\n",
       "      <td>Arizona St</td>\n",
       "      <td>Air Force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344273</td>\n",
       "      <td>Michigan St</td>\n",
       "      <td>Lake Superior St</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344250</td>\n",
       "      <td>Minnesota St</td>\n",
       "      <td>Michigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344341</td>\n",
       "      <td>Bemidji St</td>\n",
       "      <td>Minn Duluth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344346</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Bentley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344347</td>\n",
       "      <td>RIT</td>\n",
       "      <td>St Lawrence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344348</td>\n",
       "      <td>Canisius</td>\n",
       "      <td>Clarkson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344349</td>\n",
       "      <td>American Intl</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344350</td>\n",
       "      <td>Holy Cross</td>\n",
       "      <td>Boston U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344351</td>\n",
       "      <td>Bowling Green</td>\n",
       "      <td>Mercyhurst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344353</td>\n",
       "      <td>Colgate</td>\n",
       "      <td>UConn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344368</td>\n",
       "      <td>Miami OH</td>\n",
       "      <td>Ferris St</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344352</td>\n",
       "      <td>Arizona St</td>\n",
       "      <td>Air Force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344343</td>\n",
       "      <td>Denver</td>\n",
       "      <td>Alas Anchorage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344179</td>\n",
       "      <td>Penn St</td>\n",
       "      <td>Alas Fairbanks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  game_id_number      Away_Team         Home_Team\n",
       "0   2024/10/04         6344272    Michigan St  Lake Superior St\n",
       "1   2024/10/04         6344249   Minnesota St          Michigan\n",
       "2   2024/10/04         6344336  Bowling Green        Mercyhurst\n",
       "3   2024/10/04         6344337        Colgate             UConn\n",
       "4   2024/10/04         6344354       Miami OH         Ferris St\n",
       "5   2024/10/04         6344335     Arizona St         Air Force\n",
       "6   2024/10/05         6344273    Michigan St  Lake Superior St\n",
       "7   2024/10/05         6344250   Minnesota St          Michigan\n",
       "8   2024/10/05         6344341     Bemidji St       Minn Duluth\n",
       "9   2024/10/05         6344346  Massachusetts           Bentley\n",
       "10  2024/10/05         6344347            RIT       St Lawrence\n",
       "11  2024/10/05         6344348       Canisius          Clarkson\n",
       "12  2024/10/05         6344349  American Intl             Maine\n",
       "13  2024/10/05         6344350     Holy Cross          Boston U\n",
       "14  2024/10/05         6344351  Bowling Green        Mercyhurst\n",
       "15  2024/10/05         6344353        Colgate             UConn\n",
       "16  2024/10/05         6344368       Miami OH         Ferris St\n",
       "17  2024/10/05         6344352     Arizona St         Air Force\n",
       "18  2024/10/05         6344343         Denver    Alas Anchorage\n",
       "19  2024/10/05         6344179        Penn St    Alas Fairbanks"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperate team column into Home_Team, Away_Team\n",
    "\n",
    "def handle_home_away(schedule_df):\n",
    "    # Split Home_Team_Away_Team into Home_Team and Away_Team\n",
    "    schedule_df[['Away_Team', 'Home_Team']] = schedule_df['Home_Team_Away_Team'].str.split(' vs ', expand=True)\n",
    "    \n",
    "    # Remove punctuation and strip whitespace\n",
    "    schedule_df['Home_Team'] = schedule_df['Home_Team'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x).strip())\n",
    "    schedule_df['Away_Team'] = schedule_df['Away_Team'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x).strip())\n",
    "\n",
    "    # Drop the original column\n",
    "    schedule_df = schedule_df.drop(columns=['Home_Team_Away_Team'])\n",
    "    return schedule_df\n",
    "\n",
    "# call the function\n",
    "schedule_df = handle_home_away(schedule_df)\n",
    "schedule_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load School info and replace ncaa_names with standard Team names from existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>game_id_number</th>\n",
       "      <th>Away_Team</th>\n",
       "      <th>Home_Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024/10/04</td>\n",
       "      <td>6344272</td>\n",
       "      <td>Michigan State</td>\n",
       "      <td>Lake Superior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024/10/04</td>\n",
       "      <td>6344249</td>\n",
       "      <td>Minnesota State</td>\n",
       "      <td>Michigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024/10/04</td>\n",
       "      <td>6344336</td>\n",
       "      <td>Bowling Green</td>\n",
       "      <td>Mercyhurst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024/10/04</td>\n",
       "      <td>6344337</td>\n",
       "      <td>Colgate</td>\n",
       "      <td>Connecticut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024/10/04</td>\n",
       "      <td>6344354</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Ferris State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024/10/04</td>\n",
       "      <td>6344335</td>\n",
       "      <td>Arizona State</td>\n",
       "      <td>Air Force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344273</td>\n",
       "      <td>Michigan State</td>\n",
       "      <td>Lake Superior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344250</td>\n",
       "      <td>Minnesota State</td>\n",
       "      <td>Michigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344341</td>\n",
       "      <td>Bemidji State</td>\n",
       "      <td>Minnesota Duluth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344346</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Bentley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344347</td>\n",
       "      <td>RIT</td>\n",
       "      <td>St. Lawrence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344348</td>\n",
       "      <td>Canisius</td>\n",
       "      <td>Clarkson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344349</td>\n",
       "      <td>American Intl</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344350</td>\n",
       "      <td>Holy Cross</td>\n",
       "      <td>Boston University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344351</td>\n",
       "      <td>Bowling Green</td>\n",
       "      <td>Mercyhurst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344353</td>\n",
       "      <td>Colgate</td>\n",
       "      <td>Connecticut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344368</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Ferris State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344352</td>\n",
       "      <td>Arizona State</td>\n",
       "      <td>Air Force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344343</td>\n",
       "      <td>Denver</td>\n",
       "      <td>Alaska Anchorage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2024/10/05</td>\n",
       "      <td>6344179</td>\n",
       "      <td>Penn State</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  game_id_number        Away_Team          Home_Team\n",
       "0   2024/10/04         6344272   Michigan State      Lake Superior\n",
       "1   2024/10/04         6344249  Minnesota State           Michigan\n",
       "2   2024/10/04         6344336    Bowling Green         Mercyhurst\n",
       "3   2024/10/04         6344337          Colgate        Connecticut\n",
       "4   2024/10/04         6344354            Miami       Ferris State\n",
       "5   2024/10/04         6344335    Arizona State          Air Force\n",
       "6   2024/10/05         6344273   Michigan State      Lake Superior\n",
       "7   2024/10/05         6344250  Minnesota State           Michigan\n",
       "8   2024/10/05         6344341    Bemidji State   Minnesota Duluth\n",
       "9   2024/10/05         6344346    Massachusetts            Bentley\n",
       "10  2024/10/05         6344347              RIT       St. Lawrence\n",
       "11  2024/10/05         6344348         Canisius           Clarkson\n",
       "12  2024/10/05         6344349    American Intl              Maine\n",
       "13  2024/10/05         6344350       Holy Cross  Boston University\n",
       "14  2024/10/05         6344351    Bowling Green         Mercyhurst\n",
       "15  2024/10/05         6344353          Colgate        Connecticut\n",
       "16  2024/10/05         6344368            Miami       Ferris State\n",
       "17  2024/10/05         6344352    Arizona State          Air Force\n",
       "18  2024/10/05         6344343           Denver   Alaska Anchorage\n",
       "19  2024/10/05         6344179       Penn State             Alaska"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load School info \n",
    "school_info_path = os.path.join(data_folder, 'arena_school_info.csv')\n",
    "school_info_df = pd.read_csv(school_info_path)\n",
    "# school_info_df.head() # Check data\n",
    "\n",
    "# Function to map team names to standardized names\n",
    "def map_team_names(schedule_df, school_info_df):\n",
    "    # Create a mapping dictionary from school_info_df\n",
    "    team_mapping = {\n",
    "        re.sub(r'[^\\w\\s]', '', row['ncaa_name']).strip(): row['Team']\n",
    "        for _, row in school_info_df.iterrows()\n",
    "    }\n",
    "\n",
    "    # Map Home_Team and Away_Team to standardized names\n",
    "    schedule_df['Home_Team'] = schedule_df['Home_Team'].apply(lambda x: team_mapping.get(re.sub(r'[^\\w\\s]', '', x).strip(), x))\n",
    "    schedule_df['Away_Team'] = schedule_df['Away_Team'].apply(lambda x: team_mapping.get(re.sub(r'[^\\w\\s]', '', x).strip(), x))\n",
    "\n",
    "    return schedule_df\n",
    "\n",
    "# Call the function\n",
    "schedule_df = map_team_names(schedule_df, school_info_df)\n",
    "\n",
    "# Check the data\n",
    "schedule_df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a New Column with Game_ID to match with the rest of the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a unique Game_ID\n",
    "def create_game_id(schedule_df):\n",
    "    schedule_df['Game_ID'] = schedule_df.apply(\n",
    "        lambda row: f\"{row['Date'].replace('/', '-')}-{row['Away_Team']}-{row['Home_Team']}\", axis=1\n",
    "    )\n",
    "    return schedule_df\n",
    "\n",
    "# Call the function\n",
    "schedule_df = create_game_id(schedule_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>game_id_number</th>\n",
       "      <th>Away_Team</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>Game_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>2025/03/01</td>\n",
       "      <td>6344204</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Penn State</td>\n",
       "      <td>2025-03-01-Minnesota-Penn State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>2025/03/01</td>\n",
       "      <td>6345234</td>\n",
       "      <td>Providence</td>\n",
       "      <td>Merrimack</td>\n",
       "      <td>2025-03-01-Providence-Merrimack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>2025/03/06</td>\n",
       "      <td>6345255</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>2025-03-06-Connecticut-Vermont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>2025/03/06</td>\n",
       "      <td>6345253</td>\n",
       "      <td>Providence</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>2025-03-06-Providence-Boston University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>2025/03/06</td>\n",
       "      <td>6345254</td>\n",
       "      <td>Northeastern</td>\n",
       "      <td>Merrimack</td>\n",
       "      <td>2025-03-06-Northeastern-Merrimack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>2025/03/07</td>\n",
       "      <td>6345257</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>Mass. Lowell</td>\n",
       "      <td>2025-03-07-New Hampshire-Mass. Lowell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>2025/03/07</td>\n",
       "      <td>6345259</td>\n",
       "      <td>Western Michigan</td>\n",
       "      <td>Miami</td>\n",
       "      <td>2025-03-07-Western Michigan-Miami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>2025/03/07</td>\n",
       "      <td>6345260</td>\n",
       "      <td>Omaha</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>2025-03-07-Omaha-North Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>2025/03/07</td>\n",
       "      <td>6345261</td>\n",
       "      <td>Minnesota Duluth</td>\n",
       "      <td>St Cloud State</td>\n",
       "      <td>2025-03-07-Minnesota Duluth-St Cloud State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>2025/03/07</td>\n",
       "      <td>6345258</td>\n",
       "      <td>Colorado College</td>\n",
       "      <td>Denver</td>\n",
       "      <td>2025-03-07-Colorado College-Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>2025/03/07</td>\n",
       "      <td>6345256</td>\n",
       "      <td>Maine</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>2025-03-07-Maine-Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>6345263</td>\n",
       "      <td>Merrimack</td>\n",
       "      <td>Boston College</td>\n",
       "      <td>2025-03-08-Merrimack-Boston College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>6345262</td>\n",
       "      <td>Providence</td>\n",
       "      <td>Northeastern</td>\n",
       "      <td>2025-03-08-Providence-Northeastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>6345265</td>\n",
       "      <td>Minnesota Duluth</td>\n",
       "      <td>St Cloud State</td>\n",
       "      <td>2025-03-08-Minnesota Duluth-St Cloud State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>6345268</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>2025-03-08-Boston University-Vermont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>6345269</td>\n",
       "      <td>Mass. Lowell</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>2025-03-08-Mass. Lowell-New Hampshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>6345270</td>\n",
       "      <td>Western Michigan</td>\n",
       "      <td>Miami</td>\n",
       "      <td>2025-03-08-Western Michigan-Miami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>6345267</td>\n",
       "      <td>Omaha</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>2025-03-08-Omaha-North Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>6345266</td>\n",
       "      <td>Denver</td>\n",
       "      <td>Colorado College</td>\n",
       "      <td>2025-03-08-Denver-Colorado College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>2025/03/08</td>\n",
       "      <td>6345264</td>\n",
       "      <td>Maine</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>2025-03-08-Maine-Massachusetts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  game_id_number          Away_Team          Home_Team  \\\n",
       "1059  2025/03/01         6344204          Minnesota         Penn State   \n",
       "1060  2025/03/01         6345234         Providence          Merrimack   \n",
       "1061  2025/03/06         6345255        Connecticut            Vermont   \n",
       "1062  2025/03/06         6345253         Providence  Boston University   \n",
       "1063  2025/03/06         6345254       Northeastern          Merrimack   \n",
       "1064  2025/03/07         6345257      New Hampshire       Mass. Lowell   \n",
       "1065  2025/03/07         6345259   Western Michigan              Miami   \n",
       "1066  2025/03/07         6345260              Omaha       North Dakota   \n",
       "1067  2025/03/07         6345261   Minnesota Duluth     St Cloud State   \n",
       "1068  2025/03/07         6345258   Colorado College             Denver   \n",
       "1069  2025/03/07         6345256              Maine      Massachusetts   \n",
       "1070  2025/03/08         6345263          Merrimack     Boston College   \n",
       "1071  2025/03/08         6345262         Providence       Northeastern   \n",
       "1072  2025/03/08         6345265   Minnesota Duluth     St Cloud State   \n",
       "1073  2025/03/08         6345268  Boston University            Vermont   \n",
       "1074  2025/03/08         6345269       Mass. Lowell      New Hampshire   \n",
       "1075  2025/03/08         6345270   Western Michigan              Miami   \n",
       "1076  2025/03/08         6345267              Omaha       North Dakota   \n",
       "1077  2025/03/08         6345266             Denver   Colorado College   \n",
       "1078  2025/03/08         6345264              Maine      Massachusetts   \n",
       "\n",
       "                                         Game_ID  \n",
       "1059             2025-03-01-Minnesota-Penn State  \n",
       "1060             2025-03-01-Providence-Merrimack  \n",
       "1061              2025-03-06-Connecticut-Vermont  \n",
       "1062     2025-03-06-Providence-Boston University  \n",
       "1063           2025-03-06-Northeastern-Merrimack  \n",
       "1064       2025-03-07-New Hampshire-Mass. Lowell  \n",
       "1065           2025-03-07-Western Michigan-Miami  \n",
       "1066               2025-03-07-Omaha-North Dakota  \n",
       "1067  2025-03-07-Minnesota Duluth-St Cloud State  \n",
       "1068          2025-03-07-Colorado College-Denver  \n",
       "1069              2025-03-07-Maine-Massachusetts  \n",
       "1070         2025-03-08-Merrimack-Boston College  \n",
       "1071          2025-03-08-Providence-Northeastern  \n",
       "1072  2025-03-08-Minnesota Duluth-St Cloud State  \n",
       "1073        2025-03-08-Boston University-Vermont  \n",
       "1074       2025-03-08-Mass. Lowell-New Hampshire  \n",
       "1075           2025-03-08-Western Michigan-Miami  \n",
       "1076               2025-03-08-Omaha-North Dakota  \n",
       "1077          2025-03-08-Denver-Colorado College  \n",
       "1078              2025-03-08-Maine-Massachusetts  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule_df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Play By Play JSONs\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# breakpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Custom API to Call NCAA.com\n",
    "- project developed by henrygd - https://github.com/henrygd/ncaa-api\n",
    "\n",
    "Uses his custom built API to get JSON response from NCAA.com\n",
    "- can host own server for large projects for now I am using his public link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 39\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completed_games\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Fetch and update the dataframe with play-by-play JSONs\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m updated_schedule_df \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_play_by_play_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschedule_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Check the updated dataframe\u001b[39;00m\n\u001b[0;32m     42\u001b[0m updated_schedule_df\u001b[38;5;241m.\u001b[39mtail()\n",
      "Cell \u001b[1;32mIn[56], line 32\u001b[0m, in \u001b[0;36mfetch_play_by_play_data\u001b[1;34m(schedule_df)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m completed_games\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     31\u001b[0m     game_id_number \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgame_id_number\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 32\u001b[0m     json_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_play_by_play\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame_id_number\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     completed_games\u001b[38;5;241m.\u001b[39mat[index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlay_By_Play_JSON\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m json_data\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completed_games\n",
      "Cell \u001b[1;32mIn[56], line 12\u001b[0m, in \u001b[0;36mget_play_by_play\u001b[1;34m(game_id_number)\u001b[0m\n\u001b[0;32m     10\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgame_id_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/play-by-play\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 12\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()  \u001b[38;5;66;03m# Raise HTTPError for bad responses\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\urllib3\\connectionpool.py:716\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    730\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\urllib3\\connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    463\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    466\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    467\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 468\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\site-packages\\urllib3\\connectionpool.py:463\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 463\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    467\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\http\\client.py:1419\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1418\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1419\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1420\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1421\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\ssl.py:1253\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1251\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1252\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\jbanc\\anaconda3\\envs\\data_viz\\Lib\\ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "6344241\n",
    "\n",
    "# Base URL for the custom API\n",
    "base_url = \"https://ncaa-api.henrygd.me/game\"\n",
    "\n",
    "# Function to get play-by-play JSON for a single game\n",
    "def get_play_by_play(game_id_number):\n",
    "    url = f\"{base_url}/{game_id_number}/play-by-play\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for Game ID {game_id_number}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to fetch JSON data for all completed games\n",
    "def fetch_play_by_play_data(schedule_df):\n",
    "    # Filter for games that have already taken place\n",
    "    schedule_df['Date'] = pd.to_datetime(schedule_df['Date'])\n",
    "    today = pd.to_datetime(datetime.now().strftime('%Y-%m-%d'))\n",
    "    completed_games = schedule_df[schedule_df['Date'] < today].copy()\n",
    "\n",
    "\n",
    "    # Initialize a new column for play-by-play JSON\n",
    "    completed_games['Play_By_Play_JSON'] = None\n",
    "\n",
    "    for index, row in completed_games.iterrows():\n",
    "        game_id_number = row['game_id_number']\n",
    "        json_data = get_play_by_play(game_id_number)\n",
    "        completed_games.at[index, 'Play_By_Play_JSON'] = json_data\n",
    "\n",
    "    return completed_games\n",
    "\n",
    "\n",
    "# Fetch and update the dataframe with play-by-play JSONs\n",
    "updated_schedule_df = fetch_play_by_play_data(schedule_df)\n",
    "\n",
    "# Check the updated dataframe\n",
    "updated_schedule_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the dataframe in a way that doesn't cut off the json data - CSV cuts off the json data\n",
    "## Use Pickle\n",
    "# Save the updated dataframe to a pickle file\n",
    "updated_schedule_df.to_pickle(os.path.join(temp_folder, 'schedule_with_play_by_play.pkl'))\n",
    "\n",
    "## Load pickle file to avoid having to scrape again\n",
    "# Load the updated dataframe from a pickle file\n",
    "# updated_schedule_df = pd.read_pickle(os.path.join(temp_folder, 'schedule_with_play_by_play.pkl'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Play by Play JSONs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract all decriptions into a text file to study\n",
    "- Use this to make an abbr and alternate name dictionary for a find and replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Team Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create team Map for name subsitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create team name mapping from school_info_df\n",
    "team_mapping = {}\n",
    "for _, row in school_info_df.iterrows():\n",
    "    standard_name = row['Team']\n",
    "    alternatives = [a.strip() for a in row['ncaa_data_alts'].split(',')]\n",
    "    for alt in alternatives:\n",
    "        team_mapping[alt.lower()] = standard_name\n",
    "\n",
    "team_mapping\n",
    "team_map = team_mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# school_info_df.head()\n",
    "# Create a dictionary mapping the alternate names (ncaa_data_alts) to the standardized names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_schedule_df\n",
    "\n",
    "# Output Play by Play JSON to a raw text file\n",
    "# Function to save JSON data to a text file\n",
    "def save_json_to_file(json_data, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(json_data, file)\n",
    "\n",
    "## Call the function for the first row\n",
    "save_json_to_file(updated_schedule_df.iloc[0]['Play_By_Play_JSON'], os.path.join(temp_folder, 'play_by_play.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>game_id_number</th>\n",
       "      <th>Away_Team</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>Play_By_Play_JSON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>6345096</td>\n",
       "      <td>Alaska Anchorage</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2025-02-08-Alaska Anchorage-Alaska</td>\n",
       "      <td>{'inputMD5Sum': '0322531313fbecdd8d61dd62fa3c9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>6345089</td>\n",
       "      <td>Mass. Lowell</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>2025-02-08-Mass. Lowell-Connecticut</td>\n",
       "      <td>{'inputMD5Sum': 'e401227d414894c5a27c2f433d948...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>2025-02-09</td>\n",
       "      <td>6345109</td>\n",
       "      <td>Yale</td>\n",
       "      <td>Brown</td>\n",
       "      <td>2025-02-09-Yale-Brown</td>\n",
       "      <td>{'inputMD5Sum': '251669d1ee562edb178de1148305a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>2025-02-11</td>\n",
       "      <td>6345110</td>\n",
       "      <td>Canisius</td>\n",
       "      <td>Niagara</td>\n",
       "      <td>2025-02-11-Canisius-Niagara</td>\n",
       "      <td>{'inputMD5Sum': 'ba1f2525708cd123c679bfaef9891...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>2025-02-12</td>\n",
       "      <td>6345111</td>\n",
       "      <td>Alaska Anchorage</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>2025-02-12-Alaska Anchorage-Connecticut</td>\n",
       "      <td>{'inputMD5Sum': 'c7d7d3f4feb34f0d0f99d7de6401a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  game_id_number         Away_Team    Home_Team  \\\n",
       "895 2025-02-08         6345096  Alaska Anchorage       Alaska   \n",
       "896 2025-02-08         6345089      Mass. Lowell  Connecticut   \n",
       "897 2025-02-09         6345109              Yale        Brown   \n",
       "898 2025-02-11         6345110          Canisius      Niagara   \n",
       "899 2025-02-12         6345111  Alaska Anchorage  Connecticut   \n",
       "\n",
       "                                     Game_ID  \\\n",
       "895       2025-02-08-Alaska Anchorage-Alaska   \n",
       "896      2025-02-08-Mass. Lowell-Connecticut   \n",
       "897                    2025-02-09-Yale-Brown   \n",
       "898              2025-02-11-Canisius-Niagara   \n",
       "899  2025-02-12-Alaska Anchorage-Connecticut   \n",
       "\n",
       "                                     Play_By_Play_JSON  \n",
       "895  {'inputMD5Sum': '0322531313fbecdd8d61dd62fa3c9...  \n",
       "896  {'inputMD5Sum': 'e401227d414894c5a27c2f433d948...  \n",
       "897  {'inputMD5Sum': '251669d1ee562edb178de1148305a...  \n",
       "898  {'inputMD5Sum': 'ba1f2525708cd123c679bfaef9891...  \n",
       "899  {'inputMD5Sum': 'c7d7d3f4feb34f0d0f99d7de6401a...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_schedule_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatGPT attempt at parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decode the Description field in to deal with problems caused by special characters\n",
    "def clean_description_encoding_safe(df, column='Description'):\n",
    "    \"\"\"\n",
    "    Fixes encoding issues and malformed characters in the specified column safely.\n",
    "    Ignores characters that cannot be decoded.\n",
    "    \"\"\"\n",
    "    df[column] = df[column].apply(\n",
    "        lambda x: x.encode('latin1', 'ignore').decode('utf-8', 'ignore') if isinstance(x, str) else x\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take Spaces out of Multi-part Team Abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "## Function to remove spaces if they are between two capital letters, used to clean Description column before parsing\n",
    "def remove_spaces_between_two_cap_pairs(df, column='Description'):\n",
    "    \"\"\"\n",
    "    Removes spaces only if the pattern is two consecutive capital letters, \n",
    "    followed by a space, followed by another two consecutive capital letters.\n",
    "    \"\"\"\n",
    "    df[column] = df[column].apply(lambda x: re.sub(r'([A-Z]{2})\\s([A-Z]{2})', r'\\1\\2', x) if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "#### Special Function to Deal with the special cases in the description column\n",
    "## \"Alas. Fairbanks\" = \"AKFBK\"\n",
    "## \"Alas. Anchorage\" = \"AKANC\"\n",
    "## \"St. Lawerence\" = \"STLAW\"\n",
    "## \"St. Cloud St.\" = \"SCS\"\n",
    "## \"St. Thomas (MN)\" = \"STC\"\n",
    "## \n",
    "\n",
    "## Function to look for those exact strings and replace them with the correct abbreviation in Description column\n",
    "def special_cases(df, column='Description'):\n",
    "    df[column] = df[column].str.replace(\"Alas. Fairbanks\", \"AKFBK\")\n",
    "    df[column] = df[column].str.replace(\"Alas. Anchorage\", \"AKANC\")\n",
    "    df[column] = df[column].str.replace(\"St. Lawrence\", \"STLAW\")\n",
    "    df[column] = df[column].str.replace(\"St. Cloud St.\", \"SCS\")\n",
    "    df[column] = df[column].str.replace(\"St. Thomas (MN)\", \"STC\")\n",
    "\n",
    "    return df\n",
    "\n",
    "### Special Player name cases\n",
    "# \"Santa juana\" = \"Santa-Juana\"\n",
    "# \"St. louis' = \"St-Louis\"\n",
    "# \"Jamernik v\" = \"Jamernik\"\n",
    "# \"Van houtte-cachero\" = \"Van-Houtte-Cachero\"\n",
    "# \"Van why\" = \"Van-Why\"\n",
    "# \"Gustafsson nyberg\" = \"Gustafsson-Nyberg\"\n",
    "# \"La starza\" = \"La-Starza\"\n",
    "# \"De la durantaye\" = \"De-La-Durantaye\"\n",
    "\n",
    "\n",
    "\n",
    "def special_player_cases(df, column='Description'):\n",
    "    df[column] = df[column].str.replace(\"Santa juana\", \"Santa-Juana\")\n",
    "    df[column] = df[column].str.replace(\"St. louis\", \"St-Louis\")\n",
    "    df[column] = df[column].str.replace(\"St. Louis\", \"St-Louis\")\n",
    "    df[column] = df[column].str.replace(\"Jamernik v\", \"Jamernik\")\n",
    "    df[column] = df[column].str.replace(\"Van houtte-cachero\", \"Van-Houtte-Cachero\")\n",
    "    df[column] = df[column].str.replace(\"Van why\", \"Van-Why\")\n",
    "    df[column] = df[column].str.replace(\"Gustafsson nyberg\", \"Gustafsson-Nyberg\")\n",
    "    df[column] = df[column].str.replace(\"La starza\", \"La-Starza\")\n",
    "    df[column] = df[column].str.replace(\"De la durantaye\", \"De-La-Durantaye\")\n",
    "    df[column] = df[column].str.replace(\"de la durantaye\", \"De-La-Durantaye\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# Function to convert period and time to continuous time\n",
    "def convert_to_continuous_time(period, time):\n",
    "    period_offsets = {'1': 0, '2': 20, '3': 40, 'OT': 60}\n",
    "    minutes, seconds = map(int, time.split(':'))\n",
    "    elapsed_time = (20 - minutes) * 60 + -seconds\n",
    "    offset = period_offsets.get(period, 0) * 60\n",
    "    return offset + elapsed_time\n",
    "\n",
    "# Function to normalize names to handle accents and special characters\n",
    "def normalize_name(name):\n",
    "    if not name:\n",
    "        return None\n",
    "    # Normalize Unicode accents and remove non-ASCII characters\n",
    "    normalized = unicodedata.normalize('NFKD', name).encode('ascii', 'ignore').decode('utf-8')\n",
    "    return normalized\n",
    "\n",
    "# Enhanced player name formatting function\n",
    "def clean_player_name(name):\n",
    "    \"\"\"\n",
    "    Converts a name from \"Last, First\" to \"First Last\", handling punctuation and normalization.\n",
    "    Example: \"Hughes, T.J.\" -> \"T.J. Hughes\"\n",
    "    \"\"\"\n",
    "    if not name:\n",
    "        return None\n",
    "    name = normalize_name(name)\n",
    "    parts = [p.strip() for p in name.split(',')]\n",
    "    if len(parts) == 2:\n",
    "        last, first = parts\n",
    "        return f\"{first} {last}\".strip()\n",
    "    return name\n",
    "\n",
    "# Function to parse play-by-play descriptions\n",
    "# Improved to handle team abbreviations and player names with issues\n",
    "def parse_description(description):\n",
    "    \"\"\"\n",
    "    Parse a single play-by-play description into structured fields.\n",
    "    \"\"\"\n",
    "    desc_lower = description.lower().strip()\n",
    "    parsed = {\n",
    "        \"Event_type\": \"Other\",\n",
    "        \"Primary_player\": None,\n",
    "        \"Primary_team\": None,\n",
    "        \"Secondary_player\": None,\n",
    "        \"Secondary_team\": None,\n",
    "        \"Outcome\": None,\n",
    "    }\n",
    "\n",
    "    # Normalize known team abbreviations\n",
    "    team_map = {\n",
    "        'michst': 'MICHST',\n",
    "        'lake sup': 'LK SUP',\n",
    "        'lk sup': 'LK SUP',\n",
    "        'michigan state': 'MICHST',\n",
    "        'lake superior': 'LK SUP'\n",
    "    }\n",
    "\n",
    "    for key, value in team_map.items():\n",
    "        desc_lower = desc_lower.replace(key, value.lower())\n",
    "\n",
    "    # --- Faceoff ---\n",
    "    if \"faceoff\" in desc_lower:\n",
    "        parsed[\"Event_type\"] = \"Faceoff\"\n",
    "        faceoff_pattern = (\n",
    "            r\"Faceoff\\s+([A-Za-zÀ-ÖØ-öø-ÿ'\\.\\- ]+, [A-Za-zÀ-ÖØ-öø-ÿ'\\.\\- ]+)\\s+\"\n",
    "            r\"vs\\s+([A-Za-zÀ-ÖØ-öø-ÿ'\\.\\- ]+, [A-Za-zÀ-ÖØ-öø-ÿ'\\.\\- ]+)\\s+\"\n",
    "            r\"won by\\s+([A-Za-zÀ-ÖØ-öø-ÿ'\\.\\- ]+)\\.\"\n",
    "        )\n",
    "        match = re.search(faceoff_pattern, description, re.IGNORECASE)\n",
    "        if match:\n",
    "            parsed[\"Primary_player\"] = clean_player_name(match.group(1))\n",
    "            parsed[\"Secondary_player\"] = clean_player_name(match.group(2))\n",
    "            parsed[\"Primary_team\"] = match.group(3).strip()\n",
    "            parsed[\"Outcome\"] = \"won\"\n",
    "        return parsed\n",
    "\n",
    "    # --- Goal ---\n",
    "    if \"goal by\" in desc_lower:\n",
    "        parsed[\"Event_type\"] = \"Goal\"\n",
    "        goal_scorer_pattern = r\"Goal by\\s+([A-Za-zÀ-ÖØ-öø-ÿ'\\.\\- ]+, [A-Za-zÀ-ÖØ-öø-ÿ'\\.\\- ]+)\"\n",
    "        match = re.search(goal_scorer_pattern, description, re.IGNORECASE)\n",
    "        if match:\n",
    "            parsed[\"Primary_player\"] = clean_player_name(match.group(1))\n",
    "        return parsed\n",
    "\n",
    "    # --- Penalty ---\n",
    "    if desc_lower.startswith(\"penalty on\"):\n",
    "        parsed[\"Event_type\"] = \"Penalty\"\n",
    "        penalty_pattern = (\n",
    "            r\"Penalty on\\s+([A-Za-zÀ-ÖØ-öø-ÿ'\\.\\- ]+, [A-Za-zÀ-ÖØ-ÿ'\\.\\- ]+)\\s+\"\n",
    "            r\"([A-Za-zÀ-ÖØ-öø-ÿ'\\.\\- ]+)\\s+(\\d+) minutes for (.+)\"\n",
    "        )\n",
    "        match = re.search(penalty_pattern, description, re.IGNORECASE)\n",
    "        if match:\n",
    "            parsed[\"Primary_player\"] = clean_player_name(match.group(1))\n",
    "            parsed[\"Primary_team\"] = match.group(2).strip()\n",
    "            parsed[\"Penalty_duration\"] = match.group(3).strip()\n",
    "            parsed[\"Penalty_type\"] = match.group(4).strip()\n",
    "        return parsed\n",
    "\n",
    "    # --- Shot ---\n",
    "    if \"shot by\" in desc_lower:\n",
    "        parsed[\"Event_type\"] = \"Shot\"\n",
    "        shot_pattern = r\"Shot by\\s+([A-Za-zÀ-ÖØ-öø-ÿ'\\.\\- ]+)\\s+(.+)\"\n",
    "        match = re.search(shot_pattern, description, re.IGNORECASE)\n",
    "        if match:\n",
    "            parsed[\"Primary_player\"] = clean_player_name(match.group(1))\n",
    "            parsed[\"Primary_team\"] = match.group(2).strip()\n",
    "        return parsed\n",
    "\n",
    "    return parsed\n",
    "\n",
    "# Function to transform a single game's JSON data into a dataframe\n",
    "def transform_single_game(json_data, game_id):\n",
    "    rows = []\n",
    "\n",
    "    for period in json_data['periods']:\n",
    "        period_number = period['periodNumber']\n",
    "        for play in period['playStats']:\n",
    "            row = {\n",
    "                'Game_ID': game_id,\n",
    "                'Period': period_number,\n",
    "                'Time': play['time'],\n",
    "                'Description': play['visitorText'] or play['homeText'],\n",
    "                'Score': play['score']\n",
    "            }\n",
    "            rows.append(row)\n",
    "    \n",
    "\n",
    "    game_df = pd.DataFrame(rows)\n",
    "\n",
    "    # Convert period and time to continuous time\n",
    "    game_df['Period'] = game_df['Period'].replace({'1st': '1', '2nd': '2', '3rd': '3', 'OT': 'OT'})\n",
    "    game_df['Time'] = game_df.apply(lambda row: convert_to_continuous_time(row['Period'], row['Time']), axis=1)\n",
    "    # Apply function to deal with special characters in the Description column\n",
    "    clean_description_encoding_safe(game_df, 'Description')\n",
    "    # Apply Function to deal with player name special cases (last names with spaces)\n",
    "    special_player_cases(game_df, 'Description')\n",
    "    # Apply the function to make special supstitutions in the Description column\n",
    "    game_df = special_cases(game_df, 'Description')\n",
    "    ## Apply the modified function to clean Team names in the 'Description' column\n",
    "    game_df = remove_spaces_between_two_cap_pairs(game_df, 'Description')\n",
    "\n",
    "    # Parse descriptions\n",
    "    parsed_descriptions = game_df['Description'].apply(parse_description)\n",
    "    parsed_df = pd.DataFrame(parsed_descriptions.tolist())\n",
    "\n",
    "    # Combine with original game_df\n",
    "    return pd.concat([game_df, parsed_df], axis=1)\n",
    "\n",
    "# Function to process all games and combine into a single dataframe\n",
    "def process_all_games(schedule_df):\n",
    "    all_games = []\n",
    "\n",
    "    for _, row in schedule_df.iterrows():\n",
    "        game_id = row['Game_ID']\n",
    "        json_data = row['Play_By_Play_JSON']\n",
    "\n",
    "        if json_data:\n",
    "            game_df = transform_single_game(json_data, game_id)\n",
    "            all_games.append(game_df)\n",
    "\n",
    "    return pd.concat(all_games, ignore_index=True)\n",
    "\n",
    "# Example usage\n",
    "# Assuming `updated_schedule_df` is the dataframe containing the JSON play-by-play data\n",
    "final_pbp_df = process_all_games(updated_schedule_df)\n",
    "\n",
    "# Display the resulting dataframe\n",
    "# final_pbp_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## look at tail\n",
    "# final_pbp_df.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle 'SAVE' case\n",
    "def move_save(row):\n",
    "    if pd.notnull(row['Primary_team']) and ', save' in row['Primary_team']:\n",
    "        row['Secondary_player'] = row['Primary_team'].split(', save')[1].strip()\n",
    "        row['Primary_team'] = row['Primary_team'].split(', save')[0].strip()\n",
    "\n",
    "\n",
    "        row['Primary_team'] = row['Primary_team'].replace(', save', '').strip()\n",
    "    return row\n",
    "\n",
    "# Function to handle 'BLOCKED' case\n",
    "def move_blocked(row):\n",
    "    if pd.notnull(row['Primary_team']) and 'BLOCKED' in row['Primary_team']:\n",
    "        blocked_match = re.search(r'BLOCKED by (.+)', row['Primary_team'])\n",
    "        if blocked_match:\n",
    "            row['Secondary_player'] = blocked_match.group(1).strip()\n",
    "            row['Primary_team'] = re.sub(r'BLOCKED by .+', 'BLOCKED', row['Primary_team']).strip()\n",
    "    return row\n",
    "\n",
    "# Function to extract and move the outcome to 'Outcome' column\n",
    "def move_outcome(row):\n",
    "    if pd.notnull(row['Primary_team']):\n",
    "        outcome_match = re.search(r'\\b(MISSED|WIDE|BLOCKED|SAVE)\\b', row['Primary_team'])\n",
    "        if outcome_match:\n",
    "            row['Outcome'] = outcome_match.group(1)\n",
    "            row['Primary_team'] = re.sub(r'\\b(MISSED|WIDE|BLOCKED|SAVE)\\b', '', row['Primary_team']).strip()\n",
    "    return row\n",
    "\n",
    "# Apply transformations sequentially\n",
    "final_pbp_df = final_pbp_df.apply(move_save, axis=1)\n",
    "final_pbp_df = final_pbp_df.apply(move_blocked, axis=1)\n",
    "final_pbp_df = final_pbp_df.apply(move_outcome, axis=1)\n",
    "\n",
    "# # Display the first few rows of the cleaned dataframe\n",
    "\n",
    "\n",
    "# # # Notes for second step of transformation\n",
    "# # # Faceoff Seem to be working as intended\n",
    "# # # Goal - Primary_player is working as intended\n",
    "# #     # - Primary Team is not being captured - probably because the team name is used and not the abbreviation\n",
    "# # # Shots - Primary_player actually contains the team abbreviation\n",
    "# #     # - Primary_team includes the player name and still includes the shot outcome WIDE, BLOCKED, MISSED in the\n",
    "# #     #  - UPPER CASE - Need to remove the outcome from the team name and move to outcome column\n",
    "# #     #  - MISSED IS THE SAME AS SAVED - also includes the goalie name after the outcome\n",
    "# #     #  - BLOCKED also includes the secondary player name after the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Next Steps \n",
    "# For all Event_type: Shot swap the Primary_player and Primary_team values\n",
    "\n",
    "# Function to swap 'Primary_player' and 'Primary_team' for 'Shot' events\n",
    "def swap_shot_columns(row):\n",
    "    if row['Event_type'] == 'Shot':\n",
    "        row['Primary_player'], row['Primary_team'] = row['Primary_team'], row['Primary_player']\n",
    "    return row\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "final_pbp_df = final_pbp_df.apply(swap_shot_columns, axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to deal with foriegn names like Tommi Mannisto (which has accents and appears like MÃ£Â„nnistÃ£Â–, Tommi. in the data\n",
    "\n",
    "def fix_encoding_issues(df, columns):\n",
    "    \"\"\"\n",
    "    Fix encoding issues in specified columns of a dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing columns with text issues.\n",
    "        columns (list): List of column names to fix.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with fixed text in specified columns.\n",
    "    \"\"\"\n",
    "    def decode_text(text):\n",
    "        try:\n",
    "            # Decode from 'latin1' and re-encode to 'utf-8'\n",
    "            return text.encode('latin1').decode('utf-8')\n",
    "        except (UnicodeEncodeError, UnicodeDecodeError, AttributeError):\n",
    "            # Return text as is if decoding fails\n",
    "            return text\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(decode_text)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "columns_to_fix = ['Primary_player', 'Secondary_player']\n",
    "\n",
    "final_pbp_df = fix_encoding_issues(final_pbp_df, columns_to_fix)# Display the first few rows of the cleaned dataframe\n",
    "# final_pbp_df.head(12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_names(df, columns):\n",
    "    \"\"\"\n",
    "    Standardize player names in the specified columns to 'First Last' format.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing player name columns.\n",
    "        columns (list): List of column names to standardize.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with standardized player names.\n",
    "    \"\"\"\n",
    "    def fix_name_format(name):\n",
    "        if pd.isnull(name):  # Handle missing values\n",
    "            return name\n",
    "        name = name.replace(\".\", \"\")  # Remove periods\n",
    "        if \",\" in name:  # If the name is in 'Last, First' format\n",
    "            parts = name.split(\",\")\n",
    "            return f\"{parts[1].strip()} {parts[0].strip()}\"  # Rearrange to 'First Last'\n",
    "        return name.strip()  # Return as is if already in 'First Last' format\n",
    "\n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(fix_name_format)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "final_pbp_df = standardize_names(final_pbp_df, columns_to_fix)\n",
    "# Display the first few rows of the cleaned dataframe\n",
    "# final_pbp_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def classify_power_play_events(df):\n",
    "    \"\"\"\n",
    "    Classify 'Other' Event_type as 'PP - Start' or 'PP - End' based on the Description,\n",
    "    and extract the team abbreviation to the Primary_team column.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing 'Event_type', 'Description', and 'Primary_team' columns.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The updated dataframe with classified 'Event_type' and filled 'Primary_team'.\n",
    "    \"\"\"\n",
    "    def classify_event(row):\n",
    "        if row['Event_type'] == 'Other':\n",
    "            description = row['Description']\n",
    "            # Check for \"Start power play for\"\n",
    "            if re.search(r\"Start power play for\", description):\n",
    "                row['Event_type'] = 'PP - Start'\n",
    "                row['Primary_team'] = description.split('for')[-1].strip().rstrip('.')\n",
    "            # Check for \"End power play for\"\n",
    "            elif re.search(r\"End power play for\", description):\n",
    "                row['Event_type'] = 'PP - End'\n",
    "                row['Primary_team'] = description.split('for')[-1].strip().rstrip('.')\n",
    "        return row\n",
    "\n",
    "    # Apply the classification function row-wise\n",
    "    df = df.apply(classify_event, axis=1)\n",
    "    return df\n",
    "\n",
    "# Apply the function to classify power play events\n",
    "final_pbp_df = classify_power_play_events(final_pbp_df)\n",
    "\n",
    "# Display the first few rows of the updated dataframe\n",
    "# final_pbp_df.head(22)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 176190 entries, 0 to 176189\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   Game_ID           176190 non-null  object\n",
      " 1   Period            176190 non-null  object\n",
      " 2   Time              176190 non-null  int64 \n",
      " 3   Description       176190 non-null  object\n",
      " 4   Score             176190 non-null  object\n",
      " 5   Event_type        176190 non-null  object\n",
      " 6   Primary_player    153446 non-null  object\n",
      " 7   Primary_team      159463 non-null  object\n",
      " 8   Secondary_player  121353 non-null  object\n",
      " 9   Secondary_team    0 non-null       object\n",
      " 10  Outcome           142498 non-null  object\n",
      " 11  Penalty_duration  6163 non-null    object\n",
      " 12  Penalty_type      6163 non-null    object\n",
      "dtypes: int64(1), object(12)\n",
      "memory usage: 17.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Examine the data\n",
    "final_pbp_df.info()\n",
    "# Value counts\n",
    "# final_pbp_df['Event_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify Media Time out Specifically\n",
    "Description = 'Media time out.' ==> Event_type = Media TO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classify Media Time out Specifically\n",
    "# If Description = 'Media time out.' ==> Event_type = Media TO\n",
    "\n",
    "# Function to classify 'Media TO' events\n",
    "\n",
    "def classify_event(row):\n",
    "    if row['Event_type'] == 'Other' and row['Description'] == 'Media time out.':\n",
    "        row['Event_type'] = 'Media TO'\n",
    "    return row\n",
    "\n",
    "\n",
    "# Apply the classification function row-wise\n",
    "final_pbp_df = final_pbp_df.apply(classify_event, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Media TO Events\n",
    "# final_pbp_df[final_pbp_df['Event_type'] == 'Media TO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deal with Goalie change / info rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def classify_goalie_moves(df):\n",
    "    \"\"\"\n",
    "    Parse goalie moves from the Description column and classify them as 'Goalie Move'.\n",
    "    Extract the goalie name as Primary_player and the team name as Primary_team.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing 'Event_type', 'Description', 'Primary_player', and 'Primary_team' columns.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The updated dataframe with classified 'Event_type', 'Primary_player', and 'Primary_team'.\n",
    "    \"\"\"\n",
    "    def parse_goalie_move(row):\n",
    "        if row['Event_type'] == 'Other':  # Only process rows marked as 'Other'\n",
    "            description = row['Description']\n",
    "            # Look for patterns like 'Name at goalie for Team'\n",
    "            match = re.match(r\"(.+?) at goalie for (.+?)\\.\", description)\n",
    "            if match:\n",
    "                row['Event_type'] = 'Goalie Move'\n",
    "                row['Primary_player'] = match.group(1).strip()  # Extract the goalie's name\n",
    "                row['Primary_team'] = match.group(2).strip()  # Extract the team name\n",
    "        return row\n",
    "\n",
    "    # Apply the parsing function row-wise\n",
    "    df = df.apply(parse_goalie_move, axis=1)\n",
    "    return df\n",
    "\n",
    "# Apply the function to classify goalie moves\n",
    "final_pbp_df = classify_goalie_moves(final_pbp_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In the Outcome column relabel MISSED to SAVED for clairty\n",
    "def relabel_missed_to_saved(df):\n",
    "    \"\"\"\n",
    "    Relabel 'MISSED' to 'SAVED' in the Outcome column.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the Outcome column.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The updated dataframe with relabeled outcomes.\n",
    "    \"\"\"\n",
    "    df['Outcome'] = df['Outcome'].replace('MISSED', 'SAVED')\n",
    "    return df\n",
    "\n",
    "# Apply the relabeling function\n",
    "final_pbp_df = relabel_missed_to_saved(final_pbp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the Penalty_type column to remove periods and any leading/trailing whitespace\n",
    "def clean_penalty_type(df):\n",
    "    \"\"\"\n",
    "    Clean the Penalty_type column by removing periods and extra whitespace.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the Penalty_type column.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The updated dataframe with cleaned Penalty_type.\n",
    "    \"\"\"\n",
    "    df['Penalty_type'] = df['Penalty_type'].str.replace('.', '', regex=False).str.strip()\n",
    "    return df\n",
    "\n",
    "# Apply the cleaning function\n",
    "final_pbp_df = clean_penalty_type(final_pbp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>Period</th>\n",
       "      <th>Time</th>\n",
       "      <th>Description</th>\n",
       "      <th>Score</th>\n",
       "      <th>Event_type</th>\n",
       "      <th>Primary_player</th>\n",
       "      <th>Primary_team</th>\n",
       "      <th>Secondary_player</th>\n",
       "      <th>Secondary_team</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Penalty_duration</th>\n",
       "      <th>Penalty_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024-10-04-Michigan State-Lake Superior</td>\n",
       "      <td>1</td>\n",
       "      <td>837</td>\n",
       "      <td>Goal by Howard, Isaac (EVENSTRENGTH, FIRSTGOAL...</td>\n",
       "      <td>1-0</td>\n",
       "      <td>Goal</td>\n",
       "      <td>Isaac Howard</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2024-10-04-Michigan State-Lake Superior</td>\n",
       "      <td>1</td>\n",
       "      <td>960</td>\n",
       "      <td>Goal by Milburn, Connor (EVENSTRENGTH) Assist ...</td>\n",
       "      <td>1-1</td>\n",
       "      <td>Goal</td>\n",
       "      <td>Connor Milburn</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2024-10-04-Michigan State-Lake Superior</td>\n",
       "      <td>4</td>\n",
       "      <td>939</td>\n",
       "      <td>Goal by Russell, Daniel (EVENSTRENGTH, OVERTIM...</td>\n",
       "      <td>2-1</td>\n",
       "      <td>Goal</td>\n",
       "      <td>Daniel Russell</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2024-10-04-Minnesota State-Michigan</td>\n",
       "      <td>2</td>\n",
       "      <td>1233</td>\n",
       "      <td>Goal by Whitelaw, William (POWER-PLAY, FIRSTGO...</td>\n",
       "      <td>0-1</td>\n",
       "      <td>Goal</td>\n",
       "      <td>William Whitelaw</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>2024-10-04-Minnesota State-Michigan</td>\n",
       "      <td>2</td>\n",
       "      <td>1465</td>\n",
       "      <td>Goal by Carrabes, Brian (EVENSTRENGTH) Assist ...</td>\n",
       "      <td>1-1</td>\n",
       "      <td>Goal</td>\n",
       "      <td>Brian Carrabes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Game_ID Period  Time  \\\n",
       "36   2024-10-04-Michigan State-Lake Superior      1   837   \n",
       "40   2024-10-04-Michigan State-Lake Superior      1   960   \n",
       "186  2024-10-04-Michigan State-Lake Superior      4   939   \n",
       "256      2024-10-04-Minnesota State-Michigan      2  1233   \n",
       "268      2024-10-04-Minnesota State-Michigan      2  1465   \n",
       "\n",
       "                                           Description Score Event_type  \\\n",
       "36   Goal by Howard, Isaac (EVENSTRENGTH, FIRSTGOAL...   1-0       Goal   \n",
       "40   Goal by Milburn, Connor (EVENSTRENGTH) Assist ...   1-1       Goal   \n",
       "186  Goal by Russell, Daniel (EVENSTRENGTH, OVERTIM...   2-1       Goal   \n",
       "256  Goal by Whitelaw, William (POWER-PLAY, FIRSTGO...   0-1       Goal   \n",
       "268  Goal by Carrabes, Brian (EVENSTRENGTH) Assist ...   1-1       Goal   \n",
       "\n",
       "       Primary_player Primary_team Secondary_player Secondary_team Outcome  \\\n",
       "36       Isaac Howard         None             None           None    None   \n",
       "40     Connor Milburn         None             None           None    None   \n",
       "186    Daniel Russell         None             None           None    None   \n",
       "256  William Whitelaw         None             None           None    None   \n",
       "268    Brian Carrabes         None             None           None    None   \n",
       "\n",
       "    Penalty_duration Penalty_type  \n",
       "36               NaN          NaN  \n",
       "40               NaN          NaN  \n",
       "186              NaN          NaN  \n",
       "256              NaN          NaN  \n",
       "268              NaN          NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Show 5 goal events\n",
    "final_pbp_df[final_pbp_df['Event_type'] == 'Goal'].head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Wed 1-29\n",
    "- clean the goal events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grab the Goal Conditions within the parenthesis in the definition\n",
    "### Put in a new column called Goal_Conditions\n",
    "def extract_goal_conditions(df):\n",
    "    \"\"\"\n",
    "    Extract goal conditions from the Description column and add them to a new column called Goal_Conditions.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the Description column.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The updated dataframe with the Goal_Conditions column.\n",
    "    \"\"\"\n",
    "    def extract_conditions(description):\n",
    "        match = re.search(r'\\((.*?)\\)', description)\n",
    "        return match.group(1) if match else None\n",
    "\n",
    "    df['Goal_Conditions'] = df['Description'].apply(extract_conditions)\n",
    "    return df\n",
    "\n",
    "# Apply the extraction function\n",
    "final_pbp_df = extract_goal_conditions(final_pbp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game_ID</th>\n",
       "      <th>Period</th>\n",
       "      <th>Time</th>\n",
       "      <th>Description</th>\n",
       "      <th>Score</th>\n",
       "      <th>Event_type</th>\n",
       "      <th>Primary_player</th>\n",
       "      <th>Primary_team</th>\n",
       "      <th>Secondary_player</th>\n",
       "      <th>Secondary_team</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Penalty_duration</th>\n",
       "      <th>Penalty_type</th>\n",
       "      <th>Goal_Conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024-10-04-Michigan State-Lake Superior</td>\n",
       "      <td>1</td>\n",
       "      <td>837</td>\n",
       "      <td>Goal by Howard, Isaac (EVENSTRENGTH, FIRSTGOAL...</td>\n",
       "      <td>1-0</td>\n",
       "      <td>Goal</td>\n",
       "      <td>Isaac Howard</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EVENSTRENGTH, FIRSTGOAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2024-10-04-Michigan State-Lake Superior</td>\n",
       "      <td>1</td>\n",
       "      <td>960</td>\n",
       "      <td>Goal by Milburn, Connor (EVENSTRENGTH) Assist ...</td>\n",
       "      <td>1-1</td>\n",
       "      <td>Goal</td>\n",
       "      <td>Connor Milburn</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EVENSTRENGTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2024-10-04-Michigan State-Lake Superior</td>\n",
       "      <td>4</td>\n",
       "      <td>939</td>\n",
       "      <td>Goal by Russell, Daniel (EVENSTRENGTH, OVERTIM...</td>\n",
       "      <td>2-1</td>\n",
       "      <td>Goal</td>\n",
       "      <td>Daniel Russell</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EVENSTRENGTH, OVERTIME, SUDDENDEATH, GAMEWINNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2024-10-04-Minnesota State-Michigan</td>\n",
       "      <td>2</td>\n",
       "      <td>1233</td>\n",
       "      <td>Goal by Whitelaw, William (POWER-PLAY, FIRSTGO...</td>\n",
       "      <td>0-1</td>\n",
       "      <td>Goal</td>\n",
       "      <td>William Whitelaw</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POWER-PLAY, FIRSTGOAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>2024-10-04-Minnesota State-Michigan</td>\n",
       "      <td>2</td>\n",
       "      <td>1465</td>\n",
       "      <td>Goal by Carrabes, Brian (EVENSTRENGTH) Assist ...</td>\n",
       "      <td>1-1</td>\n",
       "      <td>Goal</td>\n",
       "      <td>Brian Carrabes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EVENSTRENGTH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Game_ID Period  Time  \\\n",
       "36   2024-10-04-Michigan State-Lake Superior      1   837   \n",
       "40   2024-10-04-Michigan State-Lake Superior      1   960   \n",
       "186  2024-10-04-Michigan State-Lake Superior      4   939   \n",
       "256      2024-10-04-Minnesota State-Michigan      2  1233   \n",
       "268      2024-10-04-Minnesota State-Michigan      2  1465   \n",
       "\n",
       "                                           Description Score Event_type  \\\n",
       "36   Goal by Howard, Isaac (EVENSTRENGTH, FIRSTGOAL...   1-0       Goal   \n",
       "40   Goal by Milburn, Connor (EVENSTRENGTH) Assist ...   1-1       Goal   \n",
       "186  Goal by Russell, Daniel (EVENSTRENGTH, OVERTIM...   2-1       Goal   \n",
       "256  Goal by Whitelaw, William (POWER-PLAY, FIRSTGO...   0-1       Goal   \n",
       "268  Goal by Carrabes, Brian (EVENSTRENGTH) Assist ...   1-1       Goal   \n",
       "\n",
       "       Primary_player Primary_team Secondary_player Secondary_team Outcome  \\\n",
       "36       Isaac Howard         None             None           None    None   \n",
       "40     Connor Milburn         None             None           None    None   \n",
       "186    Daniel Russell         None             None           None    None   \n",
       "256  William Whitelaw         None             None           None    None   \n",
       "268    Brian Carrabes         None             None           None    None   \n",
       "\n",
       "    Penalty_duration Penalty_type  \\\n",
       "36               NaN          NaN   \n",
       "40               NaN          NaN   \n",
       "186              NaN          NaN   \n",
       "256              NaN          NaN   \n",
       "268              NaN          NaN   \n",
       "\n",
       "                                       Goal_Conditions  \n",
       "36                             EVENSTRENGTH, FIRSTGOAL  \n",
       "40                                        EVENSTRENGTH  \n",
       "186  EVENSTRENGTH, OVERTIME, SUDDENDEATH, GAMEWINNI...  \n",
       "256                              POWER-PLAY, FIRSTGOAL  \n",
       "268                                       EVENSTRENGTH  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to just Goal events to check the Goal_Conditions column\n",
    "final_pbp_df[final_pbp_df['Event_type'] == 'Goal'].head(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_primary_team(df):\n",
    "    \"\"\"\n",
    "    Assigns the correct 'Primary_team' to goal events by analyzing score changes.\n",
    "    \"\"\"\n",
    "    # Extract away and home team names from Game_ID\n",
    "    def extract_teams(game_id):\n",
    "        parts = game_id.split('-')\n",
    "        away_team = parts[3]\n",
    "        home_team = parts[4]\n",
    "        return away_team, home_team\n",
    "\n",
    "    # Filter only goal events\n",
    "    goal_df = df[df['Event_type'] == 'Goal'].copy()\n",
    "\n",
    "    # Sort by game and time sequence\n",
    "    goal_df.sort_values(by=['Game_ID', 'Period', 'Time'], inplace=True)\n",
    "\n",
    "    # Initialize previous scores dictionary\n",
    "    prev_scores = {}\n",
    "\n",
    "    # Iterate over goal events\n",
    "    for idx, row in goal_df.iterrows():\n",
    "        game_id = row['Game_ID']\n",
    "        score_str = row['Score']\n",
    "        \n",
    "        if pd.isna(score_str):\n",
    "            continue\n",
    "\n",
    "        # Parse score into integers Unless the string is empty\n",
    "        if score_str:\n",
    "            away_score, home_score = map(int, score_str.split('-'))\n",
    "        else:\n",
    "            None\n",
    "\n",
    "        # away_score, home_score = map(int, score_str.split('-'))\n",
    "\n",
    "        # Extract teams\n",
    "        away_team, home_team = extract_teams(game_id)\n",
    "\n",
    "        # Check previous score to determine which team scored\n",
    "        if game_id in prev_scores:\n",
    "            prev_away, prev_home = prev_scores[game_id]\n",
    "\n",
    "            if away_score > prev_away:\n",
    "                goal_df.at[idx, 'Primary_team'] = away_team\n",
    "            elif home_score > prev_home:\n",
    "                goal_df.at[idx, 'Primary_team'] = home_team\n",
    "        else:\n",
    "            # First goal of the game, determine scorer by score value\n",
    "            if away_score > home_score:\n",
    "                goal_df.at[idx, 'Primary_team'] = away_team\n",
    "            else:\n",
    "                goal_df.at[idx, 'Primary_team'] = home_team\n",
    "\n",
    "        # Update previous score\n",
    "        prev_scores[game_id] = (away_score, home_score)\n",
    "\n",
    "    # Merge updated Primary_team back into original dataframe\n",
    "    df.update(goal_df[['Primary_team']])\n",
    "    return df\n",
    "\n",
    "# Apply function to the dataframe\n",
    "final_pbp_df = assign_primary_team(final_pbp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_pbp_df[final_pbp_df['Event_type'] == 'Goal'].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEAM_MAP is in memory (created earlier from school_info_df)\n",
    "### This block and be used to add additional team mappings before doing the substitution\n",
    "\n",
    "team_map['lksup'] = 'Lake Superior'\n",
    "team_map['miaoh'] = 'Miami'\n",
    "team_map['azst'] = 'Arizona State'\n",
    "team_map['akanc'] = 'Alaska Anchorage'\n",
    "team_map['akfbk'] = 'Alaska'\n",
    "team_map['amint'] = 'American Intl'\n",
    "team_map['augsd'] = 'Augustana'\n",
    "team_map['bsu'] = 'Bemidji State'\n",
    "team_map['cocol'] = 'Colorado College'\n",
    "team_map['maine'] = 'Maine'\n",
    "team_map['mndul'] = 'Minnesota Duluth'\n",
    "team_map['nodak'] = 'North Dakota'\n",
    "team_map['stlaw'] = 'St. Lawrence'\n",
    "team_map['psu'] = 'Penn State'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### ORIGINAL MAP BEFORE I ADDED THE STEP TO REMOVE SPACES BETWEEN TWO CAPS\n",
    "# ### NEED TO ADDRESS MINNESOTA DUTITH, Amerrican International, St Lawerence - THE PARSING IS COMPLETELY FAILING IN AT LEAST SOME OF THEIR GAME\n",
    "# #### ST is also a mess with mutiple teams . Alas is also showing up for bothe Alaska teams\n",
    "# # add 'michigan st': 'Michigan State', to the team_map\n",
    "\n",
    "team_map['michigan st'] = 'Michigan State'\n",
    "team_map['linwod'] = 'Lindenwood'\n",
    "team_map['sup'] = 'Lake Superior'\n",
    "team_map['afa'] = 'Air Force'\n",
    "team_map['anc'] = 'Alaska Anchorage'\n",
    "team_map['asu'] = 'Arizona State'\n",
    "team_map['aug'] = 'Augustana'\n",
    "team_map['ben'] = 'Bentley'\n",
    "# team_map['bgsu santa'] = 'Bowling Green'\n",
    "# team_map['brown st.'] = 'Brown'\n",
    "team_map['can'] = 'Canisius'\n",
    "team_map['clk'] = 'Clarkson'\n",
    "team_map['col'] = 'Colgate'\n",
    "team_map['dak'] = 'North Dakota'\n",
    "team_map['dame'] = 'Notre Dame'\n",
    "team_map['den'] = 'Denver'\n",
    "team_map['dul'] = 'Minnesota Duluth'\n",
    "team_map['fsu'] = 'Ferris State'\n",
    "team_map['har'] = 'Harvard'\n",
    "# team_map['har st.'] = 'Harvard'\n",
    "team_map['int'] = 'American Intl'\n",
    "team_map['lin'] = 'Lindenwood'\n",
    "team_map['lwu'] = 'Lindenwood'\n",
    "team_map['mai'] = 'Maine'\n",
    "team_map['mer'] = 'Mercyhurst'\n",
    "# team_map['michst a'] = 'Michigan State'\n",
    "# team_map['minn pa'] = 'Minnesota'\n",
    "team_map['neu'] = 'Northeastern'\n",
    "team_map['no dak jamernik'] = 'North Dakota'\n",
    "team_map['oh'] = 'Miami'\n",
    "# team_map['omaha van'] = 'Omaha'\n",
    "team_map['pri'] = 'Princeton'\n",
    "team_map['prince'] = 'Princeton'\n",
    "# team_map['pri de la'] = 'Princeton'\n",
    "# team_map['prince de la'] = 'Princeton'\n",
    "team_map['qui'] = 'Quinnipiac'\n",
    "team_map['scs'] = 'St. Cloud State'\n",
    "team_map['sd'] = 'Augustana'\n",
    "team_map['shu'] = 'Sacred Heart'\n",
    "team_map['slu'] = 'St. Lawrence'\n",
    "team_map['stc'] = 'Stonehill'\n",
    "team_map['sup'] = 'Lake Superior'\n",
    "team_map['u-m'] = 'Michigan'\n",
    "team_map['uma'] = 'Massachusetts'\n",
    "team_map['umd'] = 'Minnesota Duluth'\n",
    "team_map['und'] = 'Notre Dame'\n",
    "team_map['uni'] = 'Union'\n",
    "team_map['ust'] = 'St. Thomas'\n",
    "# team_map['vermnt la'] = 'Vermont'\n",
    "team_map['wis'] = 'Wisconsin'\n",
    "team_map['wmu'] = 'Western Michigan'\n",
    "team_map['yal'] = 'Yale'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# team_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardize Team names in Primary Team column\n",
    "\n",
    "# Firs by replaceing abbreviations with full names\n",
    "def standardize_primary_team(df, team_map):\n",
    "    \"\"\"\n",
    "    Standardizes the 'Primary_team' column using the provided team_map.\n",
    "    \"\"\"\n",
    "    # Convert to lowercase and map to standardized names\n",
    "    df['Primary_team'] = df['Primary_team'].str.lower().map(team_map).fillna(df['Primary_team'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Run the function to standardize the 'Primary_team' column\n",
    "final_pbp_df = standardize_primary_team(final_pbp_df, team_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardize Team names in Primary Team column PART 2\n",
    "## Deal with teams with two slightly different names and standardize to CHN names\n",
    "# \"Alaska Fairbanks\" = \"Alaska\"\n",
    "# \"Arizona St\" = \"Arizona State\"\n",
    "# \"Bemidji St\" = \"Bemidji State\"\n",
    "# \"Boston U\" = \"Boston University\"\n",
    "# \"Colorado Col\" = \"Colorado College\"\n",
    "# \"Ferris St\" = \"Ferris State\"\n",
    "# Lake Superior St\" = \"Lake Superior\"\n",
    "# \"Mass. Lowell\" = \"Mass Lowell\"\n",
    "# \"Minnesota St\" = \"Minnesota State\"\n",
    "# Northern Mich = \"Northern Michigan\"\n",
    "# Ohio St = \"Ohio State\"\n",
    "# Penn St = \"Penn State\"\n",
    "# Western Mich = \"Western Michigan\"\n",
    "# St Cloud State = \"St. Cloud State\"\n",
    "\n",
    "# Function to make the substitutions\n",
    "def standardize_team_names(df):\n",
    "    \"\"\"\n",
    "    Standardizes team names in the 'Primary_team' column.\n",
    "    \"\"\"\n",
    "    # Define team name substitutions\n",
    "    team_substitutions = {\n",
    "        'Alaska Fairbanks': 'Alaska',\n",
    "        'Arizona St': 'Arizona State',\n",
    "        'Bemidji St': 'Bemidji State',\n",
    "        'Boston U': 'Boston University',\n",
    "        'Colorado Col': 'Colorado College',\n",
    "        'Ferris St': 'Ferris State',\n",
    "        'Lake Superior St': 'Lake Superior',\n",
    "        'Mass. Lowell': 'Mass Lowell',\n",
    "        'Minnesota St': 'Minnesota State',\n",
    "        'Northern Mich': 'Northern Michigan',\n",
    "        'Ohio St': 'Ohio State',\n",
    "        'Penn St': 'Penn State',\n",
    "        'Western Mich': 'Western Michigan',\n",
    "        'St Cloud State': 'St. Cloud State'\n",
    "    }\n",
    "\n",
    "    # Apply the substitutions\n",
    "    df['Primary_team'] = df['Primary_team'].replace(team_substitutions)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Run the function to standardize team names\n",
    "final_pbp_df = standardize_team_names(final_pbp_df)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_pbp_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the dataframe to a CSV file\n",
    "final_pbp_df.to_csv(os.path.join(temp_folder, 'pbp_data_Feb_13.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Updated Schedule DF (With PbP JSONs) to csv to avoid scraping for new tests\n",
    "\n",
    "updated_schedule_df.to_csv(os.path.join(data_folder, 'schedule_from_ncaa_with_PbP_JSON.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 176190 entries, 0 to 176189\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   Game_ID           176190 non-null  object\n",
      " 1   Period            176190 non-null  object\n",
      " 2   Time              176190 non-null  int64 \n",
      " 3   Description       176190 non-null  object\n",
      " 4   Score             176190 non-null  object\n",
      " 5   Event_type        176190 non-null  object\n",
      " 6   Primary_player    157516 non-null  object\n",
      " 7   Primary_team      168299 non-null  object\n",
      " 8   Secondary_player  121353 non-null  object\n",
      " 9   Secondary_team    0 non-null       object\n",
      " 10  Outcome           142498 non-null  object\n",
      " 11  Penalty_duration  6163 non-null    object\n",
      " 12  Penalty_type      6163 non-null    object\n",
      " 13  Goal_Conditions   4952 non-null    object\n",
      "dtypes: int64(1), object(13)\n",
      "memory usage: 18.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Event_type\n",
       "Shot           89953\n",
       "Faceoff        52575\n",
       "Penalty         6356\n",
       "PP - Start      5444\n",
       "PP - End        5352\n",
       "Goal            4780\n",
       "Other           4625\n",
       "Goalie Move     4070\n",
       "Media TO        3035\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Examine the final dataframe\n",
    "final_pbp_df.info()\n",
    "\n",
    "# Value counts\n",
    "final_pbp_df['Event_type'].value_counts()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
