{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2024 -25 Roster Explore Notebook #1\n",
    "#### Created 8/25/24 -by JBS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping code taken from Roster_scraper_variable.ipynb in the original college_hockey folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "# print list of folders one dir up from current\n",
    "# print(os.listdir(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# path ro TEMP folder\n",
    "temp_folder = os.path.join(os.getcwd(), '..', 'TEMP')\n",
    "# Data folder\n",
    "data_folder = os.path.join(os.getcwd(), '..', 'data')\n",
    "# Image folder\n",
    "img_folder = os.path.join(os.getcwd(), '..', 'images')\n",
    "\n",
    "# # save file into each folder for testing\n",
    "\n",
    "# file = os.path.join(temp_folder, 'test.txt')\n",
    "# with open(file, 'w') as f:\n",
    "#     f.write('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get All Scheduled games for the given season in CHN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the URL to scrape\n",
    "url_base = 'https://www.collegehockeynews.com/schedules/?season=' # Link to the 2022-2023 season with all results\n",
    "\n",
    "#### THESE NEED TO BE UPDATED EACH SEASON ####\n",
    "#### Set the season varriable portion of the url \n",
    "url_season = '20242025'\n",
    "#### string to add to file names and whatnote\n",
    "file_tag = '2024_current_sept_25'\n",
    "\n",
    "############# Set the output folder to the TEMP folder for testing\n",
    "final_output_dir = os.path.join(temp_folder)\n",
    "\n",
    "# # Set the output folder to the data folder\n",
    "# final_output_dir = os.path.join(data_folder, 'schedule')\n",
    "\n",
    "\n",
    "# temp_output_dir = '../TEMP/results/'\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "## Construction the url to feel to parser\n",
    "url = url_base + url_season\n",
    "\n",
    "# Get the page with requests\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# select the table or tables\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "# Initialize variables\n",
    "current_date = None\n",
    "current_conference = None\n",
    "game_notes = None\n",
    "\n",
    "# Initialize an empty list to hold the data\n",
    "data = []\n",
    "\n",
    "# Parse the table with BeautifulSoup\n",
    "\n",
    "rows = soup.find_all('tr')\n",
    "\n",
    "# Loop through each row to find relevant information\n",
    "for row in rows:\n",
    "    # Check for date row\n",
    "    if row.get('class') == ['stats-section']:\n",
    "        current_date = row.find('td').text.strip()\n",
    "    # Check for conference row\n",
    "    elif row.get('class') == ['sked-header']:\n",
    "        current_conference = row.find('td').text.strip()\n",
    "    # Check for game notes\n",
    "    elif len(row.find_all('td')) == 2:\n",
    "        game_notes = row.find_all('td')[1].text.strip()\n",
    "    # Process rows with game data\n",
    "    elif row.get('valign') == 'top':\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) >= 9:\n",
    "            home_team = cells[0].text.strip()\n",
    "            home_team_link = cells[0].find('a')['href'] if cells[0].find('a') else None\n",
    "            home_score = cells[1].text.strip()\n",
    "            away_team = cells[3].text.strip()\n",
    "            away_team_link = cells[3].find('a')['href'] if cells[3].find('a') else None\n",
    "            away_score = cells[4].text.strip()\n",
    "            ot = cells[5].text.strip()\n",
    "            box_link = cells[7].find('a')['href'] if cells[7].find('a') else None\n",
    "            metrics_link = cells[8].find('a')['href'] if cells[8].find('a') else None\n",
    "             # Capture Game Notes\n",
    "            game_notes_cell = cells[-1].find('small')\n",
    "            game_notes = game_notes_cell.text.strip() if game_notes_cell else None\n",
    "\n",
    "            # Append data to the list\n",
    "            data.append([current_date, current_conference, game_notes, home_team, home_team_link, home_score, away_team, away_team_link, away_score, ot, box_link, metrics_link])\n",
    "            game_notes = None  # Reset game notes for the next row\n",
    "            \n",
    "\n",
    "# Create a DataFrame\n",
    "columns = ['Date', 'Conference', 'Game_Notes', 'Away_Team', 'Away_Team_Link', 'Away_Score', 'Home_Team', 'Home_Team_Link', 'Home_Score',  'OT', 'Box_Link', 'Metrics_Link']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Data Tranformation\n",
    "#### Creates Unique GAME_ID\n",
    "- Cleaning string formats, \n",
    "- create team abbv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract the day of the week from the date and save in new column\n",
    "df['Day'] = pd.to_datetime(df['Date']).dt.day_name()\n",
    "# remove day of the week from date\n",
    "# format data column as YYYY-MM-DD\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "### Create a new column for the game ID\n",
    "## Game ID will be a combination of the date and abbreviated team names\n",
    "\n",
    "# Function to abbreviate the team names\n",
    "for row in df.itertuples():\n",
    "    home_team = row.Home_Team\n",
    "    away_team = row.Away_Team\n",
    "    home_team_abbr = home_team.split(' ')[-1]\n",
    "    away_team_abbr = away_team.split(' ')[-1]\n",
    "    game_id = f'{row.Date}_{home_team_abbr}_{away_team_abbr}'\n",
    "    df.loc[row.Index, 'Game_ID'] = game_id\n",
    "\n",
    "# Create a new column for the game ID\n",
    "df['Game_ID'] = df['Game_ID'].str.replace(',', '')\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['Game_ID'] = df.apply(lambda row: f'{row.Date}_{row.Home_Team}_{row.Away_Team}', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adress team name problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove periods from team names\n",
    "df['Home_Team'] = df['Home_Team'].str.replace('.', '')\n",
    "df['Away_Team'] = df['Away_Team'].str.replace('.', '')\n",
    "# Replace Dashes with spaces\n",
    "df['Home_Team'] = df['Home_Team'].str.replace('-', ' ')\n",
    "df['Away_Team'] = df['Away_Team'].str.replace('-', ' ')\n",
    "# Replace ' with space\n",
    "df['Home_Team'] = df['Home_Team'].str.replace(\"'\", '')\n",
    "df['Away_Team'] = df['Away_Team'].str.replace(\"'\", '')\n",
    "\n",
    "\n",
    "# Strip whitespace\n",
    "df['Home_Team'] = df['Home_Team'].str.strip()\n",
    "df['Away_Team'] = df['Away_Team'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Conference</th>\n",
       "      <th>Game_Notes</th>\n",
       "      <th>Away_Team</th>\n",
       "      <th>Away_Team_Link</th>\n",
       "      <th>Away_Score</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>Home_Team_Link</th>\n",
       "      <th>Home_Score</th>\n",
       "      <th>OT</th>\n",
       "      <th>Box_Link</th>\n",
       "      <th>Metrics_Link</th>\n",
       "      <th>Day</th>\n",
       "      <th>Game_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>Non-Conference</td>\n",
       "      <td></td>\n",
       "      <td>Michigan State</td>\n",
       "      <td>/reports/team/Michigan-State/32</td>\n",
       "      <td></td>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>/reports/team/Lake-Superior/24</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>/schedules/taleoftape.php?gid=100540</td>\n",
       "      <td>None</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2024-10-04_Lake Superior_Michigan State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>Non-Conference</td>\n",
       "      <td></td>\n",
       "      <td>Minnesota State</td>\n",
       "      <td>/reports/team/Minnesota-State/35</td>\n",
       "      <td></td>\n",
       "      <td>Michigan</td>\n",
       "      <td>/reports/team/Michigan/31</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>/schedules/taleoftape.php?gid=100317</td>\n",
       "      <td>None</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2024-10-04_Michigan_Minnesota State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>Non-Conference</td>\n",
       "      <td></td>\n",
       "      <td>Colgate</td>\n",
       "      <td>/reports/team/Colgate/15</td>\n",
       "      <td></td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>/reports/team/Connecticut/17</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>/schedules/taleoftape.php?gid=100832</td>\n",
       "      <td>None</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2024-10-04_Connecticut_Colgate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>Non-Conference</td>\n",
       "      <td></td>\n",
       "      <td>Arizona State</td>\n",
       "      <td>/reports/team/Arizona-State/61</td>\n",
       "      <td></td>\n",
       "      <td>Air Force</td>\n",
       "      <td>/reports/team/Air-Force/1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>/schedules/taleoftape.php?gid=99879</td>\n",
       "      <td>None</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2024-10-04_Air Force_Arizona State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-05</td>\n",
       "      <td>Non-Conference</td>\n",
       "      <td></td>\n",
       "      <td>Penn State</td>\n",
       "      <td>/reports/team/Penn-State/60</td>\n",
       "      <td></td>\n",
       "      <td>Alaska</td>\n",
       "      <td>/reports/team/Alaska/4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>/schedules/taleoftape.php?gid=100580</td>\n",
       "      <td>None</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2024-10-05_Alaska_Penn State</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Conference Game_Notes        Away_Team  \\\n",
       "0  2024-10-04  Non-Conference              Michigan State   \n",
       "1  2024-10-04  Non-Conference             Minnesota State   \n",
       "2  2024-10-04  Non-Conference                     Colgate   \n",
       "3  2024-10-04  Non-Conference               Arizona State   \n",
       "4  2024-10-05  Non-Conference                  Penn State   \n",
       "\n",
       "                     Away_Team_Link Away_Score      Home_Team  \\\n",
       "0   /reports/team/Michigan-State/32             Lake Superior   \n",
       "1  /reports/team/Minnesota-State/35                  Michigan   \n",
       "2          /reports/team/Colgate/15               Connecticut   \n",
       "3    /reports/team/Arizona-State/61                 Air Force   \n",
       "4       /reports/team/Penn-State/60                    Alaska   \n",
       "\n",
       "                   Home_Team_Link Home_Score OT  \\\n",
       "0  /reports/team/Lake-Superior/24                 \n",
       "1       /reports/team/Michigan/31                 \n",
       "2    /reports/team/Connecticut/17                 \n",
       "3       /reports/team/Air-Force/1                 \n",
       "4          /reports/team/Alaska/4                 \n",
       "\n",
       "                               Box_Link Metrics_Link       Day  \\\n",
       "0  /schedules/taleoftape.php?gid=100540         None    Friday   \n",
       "1  /schedules/taleoftape.php?gid=100317         None    Friday   \n",
       "2  /schedules/taleoftape.php?gid=100832         None    Friday   \n",
       "3   /schedules/taleoftape.php?gid=99879         None    Friday   \n",
       "4  /schedules/taleoftape.php?gid=100580         None  Saturday   \n",
       "\n",
       "                                   Game_ID  \n",
       "0  2024-10-04_Lake Superior_Michigan State  \n",
       "1      2024-10-04_Michigan_Minnesota State  \n",
       "2           2024-10-04_Connecticut_Colgate  \n",
       "3       2024-10-04_Air Force_Arizona State  \n",
       "4             2024-10-05_Alaska_Penn State  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STORE AS SCHED_DF\n",
    "sched_df = df.copy()\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# IN THE TEMP FOLDER\n",
    "sched_df.to_csv(os.path.join(final_output_dir, f'schedule_{file_tag}.csv'), index=False)\n",
    "# TO THE DATA FOLDER\n",
    "sched_df.to_csv(os.path.join(data_folder, f'schedule_{file_tag}.csv'), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get The Roster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Load results for season to get team links\n",
    "# Read the CSV file\n",
    "# results = pd.read_csv('../../data/results_table_all_time.csv')\n",
    "results = sched_df.copy()\n",
    "\n",
    "season = 2024\n",
    "\n",
    "# # Concatenate the unique values in 'Home_Team_Link' and 'Away_Team_Link'\n",
    "team_links = pd.concat([results['Home_Team_Link'], results['Away_Team_Link']])\n",
    "\n",
    "# Drop duplicates and NaN values\n",
    "team_links = team_links.drop_duplicates().dropna()\n",
    "\n",
    "# Clean up the links - drop everything before the third slash - keep the team name and the school ID as string\n",
    "team = team_links.str.split('/', expand=True)[3]\n",
    "# ORIGINAL\n",
    "number = team_links.str.split('/', expand=True)[4]\n",
    "\n",
    "# NEW - Create a string for the year '{season}{season+1}'\n",
    "year = str(season) + str(season+1)\n",
    "# reconstruct the link and store in a new column\n",
    "team_links = 'https://www.collegehockeynews.com/reports/roster/' + team + '/' + number + '/' + year\n",
    "\n",
    "# reset the index\n",
    "team_links = team_links.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "team_links\n",
    "\n",
    "\n",
    "# Output results\n",
    "print(f'Number of team links: {len(team_links)}')\n",
    "print(f'TEST LINK: FIRST IN LIST: {team_links[0]}')\n",
    "print(f'TEST LINK: LAST IN LIST: {team_links.iloc[-1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions that clean the roster dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()# Function to split \"Last Team\" into \"Team\" and \"League\" with edge case handling\n",
    "def split_last_team(last_team):\n",
    "    # Use regular expression to extract team and league\n",
    "    match = re.search(r'(.+) \\((.+)\\)', last_team)\n",
    "    if match:\n",
    "        return match.groups()\n",
    "    else:\n",
    "        # If no league is specified, return the team as is and leave league blank\n",
    "        return last_team, \"\"\n",
    "\n",
    "# Updated function to correctly capture the player's position and handle edge cases in \"Last Team\"\n",
    "def parse_and_transform_roster(html_content):\n",
    "    # Initialize BeautifulSoup object\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find the table with the roster\n",
    "    roster_table = soup.find('table', {'id': 'players'})\n",
    "\n",
    "    # Check if the table exists\n",
    "    if roster_table is None:\n",
    "        print(\"Skipped: The table doesn't exist.\")\n",
    "        return None\n",
    "    \n",
    "    # Extract headers\n",
    "    header_row = roster_table.find('thead').find('tr')\n",
    "    headers = [header.text.strip() for header in header_row.find_all('th')]\n",
    "    headers.append('Position')  # Add the Position column to headers\n",
    "    \n",
    "    # Initialize data list and current_position variable\n",
    "    data = []\n",
    "    current_position = None  # Initialize as None to later filter out irrelevant rows\n",
    "    \n",
    "    # Iterate through each row in the table\n",
    "    for row in roster_table.find_all('tr'):\n",
    "        if 'class' in row.attrs and 'stats-section' in row.attrs['class']:\n",
    "            current_position = row.text.strip()\n",
    "        else:\n",
    "            cells = row.find_all('td')\n",
    "            if cells and current_position:\n",
    "                row_data = [cell.text.strip() for cell in cells]\n",
    "                row_data.append(current_position)  # Add the current position to the row data\n",
    "                data.append(row_data)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "    # Check if DataFrame is empty or if key columns are missing\n",
    "    if df.empty or 'Last Team' not in df.columns or 'NHL Draft' not in df.columns:\n",
    "        print(\"Skipped: The DataFrame is empty or missing key columns.\")\n",
    "        return None\n",
    "    \n",
    "    # Cleanup: Remove rows where 'No.' column is not numeric\n",
    "    df = df[df['No.'].str.isnumeric()]\n",
    "    \n",
    "    # Cleanup: Drop the 'Pos' column\n",
    "    df.drop(columns=['Pos'], inplace=True)\n",
    "    \n",
    "    # Transform Height to Inches\n",
    "    df['Height_Inches'] = df['Ht.'].apply(convert_to_inches)\n",
    "\n",
    "    # Transform NHL Draft to Draft_Year, NHL_Team, and D_Round\n",
    "    # Transform NHL Draft to Draft_Year, NHL_Team, and D_Round\n",
    "    draft_result = df['NHL Draft'].apply(split_nhl_draft)\n",
    "\n",
    "    # Check if there are enough values to unpack\n",
    "    if len(draft_result) > 0:\n",
    "        df['Draft_Year'], df['NHL_Team'], df['D_Round'] = zip(*draft_result)\n",
    "    else:\n",
    "        # Handle the case when result is empty\n",
    "        df['Draft_Year'], df['NHL_Team'], df['D_Round'] = [None] * len(df), [None] * len(df), [None] * len(df)\n",
    "\n",
    "    df.drop(columns=['NHL Draft'], inplace=True) # Drop the original NHL Draft column\n",
    "    \n",
    "    # Handle edge cases in \"Last Team\" to split into \"Team\" and \"League\"\n",
    "    df['Team'], df['League'] = zip(*df['Last Team'].apply(split_last_team))\n",
    "    df.drop(columns=['Last Team'], inplace=True)\n",
    "    \n",
    "    # Rename the trouble column Hometown\\nLast Team\\nNHL Draft\n",
    "    df.rename(columns={'Hometown\\nLast Team\\nNHL Draft': 'Hometown'}, inplace=True)\n",
    "\n",
    "    # assign data types No. Wt. and Height_Inches to int, DOB to datetime\n",
    "    int_list = ['No.', 'Wt.', 'Height_Inches']\n",
    "    # Convert columns to numeric, coercing errors to NaN\n",
    "    df[int_list] = df[int_list].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Replace NaNs with a default value for specific columns\n",
    "    default_value = 0\n",
    "    df[int_list] = df[int_list].fillna(value=default_value)\n",
    "\n",
    "    # Confirm that NaNs are filled\n",
    "    print(df[int_list].isna().sum())  # Should output all zeros\n",
    "\n",
    "    # Convert the columns to integers\n",
    "    df[int_list] = df[int_list].astype(int)\n",
    "\n",
    "    # df = df[df['Height_Inches'].notna()]  # Assuming convert_to_inches returns None for bad values\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to split \"NHL Draft\" into \"Draft_Year\", \"NHL_Team\", and \"D_Round\"\n",
    "def split_nhl_draft(nhl_draft):\n",
    "    try:\n",
    "        draft_year, nhl_team, d_round = nhl_draft.split('-')\n",
    "        return draft_year, nhl_team, d_round\n",
    "    except ValueError:\n",
    "        # Handle missing or incomplete data\n",
    "        return None, None, None\n",
    "\n",
    "# # Test the function\n",
    "# test_values = ['2022-WSH-7', '', '2021-DET']\n",
    "# [split_nhl_draft(val) for val in test_values]\n",
    "\n",
    "\n",
    "\n",
    "# Function to convert height in \"ft-in\" format to total inches\n",
    "def convert_to_inches(height_str):\n",
    "    try:\n",
    "        feet, inches = map(int, height_str.split('-'))\n",
    "        return (feet * 12) + inches\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the roster scrape and parser for the list of team name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the code to handle the 'Team' and 'Last Team' columns properly\n",
    "\n",
    "## Loop through the team links and parse the roster data \n",
    "### Notes: save the roster link to the dataframe and add the team name and school ID\n",
    "\n",
    "roster_dfs = []  # Assuming this list exists to store each roster DataFrame\n",
    "\n",
    "# Extract team names from team_links\n",
    "team_names = pd.Series(team_links).str.split('/', expand=True)[5]\n",
    "\n",
    "\n",
    "for i, link in enumerate(team_links):\n",
    "    print(f'Processing team {i+1} of {len(team_links)}')\n",
    "    \n",
    "    try:\n",
    "        # Make GET request to team link\n",
    "        r = requests.get(link)\n",
    "        r.raise_for_status()  # This will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "        html_content = r.text\n",
    "        \n",
    "        # Parse and transform the roster data\n",
    "        roster_df = parse_and_transform_roster(html_content)\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error during the request for team {i+1} ({team_names.iloc[i]}): {e}\")\n",
    "        continue\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing the data for team {i+1} ({team_names.iloc[i]}): {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Check if the DataFrame exists (i.e., the page had content)\n",
    "    if roster_df is None:\n",
    "        print(f\"Skipping team {i+1} due to missing or empty data.\")\n",
    "        continue  # Skip this iteration and move to the next one\n",
    "\n",
    "    try:\n",
    "        # Reset the index if it's not unique\n",
    "        roster_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Add the team name\n",
    "        current_team = team_names.iloc[i]  # Extract the current team name\n",
    "        roster_df['Current Team'] = current_team  # Add it to the DataFrame\n",
    "\n",
    "        # Add a column with the season\n",
    "        roster_df['Season'] = season\n",
    "        \n",
    "        # Add the roster DataFrame to the list\n",
    "        roster_dfs.append(roster_df)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error working with the DataFrame for team {i+1} ({team_names.iloc[i]}): {e}\")\n",
    "        continue\n",
    "\n",
    "# Assuming the last dataframe processed is the one of interest (can be adjusted later)\n",
    "# roster_df = roster_dfs[-1]\n",
    "\n",
    "# Add all the DataFrames in the list to a single DataFrame\n",
    "roster_df = pd.concat(roster_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Roster Cleaning Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTPUT TO TEMP FOLDER FOR EXAMINATION\n",
    "# roster_df.to_csv(os.path.join(temp_folder, f'roster_{file_tag}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Further transformations\n",
    "\n",
    "roster_df['Current Team'] = roster_df['Current Team'].str.replace('-', ' ') # Remove - [dash] from Current Team\n",
    "roster_df.columns = roster_df.columns.str.replace('.', '')  # Remove periods in column names\n",
    "# Split 'Name' into 'First Name' and 'Last Name'\n",
    "roster_df['Last_Name'] = roster_df['Name'].str.split(',').str[0]  # Extract 'Last Name'\n",
    "roster_df['First_Name'] = roster_df['Name'].str.split(',').str[1]  # Extract 'First Name'\n",
    "# roster_df['Name'] = roster_df['Name'].str.split(',').str[::-1].str.join(' ')  # Convert 'Last, First' to 'First Last'\n",
    "roster_df['Player'] = roster_df['Name']  # Store the Player name as 'First Last'\n",
    "roster_df['Player'] = roster_df['Player'].str.replace(u'\\xa0', u' ').str.strip()  # Cleanup player name\n",
    "roster_df = roster_df.drop(['Name'], axis=1)  # Drop the original 'Name' column\n",
    "\n",
    "# Renaming 'Team' to 'Last Team' if it exists in the DataFrame\n",
    "if 'Team' in roster_df.columns:\n",
    "    roster_df.rename(columns={'Team': 'Last Team'}, inplace=True)\n",
    "\n",
    "# Checking if 'Last Team' exists in the dataframe before reordering\n",
    "if 'Last Team' not in roster_df.columns:\n",
    "    print(\"'Last Team' column not found in the DataFrame. Please check the data extraction process.\")\n",
    "else:\n",
    "    # Reorder columns without duplicate 'Team'\n",
    "    roster_df = roster_df[['Current Team', 'Last_Name', 'First_Name', 'No', 'Position', 'Yr', 'Ht', 'Wt', 'DOB', \n",
    "                           'Hometown', 'Height_Inches', 'Draft_Year', 'NHL_Team', 'D_Round', 'Last Team', 'League']]\n",
    "\n",
    "roster_df.head() if 'Last Team' in roster_df.columns else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the Hometown column\n",
    "- Explode Hometown into City, State/Provence, Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the Hometown column is a string and handle NaN values\n",
    "roster_df['Hometown'] = roster_df['Hometown'].astype(str)\n",
    "\n",
    "# First step: split the Hometown column by commas into two parts (city and state/province)\n",
    "# We'll explicitly handle cases where there may not be two parts\n",
    "split_columns = roster_df['Hometown'].str.split(',', n=1, expand=True)\n",
    "\n",
    "# Assign split values to new columns and handle missing values\n",
    "roster_df['City'] = split_columns[0].str.strip()\n",
    "roster_df['State_Province'] = split_columns[1].str.strip() if split_columns.shape[1] > 1 else ''\n",
    "\n",
    "\n",
    "# Define a list of known USA states and Canadian provinces abbreviations\n",
    "usa_states = ['Ala.', 'Alaska', 'Ariz.', 'Ark.', 'Calif.', 'Colo.', 'Conn.', 'Del.', 'D.C.', 'DC', 'Fla.', 'Ga.', 'Hawaii', \n",
    "              'Idaho', 'Ill.', 'Ind.', 'Iowa', 'Kan.', 'Ky.', 'La.', 'Maine', 'Md.', 'Mass.', 'Mich.', 'Minn.', 'Miss.', \n",
    "              'Mo.', 'Mont.', 'Neb.', 'Nev.', 'N.H.', 'N.J.', 'N.M.', 'N.Y.', 'N.C.', 'N.D.', 'Ohio', 'Okla.', 'Ore.', \n",
    "              'Pa.', 'R.I.', 'S.C.', 'S.D.', 'Tenn.', 'Texas', 'Utah', 'Vt.', 'Va.', 'Wash.', 'W.Va.', 'Wis.', 'Wisc.', 'Wyo.']\n",
    "\n",
    "canada_provinces = ['Alta.', 'Alb.', 'B.C.', 'Man.', 'MB', 'N.B.', 'NB', 'N.L.', 'Newf.', 'NWT', 'N.S.', 'N.W.T.', 'Nunavut', 'Ont.', 'P.E.I.', 'Que.', 'Sask.', 'Yukon', 'YT']\n",
    "\n",
    "# Function to infer country more robustly\n",
    "def robust_infer_country(state_province):\n",
    "    if pd.isna(state_province) or state_province == '':\n",
    "        return None\n",
    "    state_province = state_province.strip()\n",
    "    \n",
    "    # USA state\n",
    "    if state_province in usa_states:\n",
    "        return 'USA'\n",
    "    \n",
    "    # Canadian province\n",
    "    if state_province in canada_provinces:\n",
    "        return 'Canada'\n",
    "    \n",
    "    # If it doesn't match USA or Canada, treat the state_province as a country\n",
    "    return state_province\n",
    "\n",
    "# Apply the updated function to infer the country for each player\n",
    "roster_df['Country'] = roster_df['State_Province'].apply(robust_infer_country)\n",
    "\n",
    "# Country abreviations that need to be replaced ITA-Italy, AUT-Austria, SUI-Switzerland\n",
    "roster_df['Country'] = roster_df['Country'].replace({'ITA': 'Italy', 'AUT': 'Austria', 'SUI': 'Switzerland'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADDED 9/18/2024\n",
    "\n",
    "# Need to furthur standardize some state, provence and country names\n",
    "## Dictionary to standardize state/province names\n",
    "\n",
    "standardized_locations = {\n",
    "    'Ont.': 'Ontario', 'Mich.': 'Michigan', 'Mass.': 'Massachusetts', 'Minn.': 'Minnesota', \n",
    "    'Wis.': 'Wisconsin', 'Sweden': 'Sweden', 'Germany': 'Germany', 'B.C.': 'British Columbia',\n",
    "    'N.Y.': 'New York', 'Wash.': 'Washington', 'Que.': 'Quebec', 'Alb.': 'Alberta', \n",
    "    'N.J.': 'New Jersey', 'Sask.': 'Saskatchewan', 'Conn.': 'Connecticut', 'Mo.': 'Missouri',\n",
    "    'Texas': 'Texas', 'Calif.': 'California', 'DC': 'District of Columbia', 'Fla.': 'Florida',\n",
    "    'Ohio': 'Ohio', 'Ill.': 'Illinois', 'Pa.': 'Pennsylvania', 'Ga.': 'Georgia',\n",
    "    'Mont.': 'Montana', 'Tenn.': 'Tennessee', 'Colo.': 'Colorado', 'Va.': 'Virginia', \n",
    "    'Vt.': 'Vermont', 'R.I.': 'Rhode Island', 'Md.': 'Maryland', 'Ariz.': 'Arizona', \n",
    "    'Wisc.': 'Wisconsin', 'Iowa': 'Iowa', 'Man.': 'Manitoba', 'Slovakia': 'Slovakia', \n",
    "    'N.D.': 'North Dakota', 'N.C.': 'North Carolina', 'P.E.I.': 'Prince Edward Island',\n",
    "    'N.H.': 'New Hampshire', 'Alaska': 'Alaska', 'Belarus': 'Belarus', 'MB': 'Manitoba',\n",
    "    'Russia': 'Russia', 'Finland': 'Finland', 'Newf.': 'Newfoundland and Labrador', \n",
    "    'Hungary': 'Hungary', 'SUI': 'Switzerland', 'S.C.': 'South Carolina', 'Latvia': 'Latvia',\n",
    "    'Czech Republic': 'Czech Republic', 'N.B.': 'New Brunswick', 'Great Britain': 'United Kingdom', \n",
    "    'NB': 'New Brunswick', 'Norway': 'Norway', 'N.S.': 'Nova Scotia', 'Ind.': 'Indiana', \n",
    "    'NWT': 'Northwest Territories', 'AUT': 'Austria', 'Idaho': 'Idaho', 'S.D.': 'South Dakota', \n",
    "    'Switzerland': 'Switzerland', 'Ore.': 'Oregon', 'Wyo.': 'Wyoming', 'Utah': 'Utah', \n",
    "    'ITA': 'Italy', 'Slovenia': 'Slovenia', 'YT': 'Yukon', 'Del.': 'Delaware', 'Maine': 'Maine',\n",
    "    'Poland': 'Poland', 'Yukon': 'Yukon', 'Ukraine': 'Ukraine', 'Japan': 'Japan', 'Neb.': 'Nebraska'\n",
    "}\n",
    "\n",
    "## Apply the standardization to the State/Province column\n",
    "roster_df['State_Province'] = roster_df['State_Province'].replace(standardized_locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTPUT CLEANED ROSTER FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHECK RESULTING DATAFRAME\n",
    "roster_df.head()\n",
    "\n",
    "roster_df.info()\n",
    "\n",
    "roster_df.sample(20)\n",
    "\n",
    "# Store todays data as a string\n",
    "date = pd.to_datetime('today').strftime('%Y%m%d')\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# In the TEMP folder\n",
    "roster_df.to_csv(os.path.join(final_output_dir, f'roster_{file_tag}v4_ex{date}.csv'), index=False)\n",
    "# In the DATA folder\n",
    "roster_df.to_csv(os.path.join(data_folder, f'roster_{file_tag}_v4_ex{date}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of players with no Last Team and or League vs total number of players\n",
    "missing_team = roster_df['Last Team'].isna().sum()\n",
    "missing_league = roster_df['League'].isna().sum()\n",
    "\n",
    "print(f'Number of players with missing Last Team: {missing_team}')\n",
    "print(f'Number of players with missing League: {missing_league}')\n",
    "print(f'Total number of players: {len(roster_df)}')\n",
    "print('########################################\\n')\n",
    "print('########################################')\n",
    "print(f'Distribution of players by position:\\n{roster_df[\"Position\"].value_counts()}')\n",
    "print('########################################\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Teams with the most draft picks\n",
    "# Filter out players with missing draft information\n",
    "draft_df = roster_df[roster_df['Draft_Year'].notna()]\n",
    "\n",
    "# Group by 'Current Team' and count the number of draft picks\n",
    "team_draft_counts = draft_df['Current Team'].value_counts()\n",
    "print(f'Teams with the most draft picks:\\n{team_draft_counts.head(20)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player by League\n",
    "print('########################################')\n",
    "print(f'Distribution of players by League:\\n{roster_df[\"League\"].value_counts()}')\n",
    "\n",
    "## Distrobution by class year\n",
    "print('########################################\\n')\n",
    "print(f'Distribution of players by Class Year:\\n{roster_df[\"Yr\"].value_counts()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Value Count of First Name\n",
    "print('########################################\\n')\n",
    "print(f'Distribution of players by First Name:\\n{roster_df[\"First_Name\"].value_counts()}')\n",
    "\n",
    "## Value Count of Last Name\n",
    "print('########################################\\n')\n",
    "print(f'Distribution of players by Last Name:\\n{roster_df[\"Last_Name\"].value_counts()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Value Count of City\n",
    "print('########################################\\n')\n",
    "print(f'Distribution of players by Hometown:\\n{roster_df[\"City\"].value_counts()}')\n",
    "\n",
    "## Value Count of State_Province\n",
    "print('########################################\\n')\n",
    "print(f'Distribution of players by State_Province:\\n{roster_df[\"State_Province\"].value_counts()}')\n",
    "\n",
    "## Value Count of Country\n",
    "print('########################################\\n')\n",
    "print(f'Distribution of players by Country:\\n{roster_df[\"Country\"].value_counts()}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
