{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2024 -25 Roster Explore Notebook #1\n",
    "#### Created 8/25/24 -by JBS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping code taken from Roster_scraper_variable.ipynb in the original college_hockey folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "# print list of folders one dir up from current\n",
    "# print(os.listdir(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# path ro TEMP folder\n",
    "temp_folder = os.path.join(os.getcwd(), '..', 'TEMP')\n",
    "# Data folder\n",
    "data_folder = os.path.join(os.getcwd(), '..', 'data')\n",
    "# Image folder\n",
    "img_folder = os.path.join(os.getcwd(), '..', 'images')\n",
    "\n",
    "# # save file into each folder for testing\n",
    "\n",
    "# file = os.path.join(temp_folder, 'test.txt')\n",
    "# with open(file, 'w') as f:\n",
    "#     f.write('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get All Scheduled games for the given season in CHN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the URL to scrape\n",
    "url_base = 'https://www.collegehockeynews.com/schedules/?season=' # Link to the 2022-2023 season with all results\n",
    "\n",
    "#### THESE NEED TO BE UPDATED EACH SEASON ####\n",
    "#### Set the season varriable portion of the url \n",
    "url_season = '20242025'\n",
    "#### string to add to file names and whatnote\n",
    "file_tag = '2024_current_sept_24'\n",
    "\n",
    "############# Set the output folder to the TEMP folder for testing\n",
    "final_output_dir = os.path.join(temp_folder)\n",
    "\n",
    "# # Set the output folder to the data folder\n",
    "# final_output_dir = os.path.join(data_folder, 'schedule')\n",
    "\n",
    "\n",
    "# temp_output_dir = '../TEMP/results/'\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "## Construction the url to feel to parser\n",
    "url = url_base + url_season\n",
    "\n",
    "# Get the page with requests\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# select the table or tables\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "# Initialize variables\n",
    "current_date = None\n",
    "current_conference = None\n",
    "game_notes = None\n",
    "\n",
    "# Initialize an empty list to hold the data\n",
    "data = []\n",
    "\n",
    "# Parse the table with BeautifulSoup\n",
    "\n",
    "rows = soup.find_all('tr')\n",
    "\n",
    "# Loop through each row to find relevant information\n",
    "for row in rows:\n",
    "    # Check for date row\n",
    "    if row.get('class') == ['stats-section']:\n",
    "        current_date = row.find('td').text.strip()\n",
    "    # Check for conference row\n",
    "    elif row.get('class') == ['sked-header']:\n",
    "        current_conference = row.find('td').text.strip()\n",
    "    # Check for game notes\n",
    "    elif len(row.find_all('td')) == 2:\n",
    "        game_notes = row.find_all('td')[1].text.strip()\n",
    "    # Process rows with game data\n",
    "    elif row.get('valign') == 'top':\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) >= 9:\n",
    "            home_team = cells[0].text.strip()\n",
    "            home_team_link = cells[0].find('a')['href'] if cells[0].find('a') else None\n",
    "            home_score = cells[1].text.strip()\n",
    "            away_team = cells[3].text.strip()\n",
    "            away_team_link = cells[3].find('a')['href'] if cells[3].find('a') else None\n",
    "            away_score = cells[4].text.strip()\n",
    "            ot = cells[5].text.strip()\n",
    "            box_link = cells[7].find('a')['href'] if cells[7].find('a') else None\n",
    "            metrics_link = cells[8].find('a')['href'] if cells[8].find('a') else None\n",
    "             # Capture Game Notes\n",
    "            game_notes_cell = cells[-1].find('small')\n",
    "            game_notes = game_notes_cell.text.strip() if game_notes_cell else None\n",
    "\n",
    "            # Append data to the list\n",
    "            data.append([current_date, current_conference, game_notes, home_team, home_team_link, home_score, away_team, away_team_link, away_score, ot, box_link, metrics_link])\n",
    "            game_notes = None  # Reset game notes for the next row\n",
    "            \n",
    "\n",
    "# Create a DataFrame\n",
    "columns = ['Date', 'Conference', 'Game_Notes', 'Away_Team', 'Away_Team_Link', 'Away_Score', 'Home_Team', 'Home_Team_Link', 'Home_Score',  'OT', 'Box_Link', 'Metrics_Link']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Data Tranformation\n",
    "#### Creates Unique GAME_ID\n",
    "- Cleaning string formats, \n",
    "- create team abbv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract the day of the week from the date and save in new column\n",
    "df['Day'] = pd.to_datetime(df['Date']).dt.day_name()\n",
    "# remove day of the week from date\n",
    "# format data column as YYYY-MM-DD\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "### Create a new column for the game ID\n",
    "## Game ID will be a combination of the date and abbreviated team names\n",
    "\n",
    "# Function to abbreviate the team names\n",
    "for row in df.itertuples():\n",
    "    home_team = row.Home_Team\n",
    "    away_team = row.Away_Team\n",
    "    home_team_abbr = home_team.split(' ')[-1]\n",
    "    away_team_abbr = away_team.split(' ')[-1]\n",
    "    game_id = f'{row.Date}_{home_team_abbr}_{away_team_abbr}'\n",
    "    df.loc[row.Index, 'Game_ID'] = game_id\n",
    "\n",
    "# Create a new column for the game ID\n",
    "df['Game_ID'] = df['Game_ID'].str.replace(',', '')\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['Game_ID'] = df.apply(lambda row: f'{row.Date}_{row.Home_Team}_{row.Away_Team}', axis=1)\n",
    "\n",
    "# STORE AS SCHED_DF\n",
    "sched_df = df.copy()\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# IN THE TEMP FOLDER\n",
    "sched_df.to_csv(os.path.join(final_output_dir, f'schedule_{file_tag}.csv'), index=False)\n",
    "# TO THE DATA FOLDER\n",
    "# sched_df.to_csv(os.path.join(data_folder, f'schedule_{file_tag}.csv'), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sched_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get The Roster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of team links: 64\n",
      "TEST LINK: FIRST IN LIST: https://www.collegehockeynews.com/reports/roster/Lake-Superior/24/20242025\n",
      "TEST LINK: LAST IN LIST: https://www.collegehockeynews.com/reports/roster/Long-Island/62/20242025\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Load results for season to get team links\n",
    "# Read the CSV file\n",
    "# results = pd.read_csv('../../data/results_table_all_time.csv')\n",
    "results = sched_df.copy()\n",
    "\n",
    "season = 2024\n",
    "\n",
    "# # Concatenate the unique values in 'Home_Team_Link' and 'Away_Team_Link'\n",
    "team_links = pd.concat([results['Home_Team_Link'], results['Away_Team_Link']])\n",
    "\n",
    "# Drop duplicates and NaN values\n",
    "team_links = team_links.drop_duplicates().dropna()\n",
    "\n",
    "# Clean up the links - drop everything before the third slash - keep the team name and the school ID as string\n",
    "team = team_links.str.split('/', expand=True)[3]\n",
    "# ORIGINAL\n",
    "number = team_links.str.split('/', expand=True)[4]\n",
    "\n",
    "# NEW - Create a string for the year '{season}{season+1}'\n",
    "year = str(season) + str(season+1)\n",
    "# reconstruct the link and store in a new column\n",
    "team_links = 'https://www.collegehockeynews.com/reports/roster/' + team + '/' + number + '/' + year\n",
    "\n",
    "# reset the index\n",
    "team_links = team_links.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "team_links\n",
    "\n",
    "\n",
    "# Output results\n",
    "print(f'Number of team links: {len(team_links)}')\n",
    "print(f'TEST LINK: FIRST IN LIST: {team_links[0]}')\n",
    "print(f'TEST LINK: LAST IN LIST: {team_links.iloc[-1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions that clean the roster dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()# Function to split \"Last Team\" into \"Team\" and \"League\" with edge case handling\n",
    "def split_last_team(last_team):\n",
    "    # Use regular expression to extract team and league\n",
    "    match = re.search(r'(.+) \\((.+)\\)', last_team)\n",
    "    if match:\n",
    "        return match.groups()\n",
    "    else:\n",
    "        # If no league is specified, return the team as is and leave league blank\n",
    "        return last_team, \"\"\n",
    "\n",
    "# Updated function to correctly capture the player's position and handle edge cases in \"Last Team\"\n",
    "def parse_and_transform_roster(html_content):\n",
    "    # Initialize BeautifulSoup object\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find the table with the roster\n",
    "    roster_table = soup.find('table', {'id': 'players'})\n",
    "\n",
    "    # Check if the table exists\n",
    "    if roster_table is None:\n",
    "        print(\"Skipped: The table doesn't exist.\")\n",
    "        return None\n",
    "    \n",
    "    # Extract headers\n",
    "    header_row = roster_table.find('thead').find('tr')\n",
    "    headers = [header.text.strip() for header in header_row.find_all('th')]\n",
    "    headers.append('Position')  # Add the Position column to headers\n",
    "    \n",
    "    # Initialize data list and current_position variable\n",
    "    data = []\n",
    "    current_position = None  # Initialize as None to later filter out irrelevant rows\n",
    "    \n",
    "    # Iterate through each row in the table\n",
    "    for row in roster_table.find_all('tr'):\n",
    "        if 'class' in row.attrs and 'stats-section' in row.attrs['class']:\n",
    "            current_position = row.text.strip()\n",
    "        else:\n",
    "            cells = row.find_all('td')\n",
    "            if cells and current_position:\n",
    "                row_data = [cell.text.strip() for cell in cells]\n",
    "                row_data.append(current_position)  # Add the current position to the row data\n",
    "                data.append(row_data)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "    # Check if DataFrame is empty or if key columns are missing\n",
    "    if df.empty or 'Last Team' not in df.columns or 'NHL Draft' not in df.columns:\n",
    "        print(\"Skipped: The DataFrame is empty or missing key columns.\")\n",
    "        return None\n",
    "    \n",
    "    # Cleanup: Remove rows where 'No.' column is not numeric\n",
    "    df = df[df['No.'].str.isnumeric()]\n",
    "    \n",
    "    # Cleanup: Drop the 'Pos' column\n",
    "    df.drop(columns=['Pos'], inplace=True)\n",
    "    \n",
    "    # Transform Height to Inches\n",
    "    df['Height_Inches'] = df['Ht.'].apply(convert_to_inches)\n",
    "\n",
    "    # Transform NHL Draft to Draft_Year, NHL_Team, and D_Round\n",
    "    # Transform NHL Draft to Draft_Year, NHL_Team, and D_Round\n",
    "    draft_result = df['NHL Draft'].apply(split_nhl_draft)\n",
    "\n",
    "    # Check if there are enough values to unpack\n",
    "    if len(draft_result) > 0:\n",
    "        df['Draft_Year'], df['NHL_Team'], df['D_Round'] = zip(*draft_result)\n",
    "    else:\n",
    "        # Handle the case when result is empty\n",
    "        df['Draft_Year'], df['NHL_Team'], df['D_Round'] = [None] * len(df), [None] * len(df), [None] * len(df)\n",
    "\n",
    "    df.drop(columns=['NHL Draft'], inplace=True) # Drop the original NHL Draft column\n",
    "    \n",
    "    # Handle edge cases in \"Last Team\" to split into \"Team\" and \"League\"\n",
    "    df['Team'], df['League'] = zip(*df['Last Team'].apply(split_last_team))\n",
    "    df.drop(columns=['Last Team'], inplace=True)\n",
    "    \n",
    "    # Rename the trouble column Hometown\\nLast Team\\nNHL Draft\n",
    "    df.rename(columns={'Hometown\\nLast Team\\nNHL Draft': 'Hometown'}, inplace=True)\n",
    "\n",
    "    # assign data types No. Wt. and Height_Inches to int, DOB to datetime\n",
    "    int_list = ['No.', 'Wt.', 'Height_Inches']\n",
    "    # Convert columns to numeric, coercing errors to NaN\n",
    "    df[int_list] = df[int_list].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Replace NaNs with a default value for specific columns\n",
    "    default_value = 0\n",
    "    df[int_list] = df[int_list].fillna(value=default_value)\n",
    "\n",
    "    # Confirm that NaNs are filled\n",
    "    print(df[int_list].isna().sum())  # Should output all zeros\n",
    "\n",
    "    # Convert the columns to integers\n",
    "    df[int_list] = df[int_list].astype(int)\n",
    "\n",
    "    # df = df[df['Height_Inches'].notna()]  # Assuming convert_to_inches returns None for bad values\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to split \"NHL Draft\" into \"Draft_Year\", \"NHL_Team\", and \"D_Round\"\n",
    "def split_nhl_draft(nhl_draft):\n",
    "    try:\n",
    "        draft_year, nhl_team, d_round = nhl_draft.split('-')\n",
    "        return draft_year, nhl_team, d_round\n",
    "    except ValueError:\n",
    "        # Handle missing or incomplete data\n",
    "        return None, None, None\n",
    "\n",
    "# # Test the function\n",
    "# test_values = ['2022-WSH-7', '', '2021-DET']\n",
    "# [split_nhl_draft(val) for val in test_values]\n",
    "\n",
    "\n",
    "\n",
    "# Function to convert height in \"ft-in\" format to total inches\n",
    "def convert_to_inches(height_str):\n",
    "    try:\n",
    "        feet, inches = map(int, height_str.split('-'))\n",
    "        return (feet * 12) + inches\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the roster scrape and parser for the list of team name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing team 1 of 64\n"
     ]
    }
   ],
   "source": [
    "# Correcting the code to handle the 'Team' and 'Last Team' columns properly\n",
    "\n",
    "## Loop through the team links and parse the roster data \n",
    "### Notes: save the roster link to the dataframe and add the team name and school ID\n",
    "\n",
    "roster_dfs = []  # Assuming this list exists to store each roster DataFrame\n",
    "\n",
    "# Extract team names from team_links\n",
    "team_names = pd.Series(team_links).str.split('/', expand=True)[5]\n",
    "\n",
    "\n",
    "for i, link in enumerate(team_links):\n",
    "    print(f'Processing team {i+1} of {len(team_links)}')\n",
    "    \n",
    "    try:\n",
    "        # Make GET request to team link\n",
    "        r = requests.get(link)\n",
    "        r.raise_for_status()  # This will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "        html_content = r.text\n",
    "        \n",
    "        # Parse and transform the roster data\n",
    "        roster_df = parse_and_transform_roster(html_content)\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error during the request for team {i+1} ({team_names.iloc[i]}): {e}\")\n",
    "        continue\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing the data for team {i+1} ({team_names.iloc[i]}): {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Check if the DataFrame exists (i.e., the page had content)\n",
    "    if roster_df is None:\n",
    "        print(f\"Skipping team {i+1} due to missing or empty data.\")\n",
    "        continue  # Skip this iteration and move to the next one\n",
    "\n",
    "    try:\n",
    "        # Reset the index if it's not unique\n",
    "        roster_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Add the team name\n",
    "        current_team = team_names.iloc[i]  # Extract the current team name\n",
    "        roster_df['Current Team'] = current_team  # Add it to the DataFrame\n",
    "\n",
    "        # Add a column with the season\n",
    "        roster_df['Season'] = season\n",
    "        \n",
    "        # Add the roster DataFrame to the list\n",
    "        roster_dfs.append(roster_df)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error working with the DataFrame for team {i+1} ({team_names.iloc[i]}): {e}\")\n",
    "        continue\n",
    "\n",
    "# Assuming the last dataframe processed is the one of interest (can be adjusted later)\n",
    "# roster_df = roster_dfs[-1]\n",
    "\n",
    "# Add all the DataFrames in the list to a single DataFrame\n",
    "roster_df = pd.concat(roster_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Roster Cleaning Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTPUT TO TEMP FOLDER FOR EXAMINATION\n",
    "# roster_df.to_csv(os.path.join(temp_folder, f'roster_{file_tag}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Team</th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>First_Name</th>\n",
       "      <th>No</th>\n",
       "      <th>Position</th>\n",
       "      <th>Yr</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Height_Inches</th>\n",
       "      <th>Draft_Year</th>\n",
       "      <th>NHL_Team</th>\n",
       "      <th>D_Round</th>\n",
       "      <th>Last Team</th>\n",
       "      <th>League</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>Barone</td>\n",
       "      <td>Adam</td>\n",
       "      <td>6</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Fr</td>\n",
       "      <td>6-1</td>\n",
       "      <td>174</td>\n",
       "      <td>5/6/2004</td>\n",
       "      <td>Sault Ste. Marie, Ont.</td>\n",
       "      <td>73</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Trail</td>\n",
       "      <td>BCHL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>Blanchett</td>\n",
       "      <td>Jack</td>\n",
       "      <td>16</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>So</td>\n",
       "      <td>5-11</td>\n",
       "      <td>185</td>\n",
       "      <td>5/12/2003</td>\n",
       "      <td>Monroe, Mich.</td>\n",
       "      <td>71</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Powell</td>\n",
       "      <td>BCHL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Mike</td>\n",
       "      <td>3</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Jr</td>\n",
       "      <td>6-2</td>\n",
       "      <td>209</td>\n",
       "      <td>4/3/2001</td>\n",
       "      <td>Belmont, Mass.</td>\n",
       "      <td>74</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Merrimack</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>Bushy</td>\n",
       "      <td>Evan</td>\n",
       "      <td>5</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>So</td>\n",
       "      <td>6-1</td>\n",
       "      <td>195</td>\n",
       "      <td>3/26/2002</td>\n",
       "      <td>Mankato, Minn.</td>\n",
       "      <td>73</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Trail</td>\n",
       "      <td>BCHL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>Conrad</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>4</td>\n",
       "      <td>Defensemen</td>\n",
       "      <td>Fr</td>\n",
       "      <td>5-11</td>\n",
       "      <td>180</td>\n",
       "      <td>5/18/2002</td>\n",
       "      <td>Green Bay, Wis.</td>\n",
       "      <td>71</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Fairbanks</td>\n",
       "      <td>NAHL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Current Team  Last_Name First_Name  No    Position  Yr    Ht   Wt  \\\n",
       "0  Lake Superior     Barone       Adam   6  Defensemen  Fr   6-1  174   \n",
       "1  Lake Superior  Blanchett       Jack  16  Defensemen  So  5-11  185   \n",
       "2  Lake Superior      Brown       Mike   3  Defensemen  Jr   6-2  209   \n",
       "3  Lake Superior      Bushy       Evan   5  Defensemen  So   6-1  195   \n",
       "4  Lake Superior     Conrad      Jacob   4  Defensemen  Fr  5-11  180   \n",
       "\n",
       "         DOB                Hometown  Height_Inches Draft_Year NHL_Team  \\\n",
       "0   5/6/2004  Sault Ste. Marie, Ont.             73       None     None   \n",
       "1  5/12/2003           Monroe, Mich.             71       None     None   \n",
       "2   4/3/2001          Belmont, Mass.             74       None     None   \n",
       "3  3/26/2002          Mankato, Minn.             73       None     None   \n",
       "4  5/18/2002         Green Bay, Wis.             71       None     None   \n",
       "\n",
       "  D_Round  Last Team League  \n",
       "0    None      Trail   BCHL  \n",
       "1    None     Powell   BCHL  \n",
       "2    None  Merrimack         \n",
       "3    None      Trail   BCHL  \n",
       "4    None  Fairbanks   NAHL  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Further transformations\n",
    "\n",
    "roster_df['Current Team'] = roster_df['Current Team'].str.replace('-', ' ') # Remove - [dash] from Current Team\n",
    "roster_df.columns = roster_df.columns.str.replace('.', '')  # Remove periods in column names\n",
    "# Split 'Name' into 'First Name' and 'Last Name'\n",
    "roster_df['Last_Name'] = roster_df['Name'].str.split(',').str[0]  # Extract 'Last Name'\n",
    "roster_df['First_Name'] = roster_df['Name'].str.split(',').str[1]  # Extract 'First Name'\n",
    "# roster_df['Name'] = roster_df['Name'].str.split(',').str[::-1].str.join(' ')  # Convert 'Last, First' to 'First Last'\n",
    "roster_df['Player'] = roster_df['Name']  # Store the Player name as 'First Last'\n",
    "roster_df['Player'] = roster_df['Player'].str.replace(u'\\xa0', u' ').str.strip()  # Cleanup player name\n",
    "roster_df = roster_df.drop(['Name'], axis=1)  # Drop the original 'Name' column\n",
    "\n",
    "# Renaming 'Team' to 'Last Team' if it exists in the DataFrame\n",
    "if 'Team' in roster_df.columns:\n",
    "    roster_df.rename(columns={'Team': 'Last Team'}, inplace=True)\n",
    "\n",
    "# Checking if 'Last Team' exists in the dataframe before reordering\n",
    "if 'Last Team' not in roster_df.columns:\n",
    "    print(\"'Last Team' column not found in the DataFrame. Please check the data extraction process.\")\n",
    "else:\n",
    "    # Reorder columns without duplicate 'Team'\n",
    "    roster_df = roster_df[['Current Team', 'Last_Name', 'First_Name', 'No', 'Position', 'Yr', 'Ht', 'Wt', 'DOB', \n",
    "                           'Hometown', 'Height_Inches', 'Draft_Year', 'NHL_Team', 'D_Round', 'Last Team', 'League']]\n",
    "\n",
    "roster_df.head() if 'Last Team' in roster_df.columns else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the Hometown column\n",
    "- Explode Hometown into City, State/Provence, Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the Hometown column is a string and handle NaN values\n",
    "roster_df['Hometown'] = roster_df['Hometown'].astype(str)\n",
    "\n",
    "# First step: split the Hometown column by commas into two parts (city and state/province)\n",
    "# We'll explicitly handle cases where there may not be two parts\n",
    "split_columns = roster_df['Hometown'].str.split(',', n=1, expand=True)\n",
    "\n",
    "# Assign split values to new columns and handle missing values\n",
    "roster_df['City'] = split_columns[0].str.strip()\n",
    "roster_df['State_Province'] = split_columns[1].str.strip() if split_columns.shape[1] > 1 else ''\n",
    "\n",
    "\n",
    "# Define a list of known USA states and Canadian provinces abbreviations\n",
    "usa_states = ['Ala.', 'Alaska', 'Ariz.', 'Ark.', 'Calif.', 'Colo.', 'Conn.', 'Del.', 'D.C.', 'DC', 'Fla.', 'Ga.', 'Hawaii', \n",
    "              'Idaho', 'Ill.', 'Ind.', 'Iowa', 'Kan.', 'Ky.', 'La.', 'Maine', 'Md.', 'Mass.', 'Mich.', 'Minn.', 'Miss.', \n",
    "              'Mo.', 'Mont.', 'Neb.', 'Nev.', 'N.H.', 'N.J.', 'N.M.', 'N.Y.', 'N.C.', 'N.D.', 'Ohio', 'Okla.', 'Ore.', \n",
    "              'Pa.', 'R.I.', 'S.C.', 'S.D.', 'Tenn.', 'Texas', 'Utah', 'Vt.', 'Va.', 'Wash.', 'W.Va.', 'Wis.', 'Wisc.', 'Wyo.']\n",
    "\n",
    "canada_provinces = ['Alta.', 'Alb.', 'B.C.', 'Man.', 'MB', 'N.B.', 'NB', 'N.L.', 'Newf.', 'NWT', 'N.S.', 'N.W.T.', 'Nunavut', 'Ont.', 'P.E.I.', 'Que.', 'Sask.', 'Yukon', 'YT']\n",
    "\n",
    "# Function to infer country more robustly\n",
    "def robust_infer_country(state_province):\n",
    "    if pd.isna(state_province) or state_province == '':\n",
    "        return None\n",
    "    state_province = state_province.strip()\n",
    "    \n",
    "    # USA state\n",
    "    if state_province in usa_states:\n",
    "        return 'USA'\n",
    "    \n",
    "    # Canadian province\n",
    "    if state_province in canada_provinces:\n",
    "        return 'Canada'\n",
    "    \n",
    "    # If it doesn't match USA or Canada, treat the state_province as a country\n",
    "    return state_province\n",
    "\n",
    "# Apply the updated function to infer the country for each player\n",
    "roster_df['Country'] = roster_df['State_Province'].apply(robust_infer_country)\n",
    "\n",
    "# Country abreviations that need to be replaced ITA-Italy, AUT-Austria, SUI-Switzerland\n",
    "roster_df['Country'] = roster_df['Country'].replace({'ITA': 'Italy', 'AUT': 'Austria', 'SUI': 'Switzerland'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADDED 9/18/2024\n",
    "\n",
    "# Need to furthur standardize some state, provence and country names\n",
    "## Dictionary to standardize state/province names\n",
    "\n",
    "standardized_locations = {\n",
    "    'Ont.': 'Ontario', 'Mich.': 'Michigan', 'Mass.': 'Massachusetts', 'Minn.': 'Minnesota', \n",
    "    'Wis.': 'Wisconsin', 'Sweden': 'Sweden', 'Germany': 'Germany', 'B.C.': 'British Columbia',\n",
    "    'N.Y.': 'New York', 'Wash.': 'Washington', 'Que.': 'Quebec', 'Alb.': 'Alberta', \n",
    "    'N.J.': 'New Jersey', 'Sask.': 'Saskatchewan', 'Conn.': 'Connecticut', 'Mo.': 'Missouri',\n",
    "    'Texas': 'Texas', 'Calif.': 'California', 'DC': 'District of Columbia', 'Fla.': 'Florida',\n",
    "    'Ohio': 'Ohio', 'Ill.': 'Illinois', 'Pa.': 'Pennsylvania', 'Ga.': 'Georgia',\n",
    "    'Mont.': 'Montana', 'Tenn.': 'Tennessee', 'Colo.': 'Colorado', 'Va.': 'Virginia', \n",
    "    'Vt.': 'Vermont', 'R.I.': 'Rhode Island', 'Md.': 'Maryland', 'Ariz.': 'Arizona', \n",
    "    'Wisc.': 'Wisconsin', 'Iowa': 'Iowa', 'Man.': 'Manitoba', 'Slovakia': 'Slovakia', \n",
    "    'N.D.': 'North Dakota', 'N.C.': 'North Carolina', 'P.E.I.': 'Prince Edward Island',\n",
    "    'N.H.': 'New Hampshire', 'Alaska': 'Alaska', 'Belarus': 'Belarus', 'MB': 'Manitoba',\n",
    "    'Russia': 'Russia', 'Finland': 'Finland', 'Newf.': 'Newfoundland and Labrador', \n",
    "    'Hungary': 'Hungary', 'SUI': 'Switzerland', 'S.C.': 'South Carolina', 'Latvia': 'Latvia',\n",
    "    'Czech Republic': 'Czech Republic', 'N.B.': 'New Brunswick', 'Great Britain': 'United Kingdom', \n",
    "    'NB': 'New Brunswick', 'Norway': 'Norway', 'N.S.': 'Nova Scotia', 'Ind.': 'Indiana', \n",
    "    'NWT': 'Northwest Territories', 'AUT': 'Austria', 'Idaho': 'Idaho', 'S.D.': 'South Dakota', \n",
    "    'Switzerland': 'Switzerland', 'Ore.': 'Oregon', 'Wyo.': 'Wyoming', 'Utah': 'Utah', \n",
    "    'ITA': 'Italy', 'Slovenia': 'Slovenia', 'YT': 'Yukon', 'Del.': 'Delaware', 'Maine': 'Maine',\n",
    "    'Poland': 'Poland', 'Yukon': 'Yukon', 'Ukraine': 'Ukraine', 'Japan': 'Japan', 'Neb.': 'Nebraska'\n",
    "}\n",
    "\n",
    "## Apply the standardization to the State/Province column\n",
    "roster_df['State_Province'] = roster_df['State_Province'].replace(standardized_locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTPUT CLEANED ROSTER FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1819 entries, 0 to 1818\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Current Team    1819 non-null   object\n",
      " 1   Last_Name       1819 non-null   object\n",
      " 2   First_Name      1819 non-null   object\n",
      " 3   No              1819 non-null   int32 \n",
      " 4   Position        1819 non-null   object\n",
      " 5   Yr              1819 non-null   object\n",
      " 6   Ht              1819 non-null   object\n",
      " 7   Wt              1819 non-null   int32 \n",
      " 8   DOB             1819 non-null   object\n",
      " 9   Hometown        1819 non-null   object\n",
      " 10  Height_Inches   1819 non-null   int32 \n",
      " 11  Draft_Year      224 non-null    object\n",
      " 12  NHL_Team        224 non-null    object\n",
      " 13  D_Round         224 non-null    object\n",
      " 14  Last Team       1819 non-null   object\n",
      " 15  League          1819 non-null   object\n",
      " 16  City            1819 non-null   object\n",
      " 17  State_Province  1819 non-null   object\n",
      " 18  Country         1819 non-null   object\n",
      "dtypes: int32(3), object(16)\n",
      "memory usage: 248.8+ KB\n"
     ]
    }
   ],
   "source": [
    "### CHECK RESULTING DATAFRAME\n",
    "roster_df.head()\n",
    "\n",
    "roster_df.info()\n",
    "\n",
    "roster_df.sample(20)\n",
    "\n",
    "# Store todays data as a string\n",
    "date = pd.to_datetime('today').strftime('%Y%m%d')\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# In the TEMP folder\n",
    "roster_df.to_csv(os.path.join(final_output_dir, f'roster_{file_tag}v3_ex{date}.csv'), index=False)\n",
    "# In the DATA folder\n",
    "roster_df.to_csv(os.path.join(data_folder, f'roster_{file_tag}_v3_ex{date}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of players with missing Last Team: 0\n",
      "Number of players with missing League: 0\n",
      "Total number of players: 1819\n",
      "########################################\n",
      "\n",
      "########################################\n",
      "Distribution of players by position:\n",
      "Position\n",
      "Forwards       1033\n",
      "Defensemen      585\n",
      "Goaltenders     201\n",
      "Name: count, dtype: int64\n",
      "########################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of players with no Last Team and or League vs total number of players\n",
    "missing_team = roster_df['Last Team'].isna().sum()\n",
    "missing_league = roster_df['League'].isna().sum()\n",
    "\n",
    "print(f'Number of players with missing Last Team: {missing_team}')\n",
    "print(f'Number of players with missing League: {missing_league}')\n",
    "print(f'Total number of players: {len(roster_df)}')\n",
    "print('########################################\\n')\n",
    "print('########################################')\n",
    "print(f'Distribution of players by position:\\n{roster_df[\"Position\"].value_counts()}')\n",
    "print('########################################\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams with the most draft picks:\n",
      "Current Team\n",
      "Minnesota            16\n",
      "North Dakota         13\n",
      "Boston University    13\n",
      "Denver               13\n",
      "Harvard              12\n",
      "Boston College       12\n",
      "Providence           11\n",
      "Minnesota Duluth     10\n",
      "Massachusetts         9\n",
      "Michigan              8\n",
      "Colorado College      8\n",
      "Western Michigan      8\n",
      "Northeastern          7\n",
      "Wisconsin             7\n",
      "Michigan State        7\n",
      "Cornell               6\n",
      "St Cloud State        6\n",
      "Notre Dame            6\n",
      "Omaha                 5\n",
      "Ohio State            5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Teams with the most draft picks\n",
    "# Filter out players with missing draft information\n",
    "draft_df = roster_df[roster_df['Draft_Year'].notna()]\n",
    "\n",
    "# Group by 'Current Team' and count the number of draft picks\n",
    "team_draft_counts = draft_df['Current Team'].value_counts()\n",
    "print(f'Teams with the most draft picks:\\n{team_draft_counts.head(20)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "Distribution of players by League:\n",
      "League\n",
      "USHL              550\n",
      "NAHL              341\n",
      "BCHL              283\n",
      "AJHL               82\n",
      "HEA                72\n",
      "                   58\n",
      "NCHC               55\n",
      "CCHA               44\n",
      "ECAC               42\n",
      "NTDP               40\n",
      "B10                33\n",
      "AHA                33\n",
      "OJHL               28\n",
      "NCDC               28\n",
      "SJHL               18\n",
      "Independents       16\n",
      "MJHL               16\n",
      "D-I Ind.           13\n",
      "CCHL               10\n",
      "J20 Nationell      10\n",
      "SM-sarja            6\n",
      "NCAA D3             3\n",
      "PREP                3\n",
      "SWE                 3\n",
      "ACHA                2\n",
      "AJHL/BCHL           2\n",
      "NA3HL               2\n",
      "EHL                 2\n",
      "USHS                2\n",
      "D-III               1\n",
      "PHC                 1\n",
      "USPHL NCDC          1\n",
      "Sweden              1\n",
      "ACHA-II             1\n",
      "MJAHL               1\n",
      "USHS-Prep           1\n",
      "SHL                 1\n",
      "MHL                 1\n",
      "DIII                1\n",
      "DI Independent      1\n",
      "Midget AAA          1\n",
      "Prep                1\n",
      "CISAA               1\n",
      "WCHA                1\n",
      "J20                 1\n",
      "MHSAA               1\n",
      "USPHL               1\n",
      "D3                  1\n",
      "NCAA DIII           1\n",
      "Oberliga            1\n",
      "UCHC                1\n",
      "Name: count, dtype: int64\n",
      "########################################\n",
      "\n",
      "Distribution of players by Class Year:\n",
      "Yr\n",
      "Fr    484\n",
      "So    437\n",
      "Jr    386\n",
      "Sr    332\n",
      "Gr    180\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Player by League\n",
    "print('########################################')\n",
    "print(f'Distribution of players by League:\\n{roster_df[\"League\"].value_counts()}')\n",
    "\n",
    "## Distrobution by class year\n",
    "print('########################################\\n')\n",
    "print(f'Distribution of players by Class Year:\\n{roster_df[\"Yr\"].value_counts()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "\n",
      "Distribution of players by First Name:\n",
      "First_Name\n",
      "Ryan       48\n",
      "Jack       46\n",
      "Nick       31\n",
      "Tyler      29\n",
      "Michael    27\n",
      "           ..\n",
      "Gavyn       1\n",
      "Verner      1\n",
      "Daimon      1\n",
      "Karl        1\n",
      "Tyriq       1\n",
      "Name: count, Length: 604, dtype: int64\n",
      "########################################\n",
      "\n",
      "Distribution of players by Last Name:\n",
      "Last_Name\n",
      "Smith          10\n",
      "Johnson         7\n",
      "Brown           6\n",
      "Miller          6\n",
      "Scott           6\n",
      "               ..\n",
      "Hillier         1\n",
      "Fitzpatrick     1\n",
      "Daneault        1\n",
      "Cranston        1\n",
      "Rupprecht       1\n",
      "Name: count, Length: 1576, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Value Count of First Name\n",
    "print('########################################\\n')\n",
    "print(f'Distribution of players by First Name:\\n{roster_df[\"First_Name\"].value_counts()}')\n",
    "\n",
    "## Value Count of Last Name\n",
    "print('########################################\\n')\n",
    "print(f'Distribution of players by Last Name:\\n{roster_df[\"Last_Name\"].value_counts()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "\n",
      "Distribution of players by Hometown:\n",
      "City\n",
      "Calgary              48\n",
      "Toronto              27\n",
      "Winnipeg             16\n",
      "Plymouth             15\n",
      "North Vancouver      14\n",
      "                     ..\n",
      "Westport              1\n",
      "Sewell                1\n",
      "Castle Pines          1\n",
      "Pendleton             1\n",
      "Thief River Falls     1\n",
      "Name: count, Length: 909, dtype: int64\n",
      "########################################\n",
      "\n",
      "Distribution of players by State_Province:\n",
      "State_Province\n",
      "Minnesota                241\n",
      "Ontario                  183\n",
      "Massachusetts            120\n",
      "Michigan                 117\n",
      "Alberta                  114\n",
      "                        ... \n",
      "Northwest Territories      1\n",
      "Prince Edward Island       1\n",
      "Montana                    1\n",
      "South Carolina             1\n",
      "Nebraska                   1\n",
      "Name: count, Length: 69, dtype: int64\n",
      "########################################\n",
      "\n",
      "Distribution of players by Country:\n",
      "Country\n",
      "USA               1129\n",
      "Canada             523\n",
      "Sweden              57\n",
      "Finland             29\n",
      "Latvia              18\n",
      "Slovakia            15\n",
      "Russia              10\n",
      "Czech Republic       8\n",
      "Norway               8\n",
      "Germany              4\n",
      "Hungary              3\n",
      "Belarus              3\n",
      "Switzerland          3\n",
      "Slovenia             2\n",
      "Great Britain        2\n",
      "Austria              1\n",
      "Italy                1\n",
      "Poland               1\n",
      "Ukraine              1\n",
      "Japan                1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Value Count of City\n",
    "print('########################################\\n')\n",
    "print(f'Distribution of players by Hometown:\\n{roster_df[\"City\"].value_counts()}')\n",
    "\n",
    "## Value Count of State_Province\n",
    "print('########################################\\n')\n",
    "print(f'Distribution of players by State_Province:\\n{roster_df[\"State_Province\"].value_counts()}')\n",
    "\n",
    "## Value Count of Country\n",
    "print('########################################\\n')\n",
    "print(f'Distribution of players by Country:\\n{roster_df[\"Country\"].value_counts()}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
